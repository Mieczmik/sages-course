{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem klasyfikacji sekwencji\n",
    "\n",
    "Dane to ciągi różnych długości, np. tekst, muzyka, film.\n",
    "* Elementami ciągów są “obiekty bazowe”\n",
    "  * Tekst - ciąg słów (ogólniej - tokenów)\n",
    "  * Film - ciąg obrazów\n",
    "  * Muzyka - ciąg dźwięków\n",
    "* Uwaga 1: elementy ciągów są od siebie zależne!\n",
    "* Uwaga 2: kolejność elementów jest istotna!\n",
    "* Jak można pracować z ciągami?\n",
    "  * Sprowadzić ciągi do reprezentacji wektorowej i użyć\n",
    "  klasycznych metod uczenia maszynowego\n",
    "  * Użyć metod dedykowanych do takich danych - na przykład sieci rekurencyjnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## NLP Modele Sekwencyjne i ich zastosowania\n",
    "Modelem sekwencyjnym nazwiemy model, który jako wejście otrzymuje sekwencję, ale nie musi zwracać sekwencji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sieci rekurencyjne\n",
    "Zasadą działania sieci rekurencyjnej jest przechowywanie wyjścia poprzedniego elementu i wykorzystania go w kolejnym kroku.\n",
    "\n",
    "Dlaczego po prostu do sekwencji nie wykorzystać zwykłych gęstych sieci neuronowych?\n",
    "* Nie są w stanie przetwarzać sekwencji o różnych długościach\n",
    "* Biorą pod uwagę tylko aktualne dane wejściowe\n",
    "* Nie zapamiętują informacji o poprzednich danych wejściowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RNN\n",
    "Podstawową wersją sieci rekurencyjnej jest RNN(recurrent Neural Network)\n",
    "$$ h_t = \\text{tanh}(Wx_t+Uh_{t-1}+b) $$\n",
    "![](Grafika/RNN-unrolled.png)\n",
    "\n",
    "Zalety:\n",
    "* Możliwość przetwarzania sekwencji o dowolnej długości\n",
    "* Rozmiar modelu nie rośnie razem z długością sekwencji\n",
    "* Bierze pod uwagę poprzednie stany\n",
    "\n",
    "Wady:\n",
    "* Wolne obliczenia\n",
    "* Problem wykorzystywania bardzo odległych stanów\n",
    "* Nie może brać pod uwagę przyszłych stanów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embeddingi słów\n",
    "Przeanalizujmy co się dzieje w sieci, gdy\n",
    "podajemy słowa w reprezentacji _one hot_:\n",
    "$$ h_t = f(W^h \\cdot h_{t-1}+W^x\\cdot x_t +b)$$\n",
    "Jeśli $x_t$ to _one-got_ z jedynką na pozycji i to \n",
    "$$W^x\\cdot x_t=W^x \\cdot [0,\\dots, 1_i,\\dots, 0]^T=W^x[:,i]$$\n",
    "Zatem przekształcenie to jest równoważne wzięciu i'tej kolumny macierzy wag.\n",
    "\n",
    "Czyli i-ta kolumna macierzy wag jest w pewnym sensie reprezentacją słowa i-tego.\n",
    "\n",
    "Zatem pójdźmy krok dalej: stwórzmy dodatkową warstwę w sieci - macierz \n",
    "embeddingów EMB, zawierającą reprezentacje słów, które będą\n",
    "przekazywane do wyliczenia stanu ukrytego\n",
    "\\begin{align*}\n",
    "    &emb_t=EMB\\cdot x_t=EMB[:,i]\\\\\n",
    "    &h_t=f(W^h \\cdot h_{t-1}+W^x\\cdot emb_t +b)\n",
    "\\end{align*}\n",
    "\n",
    "Embeddingi są parametrami sieci, ale\n",
    "jednocześnie reprezentacją słów.\n",
    "Oznacza to, że trenując sieć, uczymy\n",
    "\n",
    "embeddingi, czyli uczymy się reprezentacji słów!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modele sekwencyjne można podzielić na kilka przykładów\n",
    "### One-to-many, wejście o długości jednostkowej, wyjście o długości > 1. \n",
    "Przykład: generacja tekstu\n",
    "   \n",
    "![](Grafika/rnn-one-to-many-ltr.png)\n",
    "\n",
    "### Many-to-one\n",
    "przykład klasyfikacja sentymentu\n",
    "\n",
    "![](Grafika/rnn-many-to-one-ltr.png)\n",
    "\n",
    "### Many-to-many (tyle samo wejść co wyjść)\n",
    "przykład: NER(named entity recognition)\n",
    "![](Grafika/rnn-many-to-many-same-ltr.png)\n",
    "\n",
    "### Many-to-many\n",
    "przykład tłumaczenie maszynowe\n",
    "\n",
    "![](Grafika/rnn-many-to-many-different-ltr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Problem odległych informacji relewantnych\n",
    "Rozważmy problem predykcji następnego słowa po “the clouds\n",
    "are in the __”\n",
    "\n",
    "Jest to dość proste zadanie, bo odpowiedź można łatwo\n",
    "wywnioskować na podstawie tych kilku słów.\n",
    "\n",
    "W takich przypadkach zwykła sieć RNN jest odpowiednią\n",
    "strukturą.\n",
    "\n",
    "![](Grafika/RNN-shorttermdepdencies.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Próba przewidzenia “[I grew up in France… . I speak fluent ___”\n",
    "wymaga sięgnięcia wstecz dalej niż kilka słów.\n",
    "\n",
    "Ostatnie słowa sugerują tylko, że następne słowo jest nazwą języka -\n",
    "odgadnięcie, że chodzi o francuski, wymaga odnalezienia”France”.\n",
    "\n",
    "W praktyce dystans do relewantnej informacji często jest duży, a w\n",
    "miarę wzrostu tego dystansu, zwykła sieć RNN staje się niezdolna do\n",
    "wyłapania tych zależności.\n",
    "\n",
    "![](Grafika/RNN-longtermdependencies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Eksplodujący/Zanikający gradient\n",
    "Problem ten często spotyka się podczas korzystania z RNN. Wynika to z tego, że podczas wyliczania gradientu przemnażamy przez siebie wielokrotnie gradienty dla danych chwil czasowych w związku z tym może on zacząć zanikać(jak przemnażamy małe wartości), albo \"wybuchnąć\"(jak przemnażamy duże wartości).\n",
    "\n",
    "Jak sobie poradzić z tym problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LSTM\n",
    "Sieci Long Short Term Memory – zazwyczaj\n",
    "krótko “LSTM”.\n",
    "Hochreiter & Schmidhuber, 1997 (!)\n",
    "\n",
    "Są szczególnym rodzajem sieci\n",
    "rekurencyjnych zaprojektowane tak, aby\n",
    "zwiększyć skuteczność wykrywania\n",
    "długodystansowych zależności.\n",
    "\n",
    "### RNN\n",
    "![](Grafika/LSTM3-SimpleRNN.png)\n",
    "\n",
    "### LSTM\n",
    "![](Grafika/LSTM3-chain.png)\n",
    "![](Grafika/LSTM2-notation.png)\n",
    "\n",
    "Gdzie $\\sigma$ to aktywacja sigmoid.\n",
    "\n",
    "Zatem jak można zauważyć LSTM posiada dwie \"ścieżki\" pamięci. Pierwszą jest tak zwany \"cell state\"\n",
    "![](Grafika/LSTM3-C-line.png)\n",
    "Ze względu na to, że ma on tylko liniowe interakcje łatwo jest o przepływ informacji tą scieżką. LSTM ma możliwość usuwania i dodawania informacji do tej ścieżki, co jest decydowanie przez tak zwane bramki(gates). Decydują one o tym czy dana informacją powinna dalej przejść\n",
    "\n",
    "![](Grafika/LSTM3-gate.png)\n",
    "\n",
    "Ponieważ sigmoida zwraca wartości między 0 a 1 decyduje jak \"dużo\" informacji powinno przepłynąć dalej.\n",
    "\n",
    "#### LSTM krok po kroku\n",
    "W pierwszym kroku decydujemy jak wiele aktualnej informacji powinno zostać w cell state.\n",
    "\n",
    "![](Grafika/LSTM3-focus-f.png)\n",
    "\n",
    "Następnie decydujemy jak wiele nowej informacji powinniśmy dodać do cell state\n",
    "\n",
    "![](Grafika/LSTM3-focus-i.png)\n",
    "\n",
    "Dokonujemy aktualizacji cell state\n",
    "\n",
    "![](Grafika/LSTM3-focus-C.png)\n",
    "\n",
    "Na koniec wybieramy interesujące nas informacje z zakutalizowanego cell state, które zostaną zwrócone przez LSTM\n",
    "\n",
    "![](Grafika/LSTM3-focus-o.png)\n",
    "\n",
    "Istnieją jeszcze inne warianty LSTM np. wykorzystujące cell state do bramek\n",
    "\n",
    "![](Grafika/LSTM3-var-peepholes.png)\n",
    "\n",
    "i takie, które wykorzystują jedną bramkę do zapominania/dodawania informacji do cell state\n",
    "\n",
    "![](Grafika/LSTM3-var-tied.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### GRU a LSTM\n",
    "GRU jest kolejną siecią rekurencyjną, której celem jest rozwiązanie odległych relacji między momentami czasu\n",
    "\n",
    "![](Grafika/gru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stacked RNN\n",
    "\n",
    "![](Grafika/stacked_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bidirectional RNN\n",
    "Czasem może nas interesować nie tylko infromacja z lewej do prawej ale także w drugą stronę, np. podczas klasyfikacji tekstu, w związku z tym aby otrzymać Biderctional RNN łączymy wyniki z dwóch sieci RNN, jedna \"czyta\" od lewej do prawej, a druga w drugą stronę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_input = tf.ones((1, 12, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 12, 2), dtype=float32, numpy=\narray([[[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]]], dtype=float32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_inputs = tf.ones((1, 12, 2))\n",
    "example_prices = tf.ones((1, 12, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 512])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 12, 512])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 512) (1, 512)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "output, hidden_state = rnn_layer(example_input)\n",
    "print(type(output))\n",
    "print(output.shape, hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 1024)\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "output = bidirectional_rnn(example_input)\n",
    "print(type(output))\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size=10\n",
    "output_dim=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m embedding_layer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(\n\u001B[1;32m      2\u001B[0m     vocab_size,\n\u001B[1;32m      3\u001B[0m     output_dim,\n\u001B[1;32m      4\u001B[0m     embeddings_initializer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     embeddings_regularizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m     activity_regularizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m     embeddings_constraint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      8\u001B[0m     mask_zero\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m     input_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m     11\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    vocab_size,\n",
    "    output_dim,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    "    **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Do warstwy Embedding możemy podać przetrenowane wcześniej embeddingi. Muszą one być wcześniej przygotowane jako macierz o wymiarach (vocab_size x embedding_dim). Oraz i'ty wiersz, musi odpowiadać embeddingowi tokenu, który przekształacmy na liczbę `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_embedding_matrix = np.array(range(10*30)).reshape((10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_embedding = tf.keras.layers.Embedding(\n",
    "    10,\n",
    "    30,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(pretrained_embedding_matrix),\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 2, 30), dtype=float32, numpy=\narray([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,\n          10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,\n          20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.],\n        [270., 271., 272., 273., 274., 275., 276., 277., 278., 279.,\n         280., 281., 282., 283., 284., 285., 286., 287., 288., 289.,\n         290., 291., 292., 293., 294., 295., 296., 297., 298., 299.]]],\n      dtype=float32)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedding(np.array([[0,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 512])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 12, 512])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 12, 1024])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([1, 12, 512]), TensorShape([1, 512]), TensorShape([1, 512]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "out, cell_state, hidden_state = lstm(example_input)\n",
    "out.shape, cell_state.shape, hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1, 12, 512), dtype=float32, numpy=\n array([[[-0.03040359,  0.05052163, -0.0114219 , ...,  0.01880071,\n           0.04016161,  0.05248069],\n         [-0.03107806,  0.05108547, -0.01205938, ...,  0.01996111,\n           0.04064401,  0.05330994],\n         [-0.03160809,  0.05153299, -0.0126333 , ...,  0.02097402,\n           0.04100688,  0.05395285],\n         ...,\n         [-0.03309631,  0.05296824, -0.01508493, ...,  0.02506671,\n           0.0418531 ,  0.05558472],\n         [-0.03314754,  0.05304562, -0.01526771, ...,  0.02536547,\n           0.04186686,  0.05561829],\n         [-0.03318093,  0.05310643, -0.01542296, ...,  0.02562031,\n           0.04187149,  0.05563284]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n array([[-3.31809260e-02,  5.31064272e-02, -1.54229552e-02,\n          2.68803257e-02, -3.66238281e-02,  8.42820015e-03,\n          1.88487489e-02,  4.96336594e-02,  1.32185938e-02,\n          2.06017531e-02, -1.60628129e-02, -8.81140456e-02,\n          2.38809679e-02,  2.68248003e-03,  3.59957628e-02,\n         -3.32397595e-02, -3.57127525e-02,  7.66009614e-02,\n         -5.87764643e-02,  8.37468430e-02,  3.57469693e-02,\n         -7.87572339e-02,  1.70518160e-02, -2.90847123e-02,\n         -6.64429972e-04,  8.93024262e-03,  3.86235043e-02,\n          4.98608723e-02, -1.67274447e-05, -7.37490505e-03,\n          7.54992664e-03, -8.21681172e-02, -5.60706593e-02,\n          5.50317205e-02,  3.65916006e-02, -7.21387379e-03,\n         -8.52779746e-02, -2.87866015e-02,  4.03228588e-02,\n          4.12495174e-02,  3.80638661e-03, -5.87030686e-02,\n         -5.48782572e-02,  5.67746488e-03,  5.20405471e-02,\n          3.02290302e-02, -4.18009236e-02, -1.92252956e-02,\n         -8.77626240e-02, -7.44123459e-02, -1.97425056e-02,\n         -2.27800291e-02,  6.78370520e-02,  4.86237481e-02,\n          8.62606056e-03,  4.33317712e-03,  2.68753674e-02,\n         -4.73292433e-02, -7.55642727e-02, -1.49960890e-02,\n         -1.28949462e-02,  1.08492479e-01,  9.11265379e-04,\n          4.91644209e-03,  3.23137753e-02,  3.79569782e-03,\n         -4.70688082e-02,  5.75121455e-02,  4.93656062e-02,\n         -2.04622336e-02, -9.19953268e-03, -3.99631150e-02,\n          3.41217145e-02,  2.85389535e-02, -9.67945084e-02,\n          5.88295702e-03, -3.57550681e-02,  5.11406735e-02,\n          1.68682784e-02,  2.46904325e-02, -1.09830275e-02,\n         -1.51833408e-02,  4.74344054e-03, -7.13607445e-02,\n         -2.83629857e-02,  6.25924245e-02, -3.14444751e-02,\n         -1.73900109e-02,  9.16249584e-03, -3.39119472e-02,\n          5.96587174e-02,  9.56843328e-03, -4.44071740e-02,\n          4.35817242e-03, -1.33674089e-02,  1.33461347e-02,\n          1.72455944e-02, -2.15201862e-02,  8.15541483e-04,\n          4.32058275e-02, -7.08327740e-02,  8.71240813e-03,\n          2.43350416e-02, -2.56964825e-02, -2.07283348e-02,\n         -1.57877468e-02, -2.17562430e-02, -3.66805047e-02,\n          1.61696877e-02, -1.60145164e-02, -7.55662052e-03,\n          4.44850847e-02, -1.21052684e-02, -1.61787577e-03,\n          8.55243057e-02,  3.41752991e-02,  4.14696783e-02,\n         -4.00446244e-02, -2.46945266e-02, -1.00895287e-02,\n         -2.10659839e-02, -4.14597653e-02, -6.17690273e-02,\n         -4.77524512e-02, -1.20746233e-02,  3.79999131e-02,\n          5.02212346e-02, -3.00417356e-02, -8.93474184e-03,\n          2.85919812e-02, -6.72202706e-02, -3.88382673e-02,\n          9.59740952e-02, -4.01798729e-03,  3.71834310e-03,\n          1.25917062e-01,  5.32465428e-02,  2.27315836e-02,\n          1.20497219e-01, -1.16984416e-02, -2.59130076e-02,\n          5.08596599e-02, -2.04635933e-02, -4.12773117e-02,\n         -1.32687893e-02, -3.04260831e-02, -6.70434758e-02,\n         -5.15842848e-02, -4.87198262e-03, -5.36765382e-02,\n          6.80294484e-02, -1.37671391e-02,  3.23861577e-02,\n         -4.32219356e-02,  2.11904179e-02, -2.45353878e-02,\n         -5.65711483e-02, -4.15406050e-03,  2.72380076e-02,\n         -2.49122810e-02,  7.44106155e-03, -2.24425755e-02,\n          5.21888174e-02,  5.72414622e-02,  3.40862735e-03,\n         -3.72873284e-02, -7.85884336e-02, -4.15704958e-02,\n          2.06675846e-02, -1.92462634e-02,  2.18758509e-02,\n          1.38418172e-02, -9.53884795e-04, -5.86649636e-03,\n          4.12383955e-03, -5.99373132e-02, -1.69991571e-02,\n         -6.02358766e-02,  4.54099923e-02, -1.54950935e-03,\n          5.86664192e-02, -6.12630434e-02, -5.72872683e-02,\n          9.01699997e-03, -4.49373201e-02, -7.80916167e-03,\n          2.36101877e-02, -7.22638667e-02,  2.66351607e-02,\n         -1.81452781e-02, -1.92704853e-02, -4.83294278e-02,\n         -1.59366746e-02,  6.33776039e-02, -8.34325477e-02,\n         -1.30429165e-02,  5.76250143e-02, -2.43405383e-02,\n         -4.23854664e-02,  3.13220434e-02, -3.42067741e-02,\n          8.75798403e-04, -3.19854058e-02,  3.36473286e-02,\n         -2.02035997e-02, -3.52885947e-02, -7.46875419e-04,\n         -4.17043753e-02,  8.06995109e-03, -4.04941104e-02,\n          7.54214376e-02,  3.27436775e-02,  4.83034141e-02,\n          8.65488797e-02,  1.10551596e-01, -6.09341152e-02,\n          6.35854825e-02,  4.10922244e-02,  1.02015063e-02,\n         -2.49726494e-04, -4.17725034e-02, -5.30127175e-02,\n         -6.97845295e-02,  2.29326803e-02,  7.79885203e-02,\n         -3.04070152e-02,  6.50236160e-02, -2.56194808e-02,\n          1.79090332e-02,  2.53073741e-02, -4.71319221e-02,\n         -5.97882904e-02,  4.83610332e-02,  5.86424023e-02,\n         -3.42016704e-02, -4.73901108e-02,  1.29030291e-02,\n         -3.20499912e-02, -3.66655625e-02,  2.86440551e-02,\n          2.59947274e-02,  6.99796751e-02,  2.20667925e-02,\n          1.65656605e-03,  7.19202384e-02, -6.96543790e-03,\n          5.18703274e-02, -5.44986948e-02, -4.49953089e-03,\n          2.46949103e-02,  4.67585661e-02, -2.26087752e-04,\n          8.76704790e-03, -8.21472481e-02,  3.84912007e-02,\n         -3.15408246e-03,  5.49777858e-02,  3.28569897e-02,\n         -3.93057652e-02,  4.31823619e-02,  1.33380473e-01,\n         -1.92613853e-03,  6.32649213e-02,  5.30280769e-02,\n         -1.08067594e-01, -2.26071151e-03,  7.02150632e-03,\n         -3.77884731e-02, -4.16366383e-02,  9.03472025e-03,\n         -1.82555262e-02, -8.15083738e-03, -7.19091147e-02,\n         -8.33873078e-03, -1.92042682e-02,  3.63842398e-02,\n         -4.29529026e-02, -2.63126642e-02, -2.18554232e-02,\n          2.56572701e-02, -9.80648696e-02,  4.07282151e-02,\n         -5.65268332e-03,  1.13120805e-02,  4.51234952e-02,\n          6.69792469e-04, -8.07662902e-04, -1.98359936e-02,\n          1.06797861e-02,  2.62206085e-02, -4.71390933e-02,\n         -1.64245330e-02,  4.35607918e-02, -9.17144716e-02,\n         -9.27074999e-02, -4.07371037e-02, -6.51422935e-03,\n          3.10861245e-02,  6.52507618e-02, -5.78719452e-02,\n          5.57684116e-02, -7.55873397e-02,  4.20075096e-02,\n          3.68594639e-02, -6.31313324e-02, -2.80952621e-02,\n          2.41068825e-02, -7.47254957e-03, -1.69691183e-02,\n         -8.35836157e-02,  1.95489321e-02, -6.65202364e-02,\n         -8.64687115e-02,  3.67235467e-02,  1.32571505e-02,\n         -3.77426622e-03, -2.10863464e-02, -1.83521584e-02,\n          6.87191915e-03,  3.48973051e-02, -8.03468749e-02,\n         -5.67846894e-02,  1.13952346e-01,  6.43740296e-02,\n         -5.79109043e-02, -1.51731605e-02,  1.02742225e-01,\n         -1.19616978e-01,  5.16187362e-02, -1.96533538e-02,\n         -9.31496918e-02, -1.05360681e-02, -2.62578763e-02,\n         -5.52635118e-02, -3.92824113e-02, -7.65289590e-02,\n         -8.99303481e-02, -1.63498087e-04, -2.31212862e-02,\n          2.37664245e-02,  9.93239041e-03, -2.01537199e-02,\n          3.89210954e-02,  1.15359845e-02, -1.17477989e-02,\n         -2.24192571e-02, -4.97634709e-02, -8.71734545e-02,\n         -6.49349466e-02, -3.08102611e-02,  4.32342887e-02,\n         -1.40480027e-01,  2.05821320e-02,  6.10188581e-02,\n          1.36393216e-02,  4.35007289e-02, -2.79208217e-02,\n          1.42507246e-02, -4.01592162e-03, -3.67731005e-02,\n          5.15582412e-02,  1.31263700e-03,  1.56449489e-02,\n         -4.36267443e-02,  1.48404120e-02, -8.64563584e-02,\n         -6.72861412e-02,  2.83950828e-02,  5.83387837e-02,\n          5.46614528e-02,  5.30380569e-02, -2.52548270e-02,\n          9.72724240e-03,  4.60697152e-02, -1.40084038e-02,\n          1.68053303e-02, -2.71093454e-02, -6.65631099e-03,\n         -3.31357494e-02,  4.31383029e-03, -1.25182038e-02,\n         -2.09015682e-02, -1.81845482e-02,  1.01634376e-01,\n          4.20524535e-04, -1.85084678e-02,  6.88987002e-02,\n         -2.47894209e-02, -1.15554417e-02, -1.27319025e-03,\n         -1.10386815e-02,  9.08984095e-02,  9.43534896e-02,\n          5.72930500e-02,  3.98411080e-02,  1.09721674e-02,\n          1.52262608e-02,  2.28965748e-03, -2.38983613e-02,\n          4.87479270e-02,  2.78639570e-02, -5.83971255e-02,\n          2.11926084e-03, -4.87754121e-03,  1.71191115e-02,\n          5.02002332e-03,  5.38686337e-03, -8.02108366e-03,\n          5.68121858e-03,  6.55848384e-02, -4.22543660e-02,\n          1.00163172e-03,  9.02504250e-02,  2.23305523e-02,\n          4.77165021e-02, -2.25288067e-02,  4.27905805e-02,\n          5.81918135e-02,  6.78675175e-02, -5.29759228e-02,\n         -5.90072072e-04,  3.50591913e-02, -5.81267215e-02,\n         -6.83769118e-04,  7.62375221e-02,  5.41984215e-02,\n         -1.20571731e-02, -5.86853512e-02, -3.12753255e-03,\n          6.87086582e-02, -1.44265089e-02,  4.68636230e-02,\n         -8.04067180e-02, -3.90746370e-02,  2.84557082e-02,\n         -6.56786608e-03, -1.47193223e-02, -3.20787951e-02,\n          1.02378882e-01, -4.02219733e-03, -4.46141586e-02,\n         -1.87530257e-02,  7.94119015e-02,  6.65943772e-02,\n          3.21351364e-02,  6.65896991e-03,  2.74323076e-02,\n          6.73901215e-02,  6.93745166e-02, -3.00192460e-02,\n          9.71012637e-02, -9.19788629e-02, -7.22132921e-02,\n         -6.73995838e-02, -2.53908876e-02,  4.77672815e-02,\n          2.91741616e-03,  3.77359763e-02, -8.16927943e-03,\n         -1.43468035e-02,  2.60846224e-02, -2.25695241e-02,\n         -1.49614615e-02, -1.62551012e-02, -9.68597084e-02,\n         -7.68219456e-02, -4.86684628e-02,  1.55867301e-02,\n         -5.57852834e-02, -3.21702585e-02,  5.08387722e-02,\n         -5.03042378e-02, -4.90134628e-03,  3.44502591e-02,\n         -2.45455634e-02, -1.45860715e-02,  6.12760894e-02,\n          9.34671331e-03, -9.74428654e-03,  2.40488779e-02,\n          3.70700918e-02, -5.76497018e-02, -8.66698660e-03,\n         -4.85682227e-02,  1.69028975e-02, -5.99942319e-02,\n          7.48242214e-02, -1.03157245e-01,  1.48261129e-03,\n         -5.68258855e-03, -4.57844278e-03, -1.02891736e-02,\n          3.37941758e-02, -6.68211142e-03, -6.41930625e-02,\n         -7.83313159e-03,  3.26648392e-02,  7.49321133e-02,\n         -4.15862314e-02, -1.08047649e-02,  6.45887339e-03,\n          5.36029115e-02,  5.00499606e-02,  5.41060045e-03,\n         -7.83868693e-03,  8.35185274e-02, -2.90624425e-02,\n         -1.08774460e-03, -7.17950985e-03,  2.56203078e-02,\n          4.18714881e-02,  5.56328446e-02]], dtype=float32)>,\n <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n array([[-6.80724457e-02,  1.05433844e-01, -3.08122225e-02,\n          5.28938696e-02, -7.27105662e-02,  1.68246459e-02,\n          3.93707007e-02,  1.03026092e-01,  2.63893567e-02,\n          4.20491435e-02, -3.24592665e-02, -1.75905719e-01,\n          4.75476123e-02,  5.46078291e-03,  7.28214309e-02,\n         -6.48056492e-02, -7.08627477e-02,  1.57310054e-01,\n         -1.20230928e-01,  1.62612677e-01,  6.84644133e-02,\n         -1.57215387e-01,  3.58504355e-02, -5.54359630e-02,\n         -1.31551211e-03,  1.77769195e-02,  7.86297023e-02,\n          9.82979760e-02, -3.35969053e-05, -1.42762652e-02,\n          1.53582711e-02, -1.69031367e-01, -1.13651186e-01,\n          1.09762207e-01,  7.19239563e-02, -1.37557490e-02,\n         -1.67242169e-01, -5.82238808e-02,  8.36144537e-02,\n          8.23996440e-02,  7.66405836e-03, -1.13456778e-01,\n         -1.11506380e-01,  1.15092685e-02,  1.01804733e-01,\n          5.84278107e-02, -8.50883275e-02, -3.73580568e-02,\n         -1.75271109e-01, -1.53318539e-01, -3.84736136e-02,\n         -4.39522117e-02,  1.38650700e-01,  9.43083614e-02,\n          1.72306169e-02,  8.64714850e-03,  5.60934916e-02,\n         -9.44756940e-02, -1.52671829e-01, -2.97765024e-02,\n         -2.62475852e-02,  2.21373945e-01,  1.94770796e-03,\n          9.85058770e-03,  6.43775761e-02,  7.76300160e-03,\n         -9.55890194e-02,  1.15539059e-01,  9.46575478e-02,\n         -4.08077240e-02, -1.78180318e-02, -7.82772452e-02,\n          7.00307414e-02,  5.53001426e-02, -1.95199147e-01,\n          1.13919638e-02, -7.35934898e-02,  1.04044572e-01,\n          3.35719511e-02,  4.95128222e-02, -2.08733696e-02,\n         -2.94384230e-02,  9.10153892e-03, -1.48947448e-01,\n         -5.54966405e-02,  1.29021645e-01, -6.41009733e-02,\n         -3.57889049e-02,  1.76461618e-02, -6.73641935e-02,\n          1.19084135e-01,  1.87722296e-02, -8.96744132e-02,\n          8.64546746e-03, -2.63834298e-02,  2.69282442e-02,\n          3.47938463e-02, -4.21451926e-02,  1.64128351e-03,\n          9.04505402e-02, -1.43210694e-01,  1.69886742e-02,\n          4.91995215e-02, -5.15077561e-02, -4.06062156e-02,\n         -3.25923674e-02, -4.38045450e-02, -7.57287815e-02,\n          3.23009044e-02, -3.31855193e-02, -1.52296443e-02,\n          9.18296129e-02, -2.46874988e-02, -3.19096306e-03,\n          1.74852848e-01,  6.83119744e-02,  8.41648579e-02,\n         -7.88874179e-02, -5.09792268e-02, -1.92559473e-02,\n         -4.03363146e-02, -8.70812684e-02, -1.28461957e-01,\n         -9.98985320e-02, -2.39480548e-02,  7.68952295e-02,\n          9.86391306e-02, -6.05359748e-02, -1.88927799e-02,\n          5.64046651e-02, -1.38390496e-01, -7.78060108e-02,\n          1.89037338e-01, -7.99504109e-03,  7.51796365e-03,\n          2.62717664e-01,  1.09460816e-01,  4.59787734e-02,\n          2.41177052e-01, -2.38617212e-02, -5.25596775e-02,\n          9.94227752e-02, -3.99921089e-02, -8.01036954e-02,\n         -2.55517885e-02, -6.26759380e-02, -1.37519091e-01,\n         -1.03486285e-01, -9.93615109e-03, -1.10212043e-01,\n          1.33610427e-01, -2.71624010e-02,  6.55963719e-02,\n         -8.46247971e-02,  4.22615819e-02, -5.25068343e-02,\n         -1.11826710e-01, -8.19596276e-03,  5.50672263e-02,\n         -5.03403693e-02,  1.52137503e-02, -4.49925810e-02,\n          9.90505666e-02,  1.17561653e-01,  6.74886676e-03,\n         -7.11062700e-02, -1.58545643e-01, -8.50505754e-02,\n          4.19247746e-02, -3.68929952e-02,  4.36577834e-02,\n          2.81070936e-02, -1.94670598e-03, -1.19486749e-02,\n          8.04275833e-03, -1.15790889e-01, -3.48328128e-02,\n         -1.19464971e-01,  9.03063118e-02, -3.11685377e-03,\n          1.16656110e-01, -1.22083351e-01, -1.17513552e-01,\n          1.70533452e-02, -9.01247263e-02, -1.54833188e-02,\n          4.60598022e-02, -1.46470606e-01,  5.34240156e-02,\n         -3.63392420e-02, -3.78078818e-02, -9.88970920e-02,\n         -3.24820355e-02,  1.26521483e-01, -1.65992394e-01,\n         -2.57078744e-02,  1.18356675e-01, -4.90335003e-02,\n         -8.46693292e-02,  6.34094775e-02, -6.78622574e-02,\n          1.74579048e-03, -6.26590848e-02,  6.28833547e-02,\n         -4.10398804e-02, -7.30092451e-02, -1.51171884e-03,\n         -8.68231207e-02,  1.60461403e-02, -8.06221664e-02,\n          1.51811406e-01,  6.18771687e-02,  9.54037458e-02,\n          1.70523286e-01,  2.24045724e-01, -1.19926602e-01,\n          1.32857740e-01,  8.54813680e-02,  2.06002332e-02,\n         -4.82689880e-04, -8.42366368e-02, -1.03723779e-01,\n         -1.36180431e-01,  4.58167791e-02,  1.59480184e-01,\n         -5.86838536e-02,  1.30806386e-01, -4.97460254e-02,\n          3.73923033e-02,  5.07718250e-02, -9.23077315e-02,\n         -1.20890118e-01,  9.68120247e-02,  1.13352135e-01,\n         -6.79568201e-02, -9.45280045e-02,  2.48114187e-02,\n         -6.30971417e-02, -7.66304806e-02,  5.83256371e-02,\n          5.06986976e-02,  1.40628502e-01,  4.41315286e-02,\n          3.32079991e-03,  1.39649242e-01, -1.40200369e-02,\n          1.01805076e-01, -1.08569801e-01, -9.23090242e-03,\n          4.88948822e-02,  9.81561840e-02, -4.43961995e-04,\n          1.71908885e-02, -1.60567537e-01,  7.50626326e-02,\n         -6.29325397e-03,  1.12237640e-01,  6.45579472e-02,\n         -7.73799866e-02,  8.38555247e-02,  2.68652618e-01,\n         -4.00917558e-03,  1.24832198e-01,  1.08467720e-01,\n         -2.21171916e-01, -4.72470559e-03,  1.39725544e-02,\n         -7.58551508e-02, -8.25723782e-02,  1.79489274e-02,\n         -3.78434807e-02, -1.67794116e-02, -1.47508964e-01,\n         -1.61994100e-02, -3.84291708e-02,  7.31000602e-02,\n         -8.64509642e-02, -5.34988753e-02, -4.26788554e-02,\n          5.18247560e-02, -2.09585220e-01,  8.18686038e-02,\n         -1.17581403e-02,  2.23168656e-02,  8.98767859e-02,\n          1.30427943e-03, -1.66677579e-03, -3.98077816e-02,\n          2.10955627e-02,  5.32868244e-02, -9.13675651e-02,\n         -3.39419730e-02,  8.76937881e-02, -1.81425422e-01,\n         -1.94307476e-01, -8.04801062e-02, -1.30883763e-02,\n          6.00747950e-02,  1.37086764e-01, -1.14200309e-01,\n          1.11879453e-01, -1.53817728e-01,  8.37791562e-02,\n          7.54794478e-02, -1.26788437e-01, -5.88313974e-02,\n          4.68421057e-02, -1.44597534e-02, -3.48176360e-02,\n         -1.72812968e-01,  3.98658402e-02, -1.31171837e-01,\n         -1.78753585e-01,  7.27939159e-02,  2.67050695e-02,\n         -7.90406391e-03, -4.10927832e-02, -3.63078788e-02,\n          1.34883039e-02,  6.93965703e-02, -1.67030066e-01,\n         -1.12797052e-01,  2.31901139e-01,  1.25419229e-01,\n         -1.09898135e-01, -3.03995013e-02,  2.01546863e-01,\n         -2.41085798e-01,  1.07816279e-01, -3.82252149e-02,\n         -1.91535473e-01, -2.08987240e-02, -4.97610159e-02,\n         -1.07707605e-01, -8.36765915e-02, -1.51949868e-01,\n         -1.82449684e-01, -3.25804140e-04, -4.62172106e-02,\n          4.72434461e-02,  1.99654028e-02, -3.93369496e-02,\n          7.80893117e-02,  2.28898544e-02, -2.38118786e-02,\n         -4.53805700e-02, -9.83528942e-02, -1.80658937e-01,\n         -1.31398797e-01, -6.10123873e-02,  8.55753124e-02,\n         -2.72249550e-01,  4.09183763e-02,  1.24149561e-01,\n          2.65766792e-02,  8.81030411e-02, -5.48469946e-02,\n          2.78003067e-02, -7.92055205e-03, -7.38049299e-02,\n          1.05213128e-01,  2.63528316e-03,  3.25462185e-02,\n         -8.35696682e-02,  3.07102762e-02, -1.69308111e-01,\n         -1.30100965e-01,  5.52183688e-02,  1.15356103e-01,\n          1.10217296e-01,  1.07290879e-01, -4.98115122e-02,\n          1.92051716e-02,  9.29789543e-02, -2.71348134e-02,\n          3.31758410e-02, -5.39502390e-02, -1.31824017e-02,\n         -6.80318773e-02,  8.53454135e-03, -2.56266147e-02,\n         -4.32578959e-02, -3.61205414e-02,  2.11293012e-01,\n          8.27236101e-04, -3.72033268e-02,  1.38741374e-01,\n         -4.98389825e-02, -2.25483477e-02, -2.52095331e-03,\n         -2.23816410e-02,  1.80341497e-01,  1.86610579e-01,\n          1.18176743e-01,  8.02987963e-02,  2.21827626e-02,\n          3.06467395e-02,  4.58117761e-03, -4.86289635e-02,\n          9.79239792e-02,  5.76123670e-02, -1.19184189e-01,\n          4.25364636e-03, -1.01990495e-02,  3.57394852e-02,\n          1.02597028e-02,  1.08226854e-02, -1.53270634e-02,\n          1.13168657e-02,  1.30489439e-01, -8.12115073e-02,\n          1.89905160e-03,  1.85200870e-01,  4.45038378e-02,\n          9.23673511e-02, -4.39198166e-02,  8.29525739e-02,\n          1.16280824e-01,  1.38758957e-01, -1.04975767e-01,\n         -1.21537060e-03,  6.98601827e-02, -1.16878793e-01,\n         -1.27094099e-03,  1.47434965e-01,  1.08655915e-01,\n         -2.42723841e-02, -1.23310059e-01, -6.09734096e-03,\n          1.37490481e-01, -2.89038941e-02,  9.73005295e-02,\n         -1.70340091e-01, -7.38643259e-02,  5.88987768e-02,\n         -1.32447006e-02, -2.92298049e-02, -6.39339164e-02,\n          2.05607727e-01, -7.89650157e-03, -8.88695121e-02,\n         -3.87500674e-02,  1.64745003e-01,  1.37366936e-01,\n          6.37446791e-02,  1.32213626e-02,  5.57773747e-02,\n          1.38215646e-01,  1.37361273e-01, -5.87405190e-02,\n          1.93282127e-01, -1.80261880e-01, -1.48972973e-01,\n         -1.36833712e-01, -5.18562682e-02,  9.57656875e-02,\n          5.88589301e-03,  7.53502324e-02, -1.64803546e-02,\n         -2.76353694e-02,  5.17879017e-02, -4.56225909e-02,\n         -3.15286294e-02, -3.14168446e-02, -2.03698263e-01,\n         -1.55331761e-01, -9.84091759e-02,  3.04927081e-02,\n         -1.11088805e-01, -6.45534545e-02,  9.77114812e-02,\n         -1.02136597e-01, -1.01067070e-02,  6.85761124e-02,\n         -5.11738919e-02, -2.93361302e-02,  1.25623882e-01,\n          1.83144026e-02, -1.89990774e-02,  4.74390015e-02,\n          7.12810159e-02, -1.14139192e-01, -1.74336918e-02,\n         -9.72460955e-02,  3.40916924e-02, -1.15393788e-01,\n          1.55288056e-01, -1.99093968e-01,  3.01608955e-03,\n         -1.18096340e-02, -9.36697982e-03, -2.05034520e-02,\n          6.63701668e-02, -1.39494454e-02, -1.33564293e-01,\n         -1.61455292e-02,  6.51668310e-02,  1.46813303e-01,\n         -8.68741423e-02, -2.24377383e-02,  1.33375069e-02,\n          1.05534442e-01,  1.05242208e-01,  1.06086181e-02,\n         -1.60714593e-02,  1.71651542e-01, -5.68548441e-02,\n         -2.22301437e-03, -1.42907780e-02,  5.12968116e-02,\n          8.46969485e-02,  1.13311067e-01]], dtype=float32)>]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(example_input, initial_state=[cell_state, hidden_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 512])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 12, 512])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 512) (1, 512)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "output, hidden_state = rnn_layer(example_input)\n",
    "print(type(output))\n",
    "print(output.shape, hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 1024)\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "output = bidirectional_rnn(example_input)\n",
    "print(type(output))\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer2 = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "mod = tf.keras.Sequential()\n",
    "mod.add(rnn_layer1)\n",
    "mod.add(rnn_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 512])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "rnn_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "))\n",
    "mod = tf.keras.Sequential()\n",
    "mod.add(rnn_layer1)\n",
    "mod.add(rnn_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 1024])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(example_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Case study: IMBD\n",
    "Klasyfikacja tekstu przy użyciu RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "maxlen = 50\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])]\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "print(x_train[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zwróćmy uwagę w powyższym, że ciągi zaczynają się zawsze od \"1\" - jest to oznaczenie początku zdania. Czyli \"początek zdania\" będzie miał swój embedding.\n",
    "\n",
    "Standaryzacja długości sekwencji (Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `sequence.pad_sequences` not found.\n"
     ]
    }
   ],
   "source": [
    "?sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      "    2   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117    2   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194    2   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30    2   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16    2   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "x_train = utils.pad_sequences(x_train, maxlen=maxlen, padding=\"pre\")\n",
    "x_test = utils.pad_sequences(x_test, maxlen=maxlen, padding=\"pre\")\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_train = 3000\n",
    "n_test = 500\n",
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "x_test = x_test[:n_test]\n",
    "y_test = y_test[:n_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(3000,)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "(3000, 400)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Zwykła sieć rekurencyjna ( z embeddingami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    SimpleRNN,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    GRU\n",
    ")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "vocab_size = max_features #jak wczytywalismy dane to ustawilismy ze maks 5000 slow\n",
    "output_dim = 512"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    max_features,\n",
    "    50,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=64,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(rnn_layer)\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 50)          250000    \n",
      "                                                                 \n",
      " simple_rnn_17 (SimpleRNN)   (None, 64)                7360      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,425\n",
      "Trainable params: 257,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5140WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 4s 38ms/step - loss: 0.6962 - accuracy: 0.5140\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.6997WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.6344 - accuracy: 0.6997\n",
      "Epoch 3/3\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.4478 - accuracy: 0.8753WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 4s 39ms/step - loss: 0.4467 - accuracy: 0.8753\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28b9d7e80>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6938501000404358, 0.5839999914169312]"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Od trenera"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 300)         1500000   \n",
      "                                                                 \n",
      " simple_rnn_18 (SimpleRNN)   (None, 256)               142592    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,642,849\n",
      "Trainable params: 1,642,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 300))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7101 - accuracy: 0.5087WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 30s 314ms/step - loss: 0.7101 - accuracy: 0.5087\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.5697WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 29s 307ms/step - loss: 0.6815 - accuracy: 0.5697\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6410WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 29s 311ms/step - loss: 0.6416 - accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x298e1af20>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6722758412361145, 0.5339999794960022]"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Simple RNN + dense pomiędzy zwracanym wyjściem z RNN a outputem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, None, 300)         1500000   \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, 256)               142592    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,708,641\n",
      "Trainable params: 1,708,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.5090WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 27s 276ms/step - loss: 0.7448 - accuracy: 0.5090\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7534 - accuracy: 0.5020WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 38s 403ms/step - loss: 0.7534 - accuracy: 0.5020\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.5243WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 31s 332ms/step - loss: 0.7273 - accuracy: 0.5243\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7444236278533936, 0.49000000953674316]"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 300))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size, )\n",
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dwukierunkowa sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=512))\n",
    "#                                                   , activation=\"tanh\",\n",
    "#     recurrent_dropout=0.0,\n",
    "#     return_sequences=True,\n",
    "#     return_state=False,\n",
    "# ))\n",
    "# output = bidirectional_rnn(example_input)\n",
    "# print(type(output))\n",
    "# print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 300)         1500000   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 1024)             832512    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,333,537\n",
      "Trainable params: 2,333,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 300))\n",
    "model.add(bidirectional_rnn)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.5190WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 82s 856ms/step - loss: 0.7252 - accuracy: 0.5190\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7161 - accuracy: 0.5023WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 84s 897ms/step - loss: 0.7161 - accuracy: 0.5023\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5357WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 91s 963ms/step - loss: 0.6947 - accuracy: 0.5357\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28b919ba0>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6811016201972961, 0.5799999833106995]"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Zadanie. Powtórz powyższe modele z komórką LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 300)         1500000   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 1024)             3330048   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,831,073\n",
      "Trainable params: 4,831,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 300))\n",
    "model.add(lstm)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 251s 3s/step - loss: 0.6975 - accuracy: 0.5737\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7510WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 266s 3s/step - loss: 0.5326 - accuracy: 0.7510\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.8703WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 284s 3s/step - loss: 0.3044 - accuracy: 0.8703\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x289f5fcd0>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5122829675674438, 0.7839999794960022]"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dwuwarstwowa sieć rekurencyjna"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "rnn_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 300)         1500000   \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, None, 1024)       2500608   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 1024)             4724736   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,726,369\n",
      "Trainable params: 8,726,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 300))\n",
    "model.add(rnn_layer1)\n",
    "model.add(rnn_layer2)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.5893WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 560s 6s/step - loss: 0.7120 - accuracy: 0.5893\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.7937WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "94/94 [==============================] - 622s 7s/step - loss: 0.4520 - accuracy: 0.7937\n",
      "Epoch 3/3\n",
      "67/94 [====================>.........] - ETA: 3:04 - loss: 0.2427 - accuracy: 0.9025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [143]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2451\u001B[0m   (graph_function,\n\u001B[1;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1863\u001B[0m     args,\n\u001B[1;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1865\u001B[0m     executing_eagerly)\n\u001B[1;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CNN a tekst\n",
    "\n",
    "Mając sekwencję możemy zamiast wykorzystywać RNN skorzystać z jednowymiarowej konwolucji. W tym przypadku rozmiar kernela(jądra) decyduje o tym na ile chwil czasowych jednocześnie patrzy CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GlobalAveragePooling2D()(tf.zeros((16, 32,32,3))).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Zadanie\n",
    "korzystając z warstwy `tf.keras.layers.Conv1D` i jakiejś warstwy poolingowej zastąpić w poprzednim modelu RNN siecią CNN.\n",
    "Argumenty są takie same jak dla konwolucji 2D tylko `kernel_size` i `strides` mogą być tylko liczbami całkowitymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 15:25:08.127780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:08.171478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:08.172010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:08.173406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-08 15:25:08.176239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:08.176915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:08.177460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:09.473984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:09.474441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:09.474454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-08 15:25:09.474878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-08 15:25:09.474927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3947 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GlobalAveragePooling2D()(tf.zeros((16, 32,32,3))).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=5))\n",
    "model.add(Conv1D(64, kernel_size=5))\n",
    "model.add(Conv1D(128, kernel_size=5))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Case Study\n",
    "Utwórz model, który identyfikuje emocje wpisu na twiterze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dane/tweet_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     tweet_id   sentiment                                            content\n0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n2  1956967696     sadness                Funeral ceremony...gloomy friday...\n3  1956967789  enthusiasm               wants to hang out with friends SOON!\n4  1956968416     neutral  @dannycastillo We want to trade with someone w...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>wants to hang out with friends SOON!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = data['content'].tolist()\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def preprocess_tweets(sent):\n",
    "    outsent = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",sent).split())\n",
    "    outsent = outsent.lower()\n",
    "    return outsent\n",
    "\n",
    "import re\n",
    "\n",
    "X = [preprocess_tweets(elem) for elem in X]\n",
    "\n",
    "\n",
    "# Tworzymy warstwe tokenizującą\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=5000, output_mode=\"int\"\n",
    ")\n",
    "# Dopasujemy tokenizator do danych\n",
    "vectorize_layer.adapt(X) #tworzy słownik\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_label = le.fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(X), y_label, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 50\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 3\n",
    "early = EarlyStopping(patience=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, None, 256)         82176     \n",
      "                                                                 \n",
      " global_average_pooling1d_3   (None, 256)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 419,469\n",
      "Trainable params: 419,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1013/1013 [==============================] - 5s 5ms/step - loss: 2.0286 - sparse_categorical_accuracy: 0.2959 - val_loss: 1.9247 - val_sparse_categorical_accuracy: 0.3497\n",
      "Epoch 2/100\n",
      "1013/1013 [==============================] - 5s 4ms/step - loss: 1.8293 - sparse_categorical_accuracy: 0.3786 - val_loss: 1.9048 - val_sparse_categorical_accuracy: 0.3514\n",
      "Epoch 3/100\n",
      "1013/1013 [==============================] - 5s 5ms/step - loss: 1.7118 - sparse_categorical_accuracy: 0.4193 - val_loss: 1.9480 - val_sparse_categorical_accuracy: 0.3508\n",
      "Epoch 4/100\n",
      "1013/1013 [==============================] - 4s 4ms/step - loss: 1.6031 - sparse_categorical_accuracy: 0.4544 - val_loss: 2.0173 - val_sparse_categorical_accuracy: 0.3433\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2972a2560>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(max_features, 64, input_length=10))\n",
    "\n",
    "model.add(Conv1D(256, 5))\n",
    "# model.add(Conv1D(64, kernel_size=5))\n",
    "# model.add(Conv1D(128, kernel_size=5))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[2.0025696754455566, 0.3330000042915344]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1024)             590848    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 977,293\n",
      "Trainable params: 977,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1013/1013 [==============================] - 65s 63ms/step - loss: 2.1881 - sparse_categorical_accuracy: 0.2077 - val_loss: 2.1708 - val_sparse_categorical_accuracy: 0.2142\n",
      "Epoch 2/100\n",
      "1013/1013 [==============================] - 64s 63ms/step - loss: 2.1566 - sparse_categorical_accuracy: 0.2115 - val_loss: 2.1603 - val_sparse_categorical_accuracy: 0.2092\n",
      "Epoch 3/100\n",
      "1013/1013 [==============================] - 58s 57ms/step - loss: 2.1520 - sparse_categorical_accuracy: 0.2127 - val_loss: 2.1685 - val_sparse_categorical_accuracy: 0.2075\n",
      "Epoch 4/100\n",
      "1013/1013 [==============================] - 55s 54ms/step - loss: 2.1521 - sparse_categorical_accuracy: 0.2138 - val_loss: 2.1613 - val_sparse_categorical_accuracy: 0.2075\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28c9f71f0>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=512))\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(max_features, 64, input_length=10))\n",
    "\n",
    "model.add(bidirectional_rnn)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[2.1383774280548096, 0.2175000011920929]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "rnn_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 1024)       1775616   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1024)             4724736   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,886,797\n",
      "Trainable params: 6,886,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1013/1013 [==============================] - 444s 434ms/step - loss: 1.9942 - sparse_categorical_accuracy: 0.3079 - val_loss: 1.9081 - val_sparse_categorical_accuracy: 0.3525\n",
      "Epoch 2/5\n",
      "1013/1013 [==============================] - 439s 433ms/step - loss: 1.8378 - sparse_categorical_accuracy: 0.3715 - val_loss: 1.8924 - val_sparse_categorical_accuracy: 0.3550\n",
      "Epoch 3/5\n",
      "1013/1013 [==============================] - 380s 375ms/step - loss: 1.7388 - sparse_categorical_accuracy: 0.4054 - val_loss: 1.9232 - val_sparse_categorical_accuracy: 0.3489\n",
      "Epoch 4/5\n",
      "1013/1013 [==============================] - 532s 526ms/step - loss: 1.6303 - sparse_categorical_accuracy: 0.4434 - val_loss: 1.9846 - val_sparse_categorical_accuracy: 0.3300\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x298556350>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(max_features, 64, input_length=10))\n",
    "\n",
    "model.add(rnn_layer1)\n",
    "model.add(rnn_layer2)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.9611717462539673, 0.3317500054836273]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Contextual embeddings\n",
    "Przy użyciu sieci rekurencyjnych można tworzyć embeddingi, które uwzględniają kontekst w jakim użyte jest dane słowo. Istnieje wiele słów, które jak są wykorzystane bez kontekstu nie można jednoznacznie określić ich znaczenia(np. zamek jako budowla i jako zapięcie kurtki). W związku z tym wykorzystuje się modele sekwencyjne, które modelują słowo w zależności od jego \"otoczenia\"\n",
    "##### ELMo\n",
    "Model ELMo wykorzsytuje sieci Bidirectional RNN do reprezentacji kontekstu\n",
    "\n",
    "![](Grafika/Bert-language-modeling.png)\n",
    "\n",
    "Działanie ELMo\n",
    "\n",
    "![](Grafika/elmo-forward-backward-language-model-embedding.png)\n",
    "\n",
    "![](Grafika/elmo-embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = [\"ELMo lives on sesame street.\"]\n",
    "\n",
    "# Extract ELMo features\n",
    "embeddings = elmo(tf.constant(x))[\"elmo\"]\n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_elmo_embeddings = elmo(tf.constant(X[:100]))[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_elmo_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_elmo = Sequential()\n",
    "model_elmo.add(Bidirectional(GRU(512)))\n",
    "model_elmo.add(Dense(512, activation=\"relu\"))\n",
    "model_elmo.add(Dropout(0.4))\n",
    "model_elmo.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_elmo.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_elmo.fit(\n",
    "    X_elmo_embeddings,\n",
    "    y_label[:100],\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_split=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Seq2Seq\n",
    "Modele Seq2Seq składają się z dwóch modeli sekwencyjnych, zazwyczaj pierwszy nazywa się `encoder` a drugi `decoder`. Zazwyczaj sekwencje wejściowe i wyjściowe mogą być różnej długości.\n",
    "Przykłady zastosowań\n",
    "* Machine translation\n",
    "* Table summarization\n",
    "* Image captioning\n",
    "* Document Summarization\n",
    "* Question Answering(np. chatboty)\n",
    "* Speech recognition\n",
    "\n",
    "![](Grafika/seq2seq-teacher-forcing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aby utworzy takie modele trzeba już korzystać z functional API w Kerasie, ponieważ tutaj nie mamy prostego liniowego potoku zmiennych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Spacy i problemy lingwistyczne\n",
    "spacy jest biblioteką zawierającą wiele modeli do problemów lingwistycznych, które teraz sobie krótko omówimy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### tokenizacja\n",
    "spacy także posiada tokenizacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# wczytywanie modelu językowego\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Akash has been buyed by byju's in 73,000 Core's\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    print(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Part-Of_Speech (POS) - tagging\n",
    "problem ten polega na wyjaśnieniu w jaki sposób dane słowo jest wykorzystane w zdaniu. Ustalone jest 8 części mowy (po ang bo będzie łatwiej):\n",
    "* Noun\n",
    "* Pronoun\n",
    "* Adjective\n",
    "* Verb\n",
    "* Adverb\n",
    "* Preposition\n",
    "* Conjunction\n",
    "* Interjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"We are currently learning about Spacy\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the token and its part-of-speech tag\n",
    "    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"We are currently learning about Spacy\")\n",
    "spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dependency Parsing\n",
    "Jest to proces tworzenia struktury gramatycznej zdania. Daje on nam zależność słów w zdaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"We are currently learning about Spacy\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"-->\", token.dep_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Named Entity Recogniton\n",
    "Czyli po prostu wykrywanie nazw własnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\n",
    "    \"Reliance is looking at buying U.K. based analytics startup for $7 billion\"\n",
    ")\n",
    "# See the entity present\n",
    "print(f\"Enitites: {doc.ents}\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Entity Recogniton\n",
    "nazywane też Entity Detection jest bardziej zaawansowany od NER, ponieważ rozpoznaje istotne elementy między innymi miejsca, ludzi, organizacje, języki itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\n",
    "    \"\"\"The Amazon rainforest,[a] alternatively, the Amazon Jungle, also known in English as Amazonia, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km2 (2,700,000 sq mi), of which 5,500,000 km2 (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations.\n",
    "\n",
    "The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Bolivia, Ecuador, French Guiana, Guyana, Suriname, and Venezuela. Four nations have \"Amazonas\" as the name of one of their first-level administrative regions and France uses the name \"Guiana Amazonian Park\" for its rainforest protected area. The Amazon represents over half of the planet's remaining rainforests,[2] and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.[3]\n",
    "\n",
    "Etymology\n",
    "The name Amazon is said to arise from a war Francisco de Orellana fought with the Tapuyas and other tribes. The women of the tribe fought alongside the men, as was their custom.[4] Orellana derived the name Amazonas from the Amazons of Greek mythology, described by Herodotus and Diodorus.[4]\n",
    "\n",
    "History\n",
    "See also: History of South America § Amazon, and Amazon River § History\n",
    "Tribal societies are well capable of escalation to all-out wars between tribes. Thus, in the Amazonas, there was perpetual animosity between the neighboring tribes of the Jivaro. Several tribes of the Jivaroan group, including the Shuar, practised headhunting for trophies and headshrinking.[5] The accounts of missionaries to the area in the borderlands between Brazil and Venezuela have recounted constant infighting in the Yanomami tribes. More than a third of the Yanomamo males, on average, died from warfare.[6]\"\"\"\n",
    ")\n",
    "\n",
    "entities = [(i, i.label_, i.label) for i in doc.ents]\n",
    "entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Transformers\n",
    "Transformery wywołały ogromny przełom w NLP, są one w stanie modelować relacje między dowolnie odległymi chwilami czasu i są szybsze ponieważ nie wymagają pętli(wystarcza tylko mnożenie wektorów i macierzy)\n",
    "\n",
    "![](Grafika/transformer.png)\n",
    "\n",
    "Czym jest `Positional Encoding`? Istnieją dwie szkoły tworzenia\n",
    "* Uczymy embeddingi pozycji razem z modelem, czyli `Positional Encoding` jest parameterem modelu o ustalonej długości\n",
    "* Wykorzystujemy z góry zdefiniowaną funkcję np.\n",
    "\\begin{align*}\n",
    "  p_{i,j}=\n",
    "  \\begin{cases}\n",
    "    \\sin\\left(\\frac{i}{10000^{j/d}}\\right)\\\\\n",
    "    \\cos\\left(\\frac{i}{10000^{(j-1)/d}}\\right)\n",
    "  \\end{cases}\n",
    "\\end{align*}\n",
    "gdzie $i$-chwila czasu, $j$-j'ty wymiar w wektorze positional encodingu, $d$-wymiar positional encodingu.\n",
    "\n",
    "Positional Encoding jest potrzebny, żeby model był w stanie modelować dane wejściowe jako sekwencje, w przeciwnym wypadku, pozycja w której umieścimy token/wartość w chwili czasu nie ma żadnego znaczenia.\n",
    "\n",
    "Nakładamy maskę, żeby wyliczać atencję tylko na podstawie tokenów/chwil czasu, które chcemy, żeby model brał pod uwagę. Np. podczas uczenia generatora tekstu, będziemy maskowali wszystkie następne tokeny, ponieważ nie chcemy, żeby model genrował token na podstawie przyszłych tokenów, natomiast w przypadku klasyfikacji tekstu już taka maska nie jest potrzebna. Podczas trenowania nakłada też się zawsze maskę na tokeny odpowiadające paddingowi.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bibliografia\n",
    "#### Sieci rekurencyjne\n",
    "* [RNN i LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [ELMo-Embeddingi z kontekstem](https://arxiv.org/abs/1802.05365v2)\n",
    "* [BERT ELMo zilustrowane](https://jalammar.github.io/illustrated-bert/)\n",
    "* [Bahdanau Attention](https://arxiv.org/abs/1508.04025)\n",
    "#### Transformery\n",
    "* [Artykuł wprowadzający transformery](https://arxiv.org/abs/1706.03762)\n",
    "* [Wizualizacje działania transformerów](https://jalammar.github.io/illustrated-transformer/)\n",
    "* [BERT](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tematy\n",
    "### Sub-word tokenizers:\n",
    "* [Byte-Pair Encoding](https://arxiv.org/abs/1508.07909)\n",
    "* [WordPiece](https://ai.googleblog.com/2021/12/a-fast-wordpiece-tokenization-system.html)\n",
    "* [Unigram Language Model](https://arxiv.org/pdf/1804.10959.pdf)\n",
    "* [SentencePiece](https://jacky2wong.medium.com/understanding-sentencepiece-under-standing-sentence-piece-ac8da59f6b08)\n",
    "### Embeddingi\n",
    "* [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [FastText](https://arxiv.org/pdf/1607.04606.pdf)\n",
    "* [Doc2Vec](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "## Biblioteki:\n",
    "* [NLTK](https://www.nltk.org/)\n",
    "* [Spacy](https://spacy.io/)\n",
    "* [FastText](https://fasttext.cc/)\n",
    "* [Hugging face tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)\n",
    "* [Gensim](https://radimrehurek.com/gensim/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('szkolenie_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a302268556b76bf77dc7022fbbfe64be1f040e8595120b70fc62fd06ed875dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}