{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizacja\n",
    "\n",
    "Poważnym problemem jest w jaki sposób tworzyć tokeny z tekstu:\n",
    "* znaki oddzielone spacjami?\n",
    "* znaki oddzielone na znakach interpunkcyjnych?\n",
    "* rozdzielanie na podstawie regexów?\n",
    "* inne metody?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oddzielanie spacjami\n",
    "jest to najprostszy sposób, ale też nie najlepszy, ponieważ np. słowo \"won't\" będzie jednym tokenem a samo \"n't\" można też dodać jako oddzielny token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oddzielanie na znakach interpunkcyjnych i spacjach\n",
    "Tutaj dodatkowo rozdzielamy spacją wszystkie znaki interpunkcyjne czyli np. \"Ala ma psa.\" -> \\[\"Ala\", \"ma\", \"psa\", \".\"\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oddzielanie na regexach\n",
    "jest to połączenie poprzednich metod i dodanie specjalnych fraz np. oddzielanie \"n't\" w języku angielskim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mchraba/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'did', \"n't\", 'want', 'to', 'come', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I didn't want to come.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium,\"\n",
    "    \" totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. \"\n",
    "    \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui \"\n",
    "    \"ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, \"\n",
    "    \"sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis \"\n",
    "    \"nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit \"\n",
    "    \"qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.',\n",
       " 'Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.',\n",
       " 'Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem.',\n",
       " 'Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur?',\n",
       " 'Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subwords tokenization\n",
    "Wszystkie poprzednie metody mają problem z nowymi słowami, które mogą się pojawić podczas tokenizacji nowego tekstu. W przypadku poprzednich metod zastępuje się zazwyczaj słowa nie występujące w słowniku przez \"\\<unk\\>\". \n",
    "\n",
    "Kolejnym problemem jest wielkość słownika, im więcej słów chcemy posiadać tym większy musi być nasz słownik co prowadzi do coraz większych wymagań pamięciowych w celu operowania na tekstach. \n",
    "\n",
    "Problemy te są rozwiązywane przez tokenizatory, który dokonują podziału na tokeny, które nie są całymi słowami tylko ich fragmentami. W takich modelach z góry określa się wielkość słownika. Oczywiście powstaje pytanie jak wybierać ciągu znaków, które będą tokenami.\n",
    "\n",
    "Warto na nie zwrócić uwagę bo wszystkie aktualnie najlepsze modele językowe oparte o sieci neuronowe z nich korzystają ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'have', 'a', 'new', 'gp', '##u', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.tokenize(\"I have a new GPU!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z biblioteką [tokenizers](https://huggingface.co/docs/tokenizers/python/latest/) dodać wiele różnych rzeczy jak dodawanie specjalnych tokenów na początek koniec, wiele innych pretokenizatorów i wiele innych gotowych tokenizatorów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizacja w Kerasie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 09:18:20.727444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:20.764624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:20.765081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:20.766150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-10 09:18:20.768370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:20.768818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:20.769253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:21.898490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:21.898954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:21.898968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-10 09:18:21.899400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 09:18:21.899462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3947 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tokenization_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = [\"foo\", \"bar\", \"baz\"]\n",
    "max_features = 5000\n",
    "max_len = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.TextVectorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy warstwe tokenizującą\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_features, output_mode=\"int\",\n",
    ")\n",
    "# Dopasujemy tokenizator do danych\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'foo', 'baz', 'bar']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 1, 1, 1, 1, 2],\n",
       "       [1, 3, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jako pierwszą warstwę dajemy nasz tokenizator\n",
    "\n",
    "\n",
    "# Teraz nasz model na wejściu będzie akceptował teksty\n",
    "input_data = [[\"foo qux bar asf aljhg kljalk hbkla foo\"], [\"qux baz\"]]\n",
    "model.predict(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprezentacja słów i sieci neuronowe czyli embeddingi\n",
    "Embeddingi polegają na zmniejszeniu wymiaru danych tekstowych, aby zakodować ciąg słów o słowniku wielkości 50000 tworzymy macierz o wymiarach seq_len x 50000, co można się domyślić nie jest optymalne, embeddingi sprowadzają dane tekstowe do dużo niższego wymiaru np. 300.\n",
    "\n",
    "Przykładami embeddingów są:\n",
    "* Word2Vec\n",
    "* GloVe\n",
    "* FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "Metody uczenia \n",
    "\n",
    "![Word2vec image](Grafika/word2vec_diagrams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podobieństwo słów\n",
    "Mając embeddingi słów można badać ich podobieństwo badając ich odległość w przestrzeni, w której się znajdują. Najczęściej wykorzystuje się do tego odległość cosinusową\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{cos\\_sim}(A,B) = \\frac{A\\cdot B}{||A||||B||}=cos(\\theta)\n",
    "\\end{align*}\n",
    "\n",
    "która pokazuje jaki jest kąt między dwoma wektorami, jeżeli 0 wtedy mamy 1 i oznacza to że wektory są tak samo skierowane czyli są podobne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = (5000, 100)\n",
    "word = (0,0,0,..., 1,..., 0)\n",
    "word * W = W[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    [\"this\", \"is\", \"the\", \"first\", \"sentence\", \"for\", \"word2vec\"],\n",
    "    [\"this\", \"is\", \"the\", \"second\", \"sentence\"],\n",
    "    [\"yet\", \"another\", \"sentence\"],\n",
    "    [\"one\", \"more\", \"sentence\"],\n",
    "    [\"and\", \"the\", \"final\", \"sentence\"],\n",
    "]\n",
    "# size: (default 100) wymiar przestrzeni embeddingów.\n",
    "# window: (default 5) okno które będzie wykorzystywane do predykcji lub będzie predykowane.\n",
    "# min_count: (default 5) minimalna liczba wystąpień słowa aby było uwzględnione w słowniku.\n",
    "# workers: (default 3) liczba wątków wykorzystana do uczenia.\n",
    "# sg: (default 0 or CBOW) jaki algorytm ma być wykorzystany do uczenia 0-CBOW, 1-Skip-gram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7fc7b2921460>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 0,\n",
       " 'the': 1,\n",
       " 'is': 2,\n",
       " 'this': 3,\n",
       " 'final': 4,\n",
       " 'and': 5,\n",
       " 'more': 6,\n",
       " 'one': 7,\n",
       " 'another': 8,\n",
       " 'yet': 9,\n",
       " 'second': 10,\n",
       " 'word2vec': 11,\n",
       " 'for': 12,\n",
       " 'first': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.key_to_index.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv[\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 0,\n",
       " 'the': 1,\n",
       " 'is': 2,\n",
       " 'this': 3,\n",
       " 'final': 4,\n",
       " 'and': 5,\n",
       " 'more': 6,\n",
       " 'one': 7,\n",
       " 'another': 8,\n",
       " 'yet': 9,\n",
       " 'second': 10,\n",
       " 'word2vec': 11,\n",
       " 'for': 12,\n",
       " 'first': 13}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence',\n",
       " 'the',\n",
       " 'is',\n",
       " 'this',\n",
       " 'final',\n",
       " 'and',\n",
       " 'more',\n",
       " 'one',\n",
       " 'another',\n",
       " 'yet',\n",
       " 'second',\n",
       " 'word2vec',\n",
       " 'for',\n",
       " 'first']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.wv[words]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] == model.wv[\"sentence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformed = PCA(2).fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_transformed[:, 0], x_transformed[:, 1])\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(x_transformed[i, 0], x_transformed[i, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wczytywanie gotowych embeddingów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = downloader.load(\"glove-wiki-gigaword-100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698540687561035),\n",
       " ('monarch', 0.6843381524085999),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = glove_vectors.most_similar(\n",
    "    positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5\n",
    ")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.7735227942466736),\n",
       " ('physician', 0.7189430594444275),\n",
       " ('doctors', 0.6824328303337097),\n",
       " ('patient', 0.6750683188438416),\n",
       " ('dentist', 0.6726033091545105)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = glove_vectors.most_similar(\n",
    "    positive=[\"woman\", \"doctor\"], negative=['man'], topn=5\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors[\"i\", \"have\", \"a\"].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddingi fasttext\n",
    "W Word2Vec tworzymy embeddingi słów w celu stworzenia embeddingu więc nie jesteśmy w stanie otrzymać embeddingu słowa spoza naszego słownika. Fasttext inaczej pochodzi do tworzenia embeddingów, ponieważ słowa, które są do siebie podobne(co do ogległości edycyjnej) powinny mieć podobne embeddingi postanowiono tworzyć je na podstawie n-gramów na znakach (dla n od 3 do 6). Jak to działa?\n",
    "1) Dodajemy na początek słowa '<' a na koniec '>'.\n",
    "\n",
    "![](Grafika/fasttext-angular-brackets.png)\n",
    "\n",
    "2) tworzymy n-gramy dla słowa.\n",
    "3) Ponieważ liczba n-gramów może być ogromna dlatego, zamiast trenować embeddingi dla każdego unikatowego n-grama, trenowane jest B (B-bucket size). Każdy n-gram jest przetwarzany przy użyciu funkcji hashującej do liczby całkowitej między 1 a B.\n",
    "4) Do słownika dodajemy także słowa, które występują w zbiorze treningowym. Zatem mamy B+|V| embeddingów.\n",
    "\n",
    "#### Jak trenowany jest fasttext?\n",
    "\n",
    "Embeddingi są trenowane wykorzystując skip-gram z negatywnym próbkowaniem. Czyli na podstawie słowa chcemy przewidzieć słowa sąsiadujące. Ale embedding słowa na podstawie, którego chcemy przewidywać to suma n-gramów i embeddingu tego słowa.\n",
    "\n",
    "![](Grafika/fasttext-negative-sampling-goal.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "Doc2Vec jest wykorzystaniem podobnego pomysłu co Word2Vec. Czyli na podstawie contekstu przewidujemy słowo. Ale skąd tutaj embedding dokumentu? Dodany jest dodatkowo embedding paragrafu jak na zdjęciu poniżej. Z dodatkiem tego embeddingu trenowany jest model  PV-DM(Distributed Memory version of Paragraph Vector) lub PV-DBOW(Words version of Paragraph Vector) (Podobny model do skip-gram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Grafika/doc2vec_dbow.png) \n",
    "![](Grafika/doc2vec_skip_gram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zdobyć embedding nowego dokumentu? W tym celu zamrażane są wszystkie wagi sieci i jedyną zmienną jest embedding dokumentu, następnie ta zmienna jest aktualizowana trenując ją jak PV-DM lub PV-DBOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możliwe też jest z wykorzystaniem Doc2Vec modelowanie gatunków. Zamiast unikatowego id można dodawać(dodatkowo lub jako jedyne wejście) tag związany z kategorią. W ten sposób otrzymamy embeddingi kategorii i po wyznaczeniu embeddingu danego dokumentu możemy powiedzieć do której kategorii on najprawdopodobniej należy.\n",
    "\n",
    "![](Grafika/doc2vec_tag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Tutaj możemy też podać kategorie\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[parametry klasy Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html#introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.infer_vector([\"human\", \"interface\", \"computer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.7519353628158569),\n",
       " (0, 0.38346174359321594),\n",
       " (2, 0.23076751828193665),\n",
       " (6, 0.22709029912948608),\n",
       " (5, 0.10591179132461548),\n",
       " (7, 0.004431864712387323),\n",
       " (3, -0.2476314902305603),\n",
       " (1, -0.638149082660675),\n",
       " (8, -0.7812461853027344)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv.most_similar(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7056741"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity_unseen_docs([\"human\", \"response\"], [\"computer\", \"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b480b8933f078b9bb649a28ef31ddb4e88638560591c0b6b6c9f25971fe4507f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
