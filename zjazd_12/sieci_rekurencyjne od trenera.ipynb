{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem klasyfikacji sekwencji\n",
    "\n",
    "Dane to ciągi różnych długości, np. tekst, muzyka, film.\n",
    "* Elementami ciągów są “obiekty bazowe”\n",
    "  * Tekst - ciąg słów (ogólniej - tokenów)\n",
    "  * Film - ciąg obrazów\n",
    "  * Muzyka - ciąg dźwięków\n",
    "* Uwaga 1: elementy ciągów są od siebie zależne!\n",
    "* Uwaga 2: kolejność elementów jest istotna!\n",
    "* Jak można pracować z ciągami?\n",
    "  * Sprowadzić ciągi do reprezentacji wektorowej i użyć\n",
    "  klasycznych metod uczenia maszynowego\n",
    "  * Użyć metod dedykowanych do takich danych - na przykład sieci rekurencyjnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Modele Sekwencyjne i ich zastosowania\n",
    "Modelem sekwencyjnym nazwiemy model, który jako wejście otrzymuje sekwencję, ale nie musi zwracać sekwencji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci rekurencyjne\n",
    "Zasadą działania sieci rekurencyjnej jest przechowywanie wyjścia poprzedniego elementu i wykorzystania go w kolejnym kroku.\n",
    "\n",
    "Dlaczego po prostu do sekwencji nie wykorzystać zwykłych gęstych sieci neuronowych?\n",
    "* Nie są w stanie przetwarzać sekwencji o różnych długościach\n",
    "* Biorą pod uwagę tylko aktualne dane wejściowe\n",
    "* Nie zapamiętują informacji o poprzednich danych wejściowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "Podstawową wersją sieci rekurencyjnej jest RNN(recurrent Neural Network)\n",
    "$$ h_t = \\text{tanh}(Wx_t+Uh_{t-1}+b) $$\n",
    "![](Grafika/RNN-unrolled.png)\n",
    "\n",
    "Zalety:\n",
    "* Możliwość przetwarzania sekwencji o dowolnej długości\n",
    "* Rozmiar modelu nie rośnie razem z długością sekwencji\n",
    "* Bierze pod uwagę poprzednie stany\n",
    "\n",
    "Wady:\n",
    "* Wolne obliczenia\n",
    "* Problem wykorzystywania bardzo odległych stanów\n",
    "* Nie może brać pod uwagę przyszłych stanów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddingi słów\n",
    "Przeanalizujmy co się dzieje w sieci, gdy\n",
    "podajemy słowa w reprezentacji _one hot_:\n",
    "$$ h_t = f(W^h \\cdot h_{t-1}+W^x\\cdot x_t +b)$$\n",
    "Jeśli $x_t$ to _one-got_ z jedynką na pozycji i to \n",
    "$$W^x\\cdot x_t=W^x \\cdot [0,\\dots, 1_i,\\dots, 0]^T=W^x[:,i]$$\n",
    "Zatem przekształcenie to jest równoważne wzięciu i'tej kolumny macierzy wag.\n",
    "\n",
    "Czyli i-ta kolumna macierzy wag jest w pewnym sensie reprezentacją słowa i-tego.\n",
    "\n",
    "Zatem pójdźmy krok dalej: stwórzmy dodatkową warstwę w sieci - macierz \n",
    "embeddingów EMB, zawierającą reprezentacje słów, które będą\n",
    "przekazywane do wyliczenia stanu ukrytego\n",
    "\\begin{align*}\n",
    "    &emb_t=EMB\\cdot x_t=EMB[:,i]\\\\\n",
    "    &h_t=f(W^h \\cdot h_{t-1}+W^x\\cdot emb_t +b)\n",
    "\\end{align*}\n",
    "\n",
    "Embeddingi są parametrami sieci, ale\n",
    "jednocześnie reprezentacją słów.\n",
    "Oznacza to, że trenując sieć, uczymy\n",
    "\n",
    "embeddingi, czyli uczymy się reprezentacji słów!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele sekwencyjne można podzielić na kilka przykładów\n",
    "### One-to-many, wejście o długości jednostkowej, wyjście o długości > 1. \n",
    "Przykład: generacja tekstu\n",
    "   \n",
    "![](Grafika/rnn-one-to-many-ltr.png)\n",
    "\n",
    "### Many-to-one\n",
    "przykład klasyfikacja sentymentu\n",
    "\n",
    "![](Grafika/rnn-many-to-one-ltr.png)\n",
    "\n",
    "### Many-to-many (tyle samo wejść co wyjść)\n",
    "przykład: NER(named entity recognition)\n",
    "![](Grafika/rnn-many-to-many-same-ltr.png)\n",
    "\n",
    "### Many-to-many\n",
    "przykład tłumaczenie maszynowe\n",
    "\n",
    "![](Grafika/rnn-many-to-many-different-ltr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem odległych informacji relewantnych\n",
    "Rozważmy problem predykcji następnego słowa po “the clouds\n",
    "are in the __”\n",
    "\n",
    "Jest to dość proste zadanie, bo odpowiedź można łatwo\n",
    "wywnioskować na podstawie tych kilku słów.\n",
    "\n",
    "W takich przypadkach zwykła sieć RNN jest odpowiednią\n",
    "strukturą.\n",
    "\n",
    "![](Grafika/RNN-shorttermdepdencies.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próba przewidzenia “[I grew up in France… . I speak fluent ___”\n",
    "wymaga sięgnięcia wstecz dalej niż kilka słów.\n",
    "\n",
    "Ostatnie słowa sugerują tylko, że następne słowo jest nazwą języka -\n",
    "odgadnięcie, że chodzi o francuski, wymaga odnalezienia”France”.\n",
    "\n",
    "W praktyce dystans do relewantnej informacji często jest duży, a w\n",
    "miarę wzrostu tego dystansu, zwykła sieć RNN staje się niezdolna do\n",
    "wyłapania tych zależności.\n",
    "\n",
    "![](Grafika/RNN-longtermdependencies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksplodujący/Zanikający gradient\n",
    "Problem ten często spotyka się podczas korzystania z RNN. Wynika to z tego, że podczas wyliczania gradientu przemnażamy przez siebie wielokrotnie gradienty dla danych chwil czasowych w związku z tym może on zacząć zanikać(jak przemnażamy małe wartości), albo \"wybuchnąć\"(jak przemnażamy duże wartości).\n",
    "\n",
    "Jak sobie poradzić z tym problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "Sieci Long Short Term Memory – zazwyczaj\n",
    "krótko “LSTM”.\n",
    "Hochreiter & Schmidhuber, 1997 (!)\n",
    "\n",
    "Są szczególnym rodzajem sieci\n",
    "rekurencyjnych zaprojektowane tak, aby\n",
    "zwiększyć skuteczność wykrywania\n",
    "długodystansowych zależności.\n",
    "\n",
    "### RNN\n",
    "![](Grafika/LSTM3-SimpleRNN.png)\n",
    "\n",
    "### LSTM\n",
    "![](Grafika/LSTM3-chain.png)\n",
    "![](Grafika/LSTM2-notation.png)\n",
    "\n",
    "Gdzie $\\sigma$ to aktywacja sigmoid.\n",
    "\n",
    "Zatem jak można zauważyć LSTM posiada dwie \"ścieżki\" pamięci. Pierwszą jest tak zwany \"cell state\"\n",
    "![](Grafika/LSTM3-C-line.png)\n",
    "Ze względu na to, że ma on tylko liniowe interakcje łatwo jest o przepływ informacji tą scieżką. LSTM ma możliwość usuwania i dodawania informacji do tej ścieżki, co jest decydowanie przez tak zwane bramki(gates). Decydują one o tym czy dana informacją powinna dalej przejść\n",
    "\n",
    "![](Grafika/LSTM3-gate.png)\n",
    "\n",
    "Ponieważ sigmoida zwraca wartości między 0 a 1 decyduje jak \"dużo\" informacji powinno przepłynąć dalej.\n",
    "\n",
    "#### LSTM krok po kroku\n",
    "W pierwszym kroku decydujemy jak wiele aktualnej informacji powinno zostać w cell state.\n",
    "\n",
    "![](Grafika/LSTM3-focus-f.png)\n",
    "\n",
    "Następnie decydujemy jak wiele nowej informacji powinniśmy dodać do cell state\n",
    "\n",
    "![](Grafika/LSTM3-focus-i.png)\n",
    "\n",
    "Dokonujemy aktualizacji cell state\n",
    "\n",
    "![](Grafika/LSTM3-focus-C.png)\n",
    "\n",
    "Na koniec wybieramy interesujące nas informacje z zakutalizowanego cell state, które zostaną zwrócone przez LSTM\n",
    "\n",
    "![](Grafika/LSTM3-focus-o.png)\n",
    "\n",
    "### Istnieją jeszcze inne warianty LSTM np. wykorzystujące cell state do bramek\n",
    "\n",
    "![](Grafika/LSTM3-var-peepholes.png)\n",
    "\n",
    "i takie, które wykorzystują jedną bramkę do zapominania/dodawania informacji do cell state\n",
    "\n",
    "![](Grafika/LSTM3-var-tied.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU a LSTM\n",
    "GRU jest kolejną siecią rekurencyjną, której celem jest rozwiązanie odległych relacji między momentami czasu\n",
    "\n",
    "![](Grafika/gru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked RNN\n",
    "\n",
    "![](Grafika/stacked_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN\n",
    "Czasem może nas interesować nie tylko infromacja z lewej do prawej ale także w drugą stronę, np. podczas klasyfikacji tekstu, w związku z tym aby otrzymać Biderctional RNN łączymy wyniki z dwóch sieci RNN, jedna \"czyta\" od lewej do prawej, a druga w drugą stronę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 10:56:53.225086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.232256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.232669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.233379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-10 10:56:53.235732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.236179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.236574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.798037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.798445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.798458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-10 10:56:53.798837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-10 10:56:53.798876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3947 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "example_input = tf.ones((1, 12, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12, 2), dtype=float32, numpy=\n",
       "array([[[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 512) (1, 512)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "output, hidden_state = rnn_layer(example_input)\n",
    "print(type(output))\n",
    "print(output.shape, hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 1024)\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "output = bidirectional_rnn(example_input)\n",
    "print(type(output))\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mvocab_size\u001b[49m,\n\u001b[1;32m      3\u001b[0m     output_dim,\n\u001b[1;32m      4\u001b[0m     embeddings_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     embeddings_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     activity_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     embeddings_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     mask_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     input_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    vocab_size,\n",
    "    output_dim,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    "    **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do warstwy Embedding możemy podać przetrenowane wcześniej embeddingi. Muszą one być wcześniej przygotowane jako macierz o wymiarach (vocab_size x embedding_dim). Oraz i'ty wiersz, musi odpowiadać embeddingowi tokenu, który przekształacmy na liczbę `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding_matrix = np.array(range(10*30)).reshape((10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29],\n",
       "       [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59],\n",
       "       [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
       "         73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "         86,  87,  88,  89],\n",
       "       [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "        116, 117, 118, 119],\n",
       "       [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "        146, 147, 148, 149],\n",
       "       [150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
       "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
       "        176, 177, 178, 179],\n",
       "       [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "        206, 207, 208, 209],\n",
       "       [210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "        236, 237, 238, 239],\n",
       "       [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "        266, 267, 268, 269],\n",
       "       [270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "        283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = tf.keras.layers.Embedding(\n",
    "    10,\n",
    "    30,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(pretrained_embedding_matrix),\n",
    "    embeddings_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    embeddings_constraint=None,\n",
    "    mask_zero=False,\n",
    "    input_length=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 30), dtype=float32, numpy=\n",
       "array([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,\n",
       "          10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,\n",
       "          20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.],\n",
       "        [270., 271., 272., 273., 274., 275., 276., 277., 278., 279.,\n",
       "         280., 281., 282., 283., 284., 285., 286., 287., 288., 289.,\n",
       "         290., 291., 292., 293., 294., 295., 296., 297., 298., 299.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedding(np.array([[0,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 11:04:22.093312: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "lstm(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 12, 512]), TensorShape([1, 512]), TensorShape([1, 512]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = tf.keras.layers.LSTM(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "out, cell_state, hidden_state = lstm(example_input)\n",
    "out.shape, cell_state.shape, hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 12, 512), dtype=float32, numpy=\n",
       " array([[[ 9.8077089e-02, -4.1555081e-02, -2.3201019e-02, ...,\n",
       "          -2.7695877e-02,  3.2766566e-02, -3.3441110e-04],\n",
       "         [ 9.8540857e-02, -4.2712249e-02, -2.3906732e-02, ...,\n",
       "          -2.7826820e-02,  3.2997672e-02,  9.2046765e-05],\n",
       "         [ 9.8867767e-02, -4.3699343e-02, -2.4513017e-02, ...,\n",
       "          -2.7938776e-02,  3.3198118e-02,  4.1465153e-04],\n",
       "         ...,\n",
       "         [ 9.9724382e-02, -4.7378272e-02, -2.6810193e-02, ...,\n",
       "          -2.8409336e-02,  3.3902276e-02,  1.0597191e-03],\n",
       "         [ 9.9784233e-02, -4.7606535e-02, -2.6954010e-02, ...,\n",
       "          -2.8445369e-02,  3.3928175e-02,  1.0441197e-03],\n",
       "         [ 9.9840038e-02, -4.7790918e-02, -2.7069727e-02, ...,\n",
       "          -2.8475612e-02,  3.3942550e-02,  1.0199380e-03]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       " array([[ 9.98400375e-02, -4.77909185e-02, -2.70697270e-02,\n",
       "         -3.12656015e-02,  7.51215443e-02,  1.62024964e-02,\n",
       "         -6.32817000e-02,  2.15880796e-02, -3.92201170e-02,\n",
       "          2.98010055e-02, -4.03088033e-02, -5.22137806e-03,\n",
       "          8.77030566e-02, -8.14547688e-02,  6.71865493e-02,\n",
       "          2.96283010e-02,  3.08108386e-02,  3.08334101e-02,\n",
       "          3.74826416e-02, -3.48165892e-02, -3.56040290e-03,\n",
       "         -3.32098939e-02, -5.97227179e-02, -4.06116918e-02,\n",
       "          1.73697975e-02,  1.50568960e-02, -1.24802282e-02,\n",
       "         -5.76004237e-02,  4.34756186e-03, -4.56475802e-02,\n",
       "         -6.37311041e-02,  1.81531323e-05,  9.66329500e-02,\n",
       "          4.78429422e-02, -3.61271715e-03, -3.70898508e-02,\n",
       "          5.63954152e-02,  4.70672213e-02,  1.58536490e-02,\n",
       "          7.92648941e-02, -6.89448565e-02,  3.51917371e-02,\n",
       "         -6.12847023e-02,  2.80600227e-02,  1.18750622e-02,\n",
       "          1.45695861e-02, -4.82036322e-02, -4.81915548e-02,\n",
       "         -2.90570222e-03,  3.60572077e-02,  8.61968249e-02,\n",
       "          7.62406215e-02, -2.13790499e-02, -1.38305426e-02,\n",
       "         -3.73746902e-02,  2.89813187e-02,  6.39740974e-02,\n",
       "          1.25269098e-02, -8.72696638e-02, -4.50797528e-02,\n",
       "          1.32055329e-02,  1.87484212e-02,  1.91414636e-02,\n",
       "         -2.38385797e-02, -6.58552125e-02,  3.15827131e-02,\n",
       "         -4.43343036e-02,  7.22169802e-02, -4.20539416e-02,\n",
       "         -6.23963363e-02, -2.55158003e-02,  1.00944173e-02,\n",
       "         -3.77062857e-02,  1.52759403e-02, -9.02083293e-02,\n",
       "          6.88845962e-02,  3.83063555e-02,  4.14163433e-02,\n",
       "          4.57872674e-02, -2.72390451e-02, -9.61653441e-02,\n",
       "          3.94139513e-02, -1.71320569e-02, -1.95372254e-02,\n",
       "          3.18279415e-02,  3.30918692e-02, -2.33843997e-02,\n",
       "         -4.80211675e-02, -3.08809616e-02,  6.54994026e-02,\n",
       "         -1.33701172e-02,  4.36964165e-03,  6.21714927e-02,\n",
       "         -5.64625748e-02, -4.03836034e-02,  4.10728678e-02,\n",
       "          1.16132997e-01,  1.05391994e-01, -7.03393444e-02,\n",
       "          1.10337712e-01,  2.53709350e-02,  1.37900831e-02,\n",
       "         -3.58073926e-03,  7.09408894e-02,  2.86092553e-02,\n",
       "         -7.11089000e-02,  9.34274644e-02,  1.29881781e-03,\n",
       "          3.49936299e-02,  1.85491610e-02, -2.92578451e-02,\n",
       "         -8.52011610e-03, -8.70004520e-02, -2.07066201e-02,\n",
       "         -2.36642994e-02, -1.16259150e-01,  1.83562431e-02,\n",
       "         -2.58216821e-03, -4.65361541e-03,  4.36528362e-02,\n",
       "         -6.16553426e-02,  8.08570907e-02,  8.33580717e-02,\n",
       "         -1.55544868e-02,  2.84004305e-02,  1.42723229e-02,\n",
       "          7.07031414e-02,  3.68208205e-03, -4.90807742e-02,\n",
       "         -2.31350213e-02,  8.73792097e-02,  7.85114318e-02,\n",
       "         -5.85345365e-02, -2.05206543e-05, -8.89194291e-03,\n",
       "         -2.41872743e-02,  2.50453241e-02, -4.99789901e-02,\n",
       "         -2.66499016e-02,  5.29787280e-02,  7.69494027e-02,\n",
       "         -1.92048326e-02, -2.79393103e-02,  6.49545342e-02,\n",
       "         -9.92261395e-02, -1.00099379e-02, -3.78695340e-03,\n",
       "          1.00785099e-01,  8.18358064e-02,  2.29645781e-02,\n",
       "          4.32928186e-03, -2.45679952e-02,  1.59083419e-02,\n",
       "          7.22865462e-02,  2.51601990e-02, -4.56174724e-02,\n",
       "         -2.73380745e-02,  4.44097631e-02,  6.81028813e-02,\n",
       "          3.77035625e-02, -9.66675207e-02,  6.60603046e-02,\n",
       "         -2.75352281e-02,  5.36699779e-02,  3.23714018e-02,\n",
       "          3.85643356e-02,  3.84388529e-02,  5.46489982e-03,\n",
       "         -1.69598442e-02,  6.81248009e-02, -3.11766546e-02,\n",
       "         -3.77560928e-02,  2.06666924e-02,  4.17621620e-03,\n",
       "          5.90423821e-03, -9.83429477e-02, -1.37852356e-02,\n",
       "         -4.84263226e-02,  3.10528930e-02,  1.72763448e-02,\n",
       "          3.68652120e-02, -7.49837011e-02, -3.99299897e-02,\n",
       "         -1.43476035e-02, -4.79664281e-02, -7.80248316e-03,\n",
       "          3.31827067e-03,  1.92886442e-02,  2.34796237e-02,\n",
       "         -4.84996550e-02,  6.27711266e-02, -7.75514841e-02,\n",
       "         -4.43550088e-02,  1.95680521e-02, -7.17076473e-03,\n",
       "         -2.69853640e-02,  2.68297829e-02,  4.03522775e-02,\n",
       "          5.69885299e-02, -2.34903526e-02,  9.61309299e-03,\n",
       "          3.56180742e-02,  2.41266424e-03,  4.80289496e-02,\n",
       "         -1.88215077e-02,  9.87748709e-03,  2.47981139e-02,\n",
       "          5.17343469e-02, -6.81029186e-02, -2.48887986e-02,\n",
       "          5.41869439e-02,  8.84171517e-04, -1.48327015e-02,\n",
       "         -2.19350699e-02,  3.38217728e-02,  1.47204129e-02,\n",
       "         -3.91743220e-02,  1.53811248e-02, -7.59939775e-02,\n",
       "          2.97882892e-02,  1.66254006e-02, -8.48323200e-03,\n",
       "          7.72844627e-02, -2.39402466e-02, -1.07012531e-02,\n",
       "         -6.93337545e-02, -4.67566289e-02, -4.73210067e-02,\n",
       "         -6.75482955e-03,  4.12369333e-02, -9.34645534e-02,\n",
       "          4.99356091e-02,  4.01416831e-02,  8.81769601e-03,\n",
       "         -1.03387795e-02, -5.44520887e-03,  3.38125043e-02,\n",
       "          8.21424499e-02,  2.06149910e-02,  3.88640389e-02,\n",
       "          4.62901294e-02, -1.88370626e-02, -2.47545931e-02,\n",
       "          6.50590798e-03, -3.54576409e-02,  3.69495191e-02,\n",
       "         -1.08650580e-01,  4.72168177e-02, -1.00500979e-01,\n",
       "          3.53877395e-02,  1.39539940e-02,  6.65991530e-02,\n",
       "          5.55828772e-02,  3.63812856e-02,  7.84538407e-03,\n",
       "         -4.02339734e-02, -3.29232737e-02,  3.69050577e-02,\n",
       "         -6.55789748e-02,  2.02858578e-02,  8.73519629e-02,\n",
       "          3.60550880e-02, -1.00699611e-01, -4.22034925e-03,\n",
       "          3.90882194e-02, -7.25425687e-03,  2.44265348e-02,\n",
       "         -1.28375748e-02, -7.75579410e-03,  1.20034911e-01,\n",
       "         -5.25210649e-02,  7.43125891e-03,  4.09887545e-02,\n",
       "         -2.93431766e-02, -2.72114109e-02,  6.03213720e-02,\n",
       "         -6.11428060e-02, -3.37855481e-02,  7.62233511e-02,\n",
       "         -5.47880717e-02,  5.54687232e-02, -3.90942581e-02,\n",
       "         -2.50541046e-02, -6.36392310e-02,  8.50405544e-03,\n",
       "         -6.12073950e-03,  5.34152277e-02, -9.29508805e-02,\n",
       "          2.02741809e-02,  2.33712923e-02,  1.19803213e-01,\n",
       "          5.04100882e-02,  3.13031897e-02,  2.45322883e-02,\n",
       "          5.16609587e-02, -8.71707723e-02,  3.36066820e-02,\n",
       "         -4.04036306e-02, -1.96459927e-02, -3.85607332e-02,\n",
       "          3.46400291e-02, -3.33624482e-02, -3.88830788e-02,\n",
       "         -6.86207935e-02, -2.19131466e-02, -2.26796381e-02,\n",
       "         -1.83023396e-03, -6.51518852e-02,  1.94081888e-02,\n",
       "         -3.10771517e-03,  3.22753638e-02,  7.71194771e-02,\n",
       "         -6.89191371e-02, -7.87022784e-02, -2.54604239e-02,\n",
       "         -5.59860915e-02,  3.14664803e-02, -3.68749211e-03,\n",
       "         -2.50614733e-02, -9.22778845e-02,  3.86069678e-02,\n",
       "         -2.21380126e-02,  6.73622936e-02, -7.02567324e-02,\n",
       "          1.86817143e-02, -5.98722622e-02,  1.72530748e-02,\n",
       "          3.47330491e-03,  5.14938980e-02,  2.22108476e-02,\n",
       "          4.79164533e-02, -5.37575036e-02, -2.21018679e-02,\n",
       "         -7.75822476e-02, -3.62020801e-03,  1.16085084e-02,\n",
       "          4.04428169e-02,  1.87056772e-02, -8.60544443e-02,\n",
       "          9.64068323e-02, -9.89799723e-02, -7.19545707e-02,\n",
       "         -1.79197434e-02,  1.63250249e-02,  9.52150151e-02,\n",
       "         -1.07958540e-02,  4.36986051e-02,  6.21863939e-02,\n",
       "          1.36242164e-02, -3.70397754e-02, -2.53074523e-02,\n",
       "          7.40622878e-02, -7.50199407e-02,  5.23289032e-02,\n",
       "         -5.29658422e-03, -7.14984611e-02, -5.59054688e-03,\n",
       "         -6.30173311e-02,  8.66448283e-02, -8.92245919e-02,\n",
       "          1.58932165e-03,  5.52601255e-02,  6.05434505e-03,\n",
       "          4.41685095e-02, -3.02686244e-02, -2.22633313e-02,\n",
       "          3.55686247e-02, -9.99750942e-03,  4.23247973e-03,\n",
       "          2.74859462e-02, -3.57376151e-02, -7.81340376e-02,\n",
       "         -2.79856119e-02, -1.70509843e-03, -2.93352231e-02,\n",
       "         -1.54646498e-03, -2.38844082e-02,  1.72441658e-02,\n",
       "         -2.84356787e-03, -2.24046521e-02,  6.96352050e-02,\n",
       "          1.85891818e-02, -6.40475424e-03,  5.45124244e-03,\n",
       "          2.45122276e-02,  3.83085012e-02, -3.82142961e-02,\n",
       "          3.42675438e-03, -2.65812203e-02, -3.24807204e-02,\n",
       "          3.40005830e-02, -1.00976214e-01, -5.22795692e-02,\n",
       "          8.61752927e-02, -3.30426507e-02, -6.76372740e-03,\n",
       "          1.35838315e-01,  3.89326364e-02, -3.02688871e-03,\n",
       "          3.66257355e-02,  2.05726083e-02,  2.44334452e-02,\n",
       "          1.35644982e-02,  5.22223003e-02,  5.22213019e-02,\n",
       "         -3.64797823e-02,  1.25715807e-02,  7.55674541e-02,\n",
       "          7.31751183e-03,  5.91173023e-02,  7.24381441e-03,\n",
       "         -5.47103360e-02, -1.48357349e-02, -4.56403680e-02,\n",
       "         -4.67483439e-02, -4.94107828e-02, -4.11233716e-02,\n",
       "          1.07746404e-02,  1.26409782e-02, -2.79248673e-02,\n",
       "          2.48913392e-02,  2.06744112e-02, -1.75024364e-02,\n",
       "         -1.65943580e-03,  5.88205531e-02,  1.09898418e-01,\n",
       "         -2.32033711e-02, -4.51424904e-02, -4.62307855e-02,\n",
       "         -4.27396446e-02,  1.17554134e-02, -4.35705744e-02,\n",
       "         -7.61836246e-02, -1.10847913e-01, -1.88031178e-02,\n",
       "          1.08823152e-02, -3.27133536e-02, -2.78202072e-03,\n",
       "         -3.16066407e-02,  8.68385360e-02, -2.14272290e-02,\n",
       "          2.14871746e-02,  5.92830367e-02, -3.80975083e-02,\n",
       "         -1.04438355e-02, -1.70051033e-04,  1.63378345e-03,\n",
       "          5.11773974e-02, -2.56324708e-02, -5.77298133e-03,\n",
       "          7.47914659e-03,  2.90888827e-02,  7.94026777e-02,\n",
       "         -3.36074233e-02,  7.70294107e-03, -3.40709984e-02,\n",
       "          1.62368249e-02, -5.03637688e-03, -4.98920567e-02,\n",
       "         -1.08766267e-02,  5.71369892e-03,  7.58727863e-02,\n",
       "          1.42505486e-02,  4.12552767e-02, -3.55809554e-02,\n",
       "         -2.13903543e-02,  1.85743421e-02, -3.83483828e-03,\n",
       "          7.32108206e-02,  3.01672351e-02, -4.89552766e-02,\n",
       "         -7.12844804e-02,  3.65250073e-02, -5.01818135e-02,\n",
       "          6.77673221e-02, -3.52318026e-02,  6.28455430e-02,\n",
       "          4.36049365e-02,  3.66078466e-02, -3.15808915e-02,\n",
       "          9.61595550e-02,  3.07083409e-02, -6.22756295e-02,\n",
       "         -2.20497269e-02,  5.70441559e-02, -5.11872582e-02,\n",
       "         -5.78839257e-02,  6.04373068e-02,  6.50615171e-02,\n",
       "         -4.43626978e-02,  2.13549398e-02, -2.19831821e-02,\n",
       "          6.87908530e-02, -1.39199123e-02, -3.46459858e-02,\n",
       "         -3.97498272e-02, -8.20657387e-02, -6.89403787e-02,\n",
       "          8.05743560e-02, -6.28974885e-02,  5.91900200e-02,\n",
       "         -6.25170441e-03,  1.13854157e-02,  3.84316780e-02,\n",
       "          3.89806330e-02,  5.46379462e-02,  7.16158971e-02,\n",
       "          6.80038845e-03, -1.75415240e-02, -2.84756124e-02,\n",
       "          3.39425504e-02,  1.01993803e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       " array([[ 2.00161159e-01, -9.80243683e-02, -5.34316525e-02,\n",
       "         -6.26498461e-02,  1.57244578e-01,  3.36930379e-02,\n",
       "         -1.24680638e-01,  4.28975709e-02, -7.78946280e-02,\n",
       "          5.94877861e-02, -8.16078484e-02, -1.01842005e-02,\n",
       "          1.81913495e-01, -1.60424754e-01,  1.40566453e-01,\n",
       "          5.95173202e-02,  6.05837107e-02,  5.90363741e-02,\n",
       "          7.72839710e-02, -7.01183900e-02, -7.08489167e-03,\n",
       "         -6.50436729e-02, -1.25775352e-01, -8.16535950e-02,\n",
       "          3.47311758e-02,  3.05976551e-02, -2.52441708e-02,\n",
       "         -1.19650647e-01,  8.57688393e-03, -9.55648646e-02,\n",
       "         -1.29193395e-01,  3.52840943e-05,  1.82983294e-01,\n",
       "          9.67899188e-02, -7.16554187e-03, -7.67212957e-02,\n",
       "          1.16145350e-01,  9.31496397e-02,  3.12969834e-02,\n",
       "          1.68899223e-01, -1.39748633e-01,  7.17286095e-02,\n",
       "         -1.18436471e-01,  5.58180436e-02,  2.41719279e-02,\n",
       "          2.72871871e-02, -9.75003764e-02, -9.41255093e-02,\n",
       "         -5.73803484e-03,  7.35054314e-02,  1.66871175e-01,\n",
       "          1.51915461e-01, -4.37369421e-02, -2.86600199e-02,\n",
       "         -7.44675025e-02,  5.79554886e-02,  1.30457431e-01,\n",
       "          2.52357777e-02, -1.79508567e-01, -8.98847058e-02,\n",
       "          2.50522494e-02,  3.74556296e-02,  3.70880067e-02,\n",
       "         -4.76708263e-02, -1.39412805e-01,  5.99080436e-02,\n",
       "         -9.32583511e-02,  1.45190954e-01, -8.35072771e-02,\n",
       "         -1.31388485e-01, -5.13097718e-02,  1.98548846e-02,\n",
       "         -7.52729252e-02,  3.13810520e-02, -1.78338259e-01,\n",
       "          1.43219024e-01,  7.53588378e-02,  8.38947371e-02,\n",
       "          9.45370272e-02, -5.63157201e-02, -1.93862319e-01,\n",
       "          8.07449967e-02, -3.28860469e-02, -3.91827039e-02,\n",
       "          6.54315799e-02,  6.73642978e-02, -4.57319729e-02,\n",
       "         -9.87129062e-02, -6.06531464e-02,  1.29748970e-01,\n",
       "         -2.63037793e-02,  8.85960832e-03,  1.25304550e-01,\n",
       "         -1.16982080e-01, -8.31551775e-02,  8.15410838e-02,\n",
       "          2.40235999e-01,  2.16026261e-01, -1.43737212e-01,\n",
       "          2.32725561e-01,  5.15806414e-02,  2.80542411e-02,\n",
       "         -7.23643275e-03,  1.42312661e-01,  5.73345199e-02,\n",
       "         -1.43405586e-01,  1.89303935e-01,  2.69540260e-03,\n",
       "          6.88428804e-02,  3.69519778e-02, -5.72119616e-02,\n",
       "         -1.76768471e-02, -1.74778327e-01, -4.28508408e-02,\n",
       "         -4.75037247e-02, -2.36724555e-01,  3.66378091e-02,\n",
       "         -5.06979367e-03, -9.34346020e-03,  8.44859257e-02,\n",
       "         -1.18723698e-01,  1.60406202e-01,  1.58398688e-01,\n",
       "         -3.12368590e-02,  5.82303032e-02,  2.90101301e-02,\n",
       "          1.38115972e-01,  7.13893352e-03, -9.77517664e-02,\n",
       "         -4.69425432e-02,  1.77466914e-01,  1.62107795e-01,\n",
       "         -1.20668516e-01, -3.88989465e-05, -1.66215673e-02,\n",
       "         -4.86022569e-02,  5.08723669e-02, -9.62684304e-02,\n",
       "         -5.50908372e-02,  1.06708311e-01,  1.54352993e-01,\n",
       "         -3.77639420e-02, -5.68019822e-02,  1.32111952e-01,\n",
       "         -1.96667999e-01, -1.99911408e-02, -7.64785334e-03,\n",
       "          1.99851215e-01,  1.65645957e-01,  4.60945703e-02,\n",
       "          8.82721320e-03, -4.75120693e-02,  3.22788917e-02,\n",
       "          1.41132474e-01,  5.20745590e-02, -9.53378454e-02,\n",
       "         -5.61173148e-02,  8.73058364e-02,  1.41367927e-01,\n",
       "          7.64839873e-02, -1.92661226e-01,  1.33059561e-01,\n",
       "         -5.54462075e-02,  1.06050633e-01,  6.33734167e-02,\n",
       "          7.84150213e-02,  7.80801103e-02,  1.07547902e-02,\n",
       "         -3.36061344e-02,  1.46387398e-01, -6.24352880e-02,\n",
       "         -7.64917433e-02,  4.10273671e-02,  8.42486881e-03,\n",
       "          1.19029619e-02, -1.89187095e-01, -2.78429314e-02,\n",
       "         -9.88909677e-02,  6.34637475e-02,  3.38851474e-02,\n",
       "          7.34381750e-02, -1.54084161e-01, -8.05658773e-02,\n",
       "         -2.87696756e-02, -9.78925228e-02, -1.59886330e-02,\n",
       "          6.59846328e-03,  3.82057130e-02,  4.71822694e-02,\n",
       "         -9.49682593e-02,  1.26815736e-01, -1.47819400e-01,\n",
       "         -9.01099890e-02,  3.90461758e-02, -1.37496321e-02,\n",
       "         -5.40021062e-02,  5.39907999e-02,  8.24820027e-02,\n",
       "          1.14265732e-01, -4.61672172e-02,  1.97481662e-02,\n",
       "          6.95977136e-02,  4.84962063e-03,  9.39993337e-02,\n",
       "         -3.81309129e-02,  1.95348524e-02,  5.06704114e-02,\n",
       "          1.03253774e-01, -1.35588512e-01, -4.99754138e-02,\n",
       "          1.05164178e-01,  1.83174200e-03, -2.85339598e-02,\n",
       "         -4.29322086e-02,  6.70715421e-02,  3.02116480e-02,\n",
       "         -8.07313100e-02,  3.12793180e-02, -1.57462478e-01,\n",
       "          6.07184395e-02,  3.30771469e-02, -1.67308636e-02,\n",
       "          1.53750107e-01, -4.69814166e-02, -2.27195062e-02,\n",
       "         -1.38899505e-01, -9.57110450e-02, -9.90127698e-02,\n",
       "         -1.35821337e-02,  8.40902776e-02, -1.95825607e-01,\n",
       "          9.92898196e-02,  8.22435915e-02,  1.80339552e-02,\n",
       "         -2.04822160e-02, -1.12166060e-02,  6.79978207e-02,\n",
       "          1.63243681e-01,  4.18040678e-02,  7.82146454e-02,\n",
       "          9.34029743e-02, -3.64573114e-02, -4.87332977e-02,\n",
       "          1.34617910e-02, -7.18249530e-02,  7.38695413e-02,\n",
       "         -2.21603647e-01,  9.52019617e-02, -2.00056925e-01,\n",
       "          7.20436871e-02,  2.86061317e-02,  1.28195226e-01,\n",
       "          1.11852981e-01,  7.04354271e-02,  1.60480849e-02,\n",
       "         -7.76324719e-02, -6.48076236e-02,  7.34526739e-02,\n",
       "         -1.31419495e-01,  4.14554961e-02,  1.74402907e-01,\n",
       "          7.39676654e-02, -2.04149663e-01, -8.58030003e-03,\n",
       "          8.22078809e-02, -1.46114584e-02,  4.89494093e-02,\n",
       "         -2.61042081e-02, -1.51804714e-02,  2.46172100e-01,\n",
       "         -1.07632183e-01,  1.47329364e-02,  8.21894482e-02,\n",
       "         -5.69718033e-02, -5.34079075e-02,  1.22273117e-01,\n",
       "         -1.21534534e-01, -6.39401451e-02,  1.51316449e-01,\n",
       "         -1.08591504e-01,  1.14917070e-01, -7.86173642e-02,\n",
       "         -4.95360345e-02, -1.25086680e-01,  1.64656751e-02,\n",
       "         -1.25819994e-02,  1.07801139e-01, -1.83089375e-01,\n",
       "          4.12261300e-02,  4.64155562e-02,  2.35763595e-01,\n",
       "          9.99274328e-02,  6.35953248e-02,  4.86471094e-02,\n",
       "          1.01673335e-01, -1.77877396e-01,  6.97844326e-02,\n",
       "         -8.28172266e-02, -3.97210903e-02, -7.69966990e-02,\n",
       "          6.84268028e-02, -6.77404180e-02, -8.03404227e-02,\n",
       "         -1.41845092e-01, -4.33542542e-02, -4.58070822e-02,\n",
       "         -3.71048949e-03, -1.34304181e-01,  3.79576534e-02,\n",
       "         -6.09293208e-03,  6.62979186e-02,  1.58470720e-01,\n",
       "         -1.35207966e-01, -1.57245398e-01, -5.07830456e-02,\n",
       "         -1.10479385e-01,  6.07212521e-02, -7.37340050e-03,\n",
       "         -5.22559807e-02, -1.80034935e-01,  7.75176734e-02,\n",
       "         -4.52081338e-02,  1.32777348e-01, -1.39028624e-01,\n",
       "          3.68726403e-02, -1.21039741e-01,  3.41846570e-02,\n",
       "          6.90252148e-03,  1.03603028e-01,  4.44833152e-02,\n",
       "          1.01430565e-01, -1.10309303e-01, -4.40158285e-02,\n",
       "         -1.54665321e-01, -7.02857319e-03,  2.29540914e-02,\n",
       "          8.28776732e-02,  3.85141894e-02, -1.69340283e-01,\n",
       "          2.04936147e-01, -1.94272280e-01, -1.37830153e-01,\n",
       "         -3.46803069e-02,  3.25585753e-02,  1.92381337e-01,\n",
       "         -2.11864449e-02,  8.64694789e-02,  1.25444308e-01,\n",
       "          2.60582399e-02, -7.51778334e-02, -4.92630005e-02,\n",
       "          1.44211993e-01, -1.51486322e-01,  1.07261457e-01,\n",
       "         -1.01072490e-02, -1.45752653e-01, -1.13543300e-02,\n",
       "         -1.27978563e-01,  1.78469986e-01, -1.84029654e-01,\n",
       "          3.20079527e-03,  1.09803803e-01,  1.25134420e-02,\n",
       "          9.05539989e-02, -6.28263429e-02, -4.48481329e-02,\n",
       "          7.50450566e-02, -2.00015251e-02,  8.73224810e-03,\n",
       "          5.79722337e-02, -7.38346279e-02, -1.53006613e-01,\n",
       "         -5.68668135e-02, -3.32866586e-03, -5.92155494e-02,\n",
       "         -3.07060685e-03, -4.91870940e-02,  3.38864997e-02,\n",
       "         -5.62209915e-03, -4.35149707e-02,  1.40709639e-01,\n",
       "          3.66311111e-02, -1.25555079e-02,  1.12431757e-02,\n",
       "          4.89911288e-02,  7.28065223e-02, -7.60462880e-02,\n",
       "          6.97549153e-03, -5.11447303e-02, -6.32064193e-02,\n",
       "          6.58310801e-02, -2.02338412e-01, -1.02773525e-01,\n",
       "          1.84560463e-01, -6.47910908e-02, -1.34174284e-02,\n",
       "          2.67129093e-01,  7.81730935e-02, -6.03934191e-03,\n",
       "          7.32294247e-02,  4.13762555e-02,  4.84747179e-02,\n",
       "          2.58133318e-02,  1.04939803e-01,  1.04027689e-01,\n",
       "         -7.52488375e-02,  2.47221999e-02,  1.58092186e-01,\n",
       "          1.47876078e-02,  1.15511678e-01,  1.47865759e-02,\n",
       "         -1.07006624e-01, -2.87590995e-02, -9.14582014e-02,\n",
       "         -9.67007652e-02, -9.88083258e-02, -8.42550397e-02,\n",
       "          2.21284628e-02,  2.58921422e-02, -5.55888303e-02,\n",
       "          4.92242575e-02,  4.21331115e-02, -3.33243981e-02,\n",
       "         -3.29253729e-03,  1.21081918e-01,  2.17007175e-01,\n",
       "         -4.66588587e-02, -9.28870812e-02, -9.32304785e-02,\n",
       "         -8.65323320e-02,  2.23125443e-02, -8.54410082e-02,\n",
       "         -1.53131992e-01, -2.16588125e-01, -3.77191268e-02,\n",
       "          2.15013810e-02, -6.58183992e-02, -5.46685094e-03,\n",
       "         -6.32494614e-02,  1.72180116e-01, -4.19381037e-02,\n",
       "          4.15476039e-02,  1.22763433e-01, -7.79519379e-02,\n",
       "         -2.08212137e-02, -3.34872835e-04,  3.28706671e-03,\n",
       "          1.06092669e-01, -4.93865870e-02, -1.17701581e-02,\n",
       "          1.47905303e-02,  5.82950041e-02,  1.66406214e-01,\n",
       "         -6.65740147e-02,  1.55857280e-02, -6.90014958e-02,\n",
       "          3.24752517e-02, -9.84281860e-03, -1.02309898e-01,\n",
       "         -2.25941166e-02,  1.09524876e-02,  1.53247818e-01,\n",
       "          2.70097908e-02,  8.20276439e-02, -7.02438653e-02,\n",
       "         -4.47770543e-02,  3.86838242e-02, -7.74319237e-03,\n",
       "          1.41910329e-01,  5.99394254e-02, -9.65862349e-02,\n",
       "         -1.45809367e-01,  7.61011615e-02, -1.01917796e-01,\n",
       "          1.33504257e-01, -7.27257505e-02,  1.29505143e-01,\n",
       "          8.57303515e-02,  7.66634867e-02, -6.13369830e-02,\n",
       "          1.94678500e-01,  6.25589713e-02, -1.25417084e-01,\n",
       "         -4.40590754e-02,  1.14292398e-01, -1.05727606e-01,\n",
       "         -1.16094895e-01,  1.24037676e-01,  1.26800194e-01,\n",
       "         -8.87800306e-02,  4.45840433e-02, -4.64775898e-02,\n",
       "          1.35793433e-01, -2.65042353e-02, -6.75836653e-02,\n",
       "         -7.99269304e-02, -1.74086928e-01, -1.37716517e-01,\n",
       "          1.64153963e-01, -1.25275508e-01,  1.18513048e-01,\n",
       "         -1.16663668e-02,  2.22112797e-02,  7.68153220e-02,\n",
       "          7.89689869e-02,  1.05460674e-01,  1.44319803e-01,\n",
       "          1.38017898e-02, -3.40991840e-02, -5.64184524e-02,\n",
       "          6.72832653e-02,  1.99118117e-03]], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(example_input, initial_state=[cell_state, hidden_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer(example_input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 512) (1, 512)\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    ")\n",
    "output, hidden_state = rnn_layer(example_input)\n",
    "print(type(output))\n",
    "print(output.shape, hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 12, 1024)\n"
     ]
    }
   ],
   "source": [
    "bidirectional_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "output = bidirectional_rnn(example_input)\n",
    "print(type(output))\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")\n",
    "rnn_layer2 = tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")\n",
    "mod = tf.keras.Sequential()\n",
    "mod.add(rnn_layer1)\n",
    "mod.add(rnn_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (1, 12, 512)              792576    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (1, 512)                  1575936   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,368,512\n",
      "Trainable params: 2,368,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(example_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "rnn_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "))\n",
    "mod = tf.keras.Sequential()\n",
    "mod.add(rnn_layer1)\n",
    "mod.add(rnn_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(example_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study: IMBD\n",
    "Klasyfikacja tekstu przy użyciu RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "maxlen = 50\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
      " list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])]\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "print(x_train[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwróćmy uwagę w powyższym, że ciągi zaczynają się zawsze od \"1\" - jest to oznaczenie początku zdania. Czyli \"początek zdania\" będzie miał swój embedding.\n",
    "\n",
    "Standaryzacja długości sekwencji (Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import sequence\n",
    "# keras < 2.9\n",
    "\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen, padding=\"pre\")\n",
    "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen, padding=\"pre\")\n",
    "\n",
    "# print(\"x_train shape:\", x_train.shape)\n",
    "# print(\"x_test shape:\", x_test.shape)\n",
    "# print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 50)\n",
      "x_test shape: (25000, 50)\n",
      "[  2  56  26 141   6 194   2  18   4 226  22  21 134 476  26 480   5 144\n",
      "  30   2  18  51  36  28 224  92  25 104   4 226  65  16  38   2  88  12\n",
      "  16 283   5  16   2 113 103  32  15  16   2  19 178  32]\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "\n",
    "\n",
    "x_train = utils.pad_sequences(x_train, maxlen=maxlen, padding=\"pre\")\n",
    "x_test = utils.pad_sequences(x_test, maxlen=maxlen, padding=\"pre\")\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 3000\n",
    "n_test = 500\n",
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "x_test = x_test[:n_test]\n",
    "y_test = y_test[:n_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zwykła sieć rekurencyjna ( z embeddingami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    SimpleRNN,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    GRU\n",
    ")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN + dense pomiędzy zwracanym wyjściem z RNN a outputem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 50)          50000     \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 64)                7360      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,425\n",
      "Trainable params: 57,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 50))\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 11s 230ms/step - loss: 0.6938 - accuracy: 0.5059 - val_loss: 0.6886 - val_accuracy: 0.5200\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 10s 234ms/step - loss: 0.6396 - accuracy: 0.6667 - val_loss: 0.7422 - val_accuracy: 0.5033\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 10s 230ms/step - loss: 0.4991 - accuracy: 0.7756 - val_loss: 0.5757 - val_accuracy: 0.6733\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 10s 233ms/step - loss: 0.3062 - accuracy: 0.8948 - val_loss: 0.6378 - val_accuracy: 0.6767\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 10s 225ms/step - loss: 0.1749 - accuracy: 0.9530 - val_loss: 0.6833 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a4428fe50>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, callbacks=[early], validation_split=0.1, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwukierunkowa sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 50, 50)            50000     \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 64)               5312      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,369\n",
      "Trainable params: 56,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen, mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(SimpleRNN(32)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 31s 689ms/step - loss: 0.6952 - accuracy: 0.5170 - val_loss: 0.6854 - val_accuracy: 0.5567\n",
      "Epoch 2/5\n",
      " 4/43 [=>............................] - ETA: 24s - loss: 0.6685 - accuracy: 0.6992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, callbacks=[early], validation_split=0.1, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie. Powtórz powyższe modele z komórką LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import random\n",
    "random.set_seed(2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    max_features,\n",
    "    400))\n",
    "model.add(Bidirectional(LSTM(\n",
    "    units=embedding_dims,\n",
    "    activation=\"tanh\",\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    ")))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(x_train, y_train, callbacks=[early], validation_split=0.1, batch_size=64, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 50, 50)            50000     \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 64)               21248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,305\n",
      "Trainable params: 72,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen, mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 12:47:54.369529: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_19'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/43 [==========>...................] - ETA: 29s - loss: 0.6929 - accuracy: 0.4971"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, callbacks=[early], validation_split=0.1, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwuwarstwowa sieć rekurencyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 50, 50)            50000     \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 50, 64)           16128     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 50, 64)           18816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, 128)              49920     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,945\n",
      "Trainable params: 136,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/85 [==>...........................] - ETA: 3:00 - loss: 0.6947 - accuracy: 0.4659"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     11\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen, mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN a tekst\n",
    "\n",
    "Mając sekwencję możemy zamiast wykorzystywać RNN skorzystać z jednowymiarowej konwolucji. W tym przypadku rozmiar kernela(jądra) decyduje o tym na ile chwil czasowych jednocześnie patrzy CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 3])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GlobalAveragePooling2D()(tf.zeros((16, 32,32,3))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie\n",
    "korzystając z warstwy `tf.keras.layers.Conv1D` i jakiejś warstwy poolingowej zastąpić w poprzednim modelu RNN siecią CNN.\n",
    "Argumenty są takie same jak dla konwolucji 2D tylko `kernel_size` i `strides` mogą być tylko liczbami całkowitymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64, input_length=maxlen))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=5))\n",
    "model.add(Conv1D(64, kernel_size=5))\n",
    "model.add(Conv1D(128, kernel_size=5))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early],\n",
    "    validation_split=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5996 - accuracy: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5995662212371826, 0.7379999756813049]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study\n",
    "Utwórz model, który identyfikuje emocje wpisu na twiterze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dane/tweet_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['content'].tolist()\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5\n",
    "Przygotowanie danych:\n",
    "* (Opcjonalnie) Przeczyścić\n",
    "* Tokenizować i utworzyć słownik\n",
    "* Zakodowanie etykiet\n",
    "* Podział na zbiór treningowy i testowy\n",
    "\n",
    "`tf.keras.layers.TextVectorization`\n",
    "\n",
    "metody:\n",
    "\n",
    "`adapt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(sent):\n",
    "    outsent = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",sent).split())\n",
    "    outsent = outsent.lower()\n",
    "    return outsent\n",
    "\n",
    "import re\n",
    "\n",
    "X = [preprocess_tweets(elem) for elem in X]\n",
    "\n",
    "\n",
    "# Tworzymy warstwe tokenizującą\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=5000, output_mode=\"int\"\n",
    ")\n",
    "# Dopasujemy tokenizator do danych\n",
    "vectorize_layer.adapt(X) #tworzy słownik\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_label = le.fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(X), y_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5, 12, ...,  4, 11, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6\n",
    "przetrenować sieć CNN do klasyfikacji sentymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizacja\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=5000, output_mode=\"int\")\n",
    "vectorize_layer.adapt(X)\n",
    "vocab_size = len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader\n",
    "import numpy as np\n",
    "\n",
    "glove_vectors = downloader.load('glove-wiki-gigaword-100')\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "for i, word in enumerate(vectorize_layer.get_vocabulary()):\n",
    "    try:\n",
    "        word_embedding = glove_vectors[word]\n",
    "        embedding_matrix[i] = word_embedding\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_3 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_8 (Embedding)     (None, None, 100)         500000    \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, None, 32)          16032     \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, None, 64)          10304     \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 560,269\n",
      "Trainable params: 560,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "254/254 [==============================] - 9s 30ms/step - loss: 2.3082 - sparse_categorical_accuracy: 0.2132 - val_loss: 2.1688 - val_sparse_categorical_accuracy: 0.2531\n",
      "Epoch 2/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 2.1612 - sparse_categorical_accuracy: 0.2496 - val_loss: 2.0954 - val_sparse_categorical_accuracy: 0.2708\n",
      "Epoch 3/100\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 2.0925 - sparse_categorical_accuracy: 0.2812 - val_loss: 2.0494 - val_sparse_categorical_accuracy: 0.2881\n",
      "Epoch 4/100\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 2.0464 - sparse_categorical_accuracy: 0.3004 - val_loss: 2.0276 - val_sparse_categorical_accuracy: 0.3008\n",
      "Epoch 5/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 2.0156 - sparse_categorical_accuracy: 0.3093 - val_loss: 1.9873 - val_sparse_categorical_accuracy: 0.3106\n",
      "Epoch 6/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.9896 - sparse_categorical_accuracy: 0.3188 - val_loss: 1.9699 - val_sparse_categorical_accuracy: 0.3172\n",
      "Epoch 7/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.9698 - sparse_categorical_accuracy: 0.3287 - val_loss: 1.9537 - val_sparse_categorical_accuracy: 0.3214\n",
      "Epoch 8/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.9571 - sparse_categorical_accuracy: 0.3343 - val_loss: 1.9456 - val_sparse_categorical_accuracy: 0.3275\n",
      "Epoch 9/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.9437 - sparse_categorical_accuracy: 0.3366 - val_loss: 1.9388 - val_sparse_categorical_accuracy: 0.3272\n",
      "Epoch 10/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.9285 - sparse_categorical_accuracy: 0.3436 - val_loss: 1.9300 - val_sparse_categorical_accuracy: 0.3358\n",
      "Epoch 11/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.9152 - sparse_categorical_accuracy: 0.3463 - val_loss: 1.9213 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 12/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.9063 - sparse_categorical_accuracy: 0.3502 - val_loss: 1.9245 - val_sparse_categorical_accuracy: 0.3294\n",
      "Epoch 13/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8948 - sparse_categorical_accuracy: 0.3525 - val_loss: 1.9139 - val_sparse_categorical_accuracy: 0.3372\n",
      "Epoch 14/100\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 1.8884 - sparse_categorical_accuracy: 0.3578 - val_loss: 1.9097 - val_sparse_categorical_accuracy: 0.3394\n",
      "Epoch 15/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8800 - sparse_categorical_accuracy: 0.3595 - val_loss: 1.9065 - val_sparse_categorical_accuracy: 0.3397\n",
      "Epoch 16/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8717 - sparse_categorical_accuracy: 0.3656 - val_loss: 1.9042 - val_sparse_categorical_accuracy: 0.3422\n",
      "Epoch 17/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8661 - sparse_categorical_accuracy: 0.3647 - val_loss: 1.9009 - val_sparse_categorical_accuracy: 0.3439\n",
      "Epoch 18/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8568 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.8986 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 19/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8508 - sparse_categorical_accuracy: 0.3713 - val_loss: 1.8994 - val_sparse_categorical_accuracy: 0.3486\n",
      "Epoch 20/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.8390 - sparse_categorical_accuracy: 0.3766 - val_loss: 1.8964 - val_sparse_categorical_accuracy: 0.3514\n",
      "Epoch 21/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8362 - sparse_categorical_accuracy: 0.3766 - val_loss: 1.8994 - val_sparse_categorical_accuracy: 0.3461\n",
      "Epoch 22/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8266 - sparse_categorical_accuracy: 0.3774 - val_loss: 1.8965 - val_sparse_categorical_accuracy: 0.3486\n",
      "Epoch 23/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8214 - sparse_categorical_accuracy: 0.3824 - val_loss: 1.8963 - val_sparse_categorical_accuracy: 0.3456\n",
      "Epoch 24/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.8151 - sparse_categorical_accuracy: 0.3829 - val_loss: 1.9044 - val_sparse_categorical_accuracy: 0.3511\n",
      "Epoch 25/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.8096 - sparse_categorical_accuracy: 0.3852 - val_loss: 1.8969 - val_sparse_categorical_accuracy: 0.3514\n",
      "Epoch 26/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.8049 - sparse_categorical_accuracy: 0.3871 - val_loss: 1.8942 - val_sparse_categorical_accuracy: 0.3492\n",
      "Epoch 27/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7976 - sparse_categorical_accuracy: 0.3899 - val_loss: 1.8970 - val_sparse_categorical_accuracy: 0.3517\n",
      "Epoch 28/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7911 - sparse_categorical_accuracy: 0.3935 - val_loss: 1.8967 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 29/100\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 1.7847 - sparse_categorical_accuracy: 0.3932 - val_loss: 1.8961 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 30/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7830 - sparse_categorical_accuracy: 0.3949 - val_loss: 1.9097 - val_sparse_categorical_accuracy: 0.3469\n",
      "Epoch 31/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7761 - sparse_categorical_accuracy: 0.3939 - val_loss: 1.9082 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 32/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.7715 - sparse_categorical_accuracy: 0.3954 - val_loss: 1.9066 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 33/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.7675 - sparse_categorical_accuracy: 0.4004 - val_loss: 1.9086 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 34/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7605 - sparse_categorical_accuracy: 0.3997 - val_loss: 1.9077 - val_sparse_categorical_accuracy: 0.3461\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7560 - sparse_categorical_accuracy: 0.4035 - val_loss: 1.9099 - val_sparse_categorical_accuracy: 0.3439\n",
      "Epoch 36/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7508 - sparse_categorical_accuracy: 0.4053 - val_loss: 1.9021 - val_sparse_categorical_accuracy: 0.3439\n",
      "Epoch 37/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7456 - sparse_categorical_accuracy: 0.4070 - val_loss: 1.9173 - val_sparse_categorical_accuracy: 0.3486\n",
      "Epoch 38/100\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 1.7433 - sparse_categorical_accuracy: 0.4094 - val_loss: 1.9087 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 39/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.7354 - sparse_categorical_accuracy: 0.4097 - val_loss: 1.9167 - val_sparse_categorical_accuracy: 0.3508\n",
      "Epoch 40/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7312 - sparse_categorical_accuracy: 0.4111 - val_loss: 1.9235 - val_sparse_categorical_accuracy: 0.3467\n",
      "Epoch 41/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7302 - sparse_categorical_accuracy: 0.4135 - val_loss: 1.9253 - val_sparse_categorical_accuracy: 0.3439\n",
      "Epoch 42/100\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 1.7221 - sparse_categorical_accuracy: 0.4137 - val_loss: 1.9159 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 43/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7161 - sparse_categorical_accuracy: 0.4179 - val_loss: 1.9223 - val_sparse_categorical_accuracy: 0.3425\n",
      "Epoch 44/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7124 - sparse_categorical_accuracy: 0.4196 - val_loss: 1.9303 - val_sparse_categorical_accuracy: 0.3403\n",
      "Epoch 45/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7129 - sparse_categorical_accuracy: 0.4196 - val_loss: 1.9410 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 46/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7078 - sparse_categorical_accuracy: 0.4201 - val_loss: 1.9274 - val_sparse_categorical_accuracy: 0.3417\n",
      "Epoch 47/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.7017 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.9435 - val_sparse_categorical_accuracy: 0.3422\n",
      "Epoch 48/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6973 - sparse_categorical_accuracy: 0.4225 - val_loss: 1.9344 - val_sparse_categorical_accuracy: 0.3456\n",
      "Epoch 49/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6951 - sparse_categorical_accuracy: 0.4268 - val_loss: 1.9371 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 50/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6892 - sparse_categorical_accuracy: 0.4272 - val_loss: 1.9375 - val_sparse_categorical_accuracy: 0.3378\n",
      "Epoch 51/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6876 - sparse_categorical_accuracy: 0.4261 - val_loss: 1.9409 - val_sparse_categorical_accuracy: 0.3397\n",
      "Epoch 52/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6811 - sparse_categorical_accuracy: 0.4270 - val_loss: 1.9515 - val_sparse_categorical_accuracy: 0.3408\n",
      "Epoch 53/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6801 - sparse_categorical_accuracy: 0.4306 - val_loss: 1.9461 - val_sparse_categorical_accuracy: 0.3339\n",
      "Epoch 54/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6743 - sparse_categorical_accuracy: 0.4322 - val_loss: 1.9580 - val_sparse_categorical_accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6701 - sparse_categorical_accuracy: 0.4327 - val_loss: 1.9664 - val_sparse_categorical_accuracy: 0.3439\n",
      "Epoch 56/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6618 - sparse_categorical_accuracy: 0.4340 - val_loss: 1.9534 - val_sparse_categorical_accuracy: 0.3414\n",
      "Epoch 57/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6622 - sparse_categorical_accuracy: 0.4382 - val_loss: 1.9701 - val_sparse_categorical_accuracy: 0.3400\n",
      "Epoch 58/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6581 - sparse_categorical_accuracy: 0.4368 - val_loss: 1.9646 - val_sparse_categorical_accuracy: 0.3392\n",
      "Epoch 59/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6517 - sparse_categorical_accuracy: 0.4378 - val_loss: 1.9757 - val_sparse_categorical_accuracy: 0.3386\n",
      "Epoch 60/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6522 - sparse_categorical_accuracy: 0.4393 - val_loss: 1.9678 - val_sparse_categorical_accuracy: 0.3336\n",
      "Epoch 61/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6447 - sparse_categorical_accuracy: 0.4405 - val_loss: 1.9715 - val_sparse_categorical_accuracy: 0.3328\n",
      "Epoch 62/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6444 - sparse_categorical_accuracy: 0.4394 - val_loss: 1.9625 - val_sparse_categorical_accuracy: 0.3342\n",
      "Epoch 63/100\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.6391 - sparse_categorical_accuracy: 0.4422 - val_loss: 2.0040 - val_sparse_categorical_accuracy: 0.3383\n",
      "Epoch 64/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6337 - sparse_categorical_accuracy: 0.4437 - val_loss: 1.9802 - val_sparse_categorical_accuracy: 0.3267\n",
      "Epoch 65/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6321 - sparse_categorical_accuracy: 0.4448 - val_loss: 1.9943 - val_sparse_categorical_accuracy: 0.3297\n",
      "Epoch 66/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6283 - sparse_categorical_accuracy: 0.4448 - val_loss: 2.0132 - val_sparse_categorical_accuracy: 0.3375\n",
      "Epoch 67/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6238 - sparse_categorical_accuracy: 0.4456 - val_loss: 1.9948 - val_sparse_categorical_accuracy: 0.3367\n",
      "Epoch 68/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6202 - sparse_categorical_accuracy: 0.4472 - val_loss: 2.0171 - val_sparse_categorical_accuracy: 0.3381\n",
      "Epoch 69/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6191 - sparse_categorical_accuracy: 0.4461 - val_loss: 1.9989 - val_sparse_categorical_accuracy: 0.3347\n",
      "Epoch 70/100\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 1.6142 - sparse_categorical_accuracy: 0.4517 - val_loss: 1.9935 - val_sparse_categorical_accuracy: 0.3331\n",
      "Epoch 71/100\n",
      "148/254 [================>.............] - ETA: 2s - loss: 1.6082 - sparse_categorical_accuracy: 0.4510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     28\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39msparse_categorical_crossentropy, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.0001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;43;03m#     callbacks=EarlyStopping(patience=2),\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Zakodowanie etykiet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y)\n",
    "list(enc.classes_)\n",
    "\n",
    "#split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), enc.transform(y), test_size=0.1)\n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(vocab_size, 100, \n",
    "                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix)\n",
    "                   ))\n",
    "model.add(Conv1D(32, kernel_size=5, padding='same'))\n",
    "model.add(Conv1D(64, kernel_size=5, padding='same'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(enc.classes_), activation=\"softmax\"))\n",
    "\n",
    "# model.layers[1].trainable=False\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(0.0001), metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "#     callbacks=EarlyStopping(patience=2),\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7\n",
    "Przetrenować RNN do klasyfikacji sentymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    "))\n",
    "rnn_layer2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
    "    units=512,\n",
    "    activation=\"tanh\",\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_3 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_12 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, None, 1024)       1775616   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 1024)             4724736   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,886,797\n",
      "Trainable params: 6,886,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "254/254 [==============================] - 27s 87ms/step - loss: 2.1639 - sparse_categorical_accuracy: 0.2152 - val_loss: 2.1527 - val_sparse_categorical_accuracy: 0.2169\n",
      "Epoch 2/5\n",
      "254/254 [==============================] - 21s 84ms/step - loss: 2.1435 - sparse_categorical_accuracy: 0.2239 - val_loss: 2.1542 - val_sparse_categorical_accuracy: 0.2136\n",
      "Epoch 3/5\n",
      "254/254 [==============================] - 22s 85ms/step - loss: 2.1041 - sparse_categorical_accuracy: 0.2466 - val_loss: 2.2066 - val_sparse_categorical_accuracy: 0.1944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a6ef45790>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(vocab_size, 64))\n",
    "\n",
    "model.add(rnn_layer1)\n",
    "model.add(rnn_layer2)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    callbacks=EarlyStopping(patience=2),\n",
    "    validation_split=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 21ms/step - loss: 2.1852 - sparse_categorical_accuracy: 0.2020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1851632595062256, 0.20200000703334808]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_3 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_9 (Embedding)     (None, None, 100)         500000    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 512)        731136    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, None, 512)        1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 13)                3341      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,515,629\n",
      "Trainable params: 4,515,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "254/254 [==============================] - 31s 96ms/step - loss: 2.0088 - sparse_categorical_accuracy: 0.3080 - val_loss: 1.9338 - val_sparse_categorical_accuracy: 0.3272\n",
      "Epoch 2/100\n",
      "254/254 [==============================] - 23s 92ms/step - loss: 1.8808 - sparse_categorical_accuracy: 0.3573 - val_loss: 1.8727 - val_sparse_categorical_accuracy: 0.3447\n",
      "Epoch 3/100\n",
      "254/254 [==============================] - 23s 92ms/step - loss: 1.8169 - sparse_categorical_accuracy: 0.3793 - val_loss: 1.8698 - val_sparse_categorical_accuracy: 0.3492\n",
      "Epoch 4/100\n",
      "254/254 [==============================] - 23s 92ms/step - loss: 1.7622 - sparse_categorical_accuracy: 0.3986 - val_loss: 1.8869 - val_sparse_categorical_accuracy: 0.3381\n",
      "Epoch 5/100\n",
      "254/254 [==============================] - 23s 90ms/step - loss: 1.7085 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.8833 - val_sparse_categorical_accuracy: 0.3511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99a0297be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(vocab_size, 100, embeddings_initializer=tf.keras.initializers.Constant(\n",
    "            embedding_matrix\n",
    "        )))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(enc.classes_), activation=\"softmax\"))\n",
    "# model.layers[1].trainable=False\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(0.001), metrics=[\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=EarlyStopping(patience=2),\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 29ms/step - loss: 1.8774 - sparse_categorical_accuracy: 0.3505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8774006366729736, 0.3504999876022339]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual embeddings\n",
    "Przy użyciu sieci rekurencyjnych można tworzyć embeddingi, które uwzględniają kontekst w jakim użyte jest dane słowo. Istnieje wiele słów, które jak są wykorzystane bez kontekstu nie można jednoznacznie określić ich znaczenia(np. zamek jako budowla i jako zapięcie kurtki). W związku z tym wykorzystuje się modele sekwencyjne, które modelują słowo w zależności od jego \"otoczenia\"\n",
    "##### ELMo\n",
    "Model ELMo wykorzsytuje sieci Bidirectional RNN do reprezentacji kontekstu\n",
    "\n",
    "![](Grafika/Bert-language-modeling.png)\n",
    "\n",
    "Działanie ELMo\n",
    "\n",
    "![](Grafika/elmo-forward-backward-language-model-embedding.png)\n",
    "\n",
    "![](Grafika/elmo-embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 1024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"ELMo lives on sesame street.\"]\n",
    "\n",
    "# Extract ELMo features\n",
    "embeddings = elmo(tf.constant(x))[\"elmo\"]\n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_elmo_embeddings = elmo(tf.constant(x_train[:100]))[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 28, 1024])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_elmo_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elmo = Sequential()\n",
    "model_elmo.add(Bidirectional(GRU(512)))\n",
    "model_elmo.add(Dense(512, activation=\"relu\"))\n",
    "model_elmo.add(Dropout(0.4))\n",
    "model_elmo.add(Dense(13, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elmo.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6/6 [==============================] - 4s 156ms/step - loss: 2.5344 - sparse_categorical_accuracy: 0.1889 - val_loss: 2.4384 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.6741 - sparse_categorical_accuracy: 0.4667 - val_loss: 2.3752 - val_sparse_categorical_accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a676a68b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_elmo.fit(\n",
    "    X_elmo_embeddings,\n",
    "    y_train[:100],\n",
    "    batch_size=16,\n",
    "    epochs=2,\n",
    "    validation_split=0.10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "Modele Seq2Seq składają się z dwóch modeli sekwencyjnych, zazwyczaj pierwszy nazywa się `encoder` a drugi `decoder`. Zazwyczaj sekwencje wejściowe i wyjściowe mogą być różnej długości.\n",
    "Przykłady zastosowań\n",
    "* Machine translation\n",
    "* Table summarization\n",
    "* Image captioning\n",
    "* Document Summarization\n",
    "* Question Answering(np. chatboty)\n",
    "* Speech recognition\n",
    "\n",
    "![](Grafika/seq2seq-teacher-forcing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby utworzy takie modele trzeba już korzystać z functional API w Kerasie, ponieważ tutaj nie mamy prostego liniowego potoku zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 256)               786688    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 789,258\n",
      "Trainable params: 789,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = keras.Input(shape=(32,32,3))\n",
    "\n",
    "flatten_layer = keras.layers.Flatten()\n",
    "\n",
    "flattened = flatten_layer(img_input)\n",
    "x = keras.layers.Dense(256, activation='relu')(flattened)\n",
    "x1 = keras.layers.Dense(256, activation='relu')(x)\n",
    "x1 = x + x1\n",
    "output = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=img_input, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy i problemy lingwistyczne\n",
    "spacy jest biblioteką zawierającą wiele modeli do problemów lingwistycznych, które teraz sobie krótko omówimy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tokenizacja\n",
    "spacy także posiada tokenizacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/mchraba/miniconda3/envs/szkolenie_ds/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting pl-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.3.0/pl_core_news_sm-3.3.0-py3-none-any.whl (20.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from pl-core-news-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (1.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: jinja2 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->pl-core-news-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: pl-core-news-sm\n",
      "Successfully installed pl-core-news-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biorę\n",
      "biora\n",
      "dzisiaj\n",
      "dzisiaj\n",
      "udział\n",
      "udział\n",
      "w\n",
      "w\n",
      "zajęciach\n",
      "zajęcia\n",
      "z\n",
      "z\n",
      "sieci\n",
      "sieć\n",
      "rekurencyjnych\n",
      "rekurencyjny\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# wczytywanie modelu językowego\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "doc = nlp(\"biorę dzisiaj udział w zajęciach z sieci rekurencyjnych.\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    print(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-Of_Speech (POS) - tagging\n",
    "problem ten polega na wyjaśnieniu w jaki sposób dane słowo jest wykorzystane w zdaniu. Ustalone jest 8 części mowy (po ang bo będzie łatwiej):\n",
    "* Noun\n",
    "* Pronoun\n",
    "* Adjective\n",
    "* Verb\n",
    "* Adverb\n",
    "* Preposition\n",
    "* Conjunction\n",
    "* Interjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uczymy FIN VERB None\n",
      "się QUB PRON None\n",
      "teraz ADV ADV adverb\n",
      "o PREP ADP None\n",
      "Spacy SUBST PROPN None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'FIN' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'QUB' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'PREP' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/mchraba/miniconda3/envs/szkolenie_ds/lib/python3.9/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'SUBST' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"uczymy się teraz o Spacy\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the token and its part-of-speech tag\n",
    "    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pl\" id=\"d894f54125a54a00a8a1aa6731da306a-0\" class=\"displacy\" width=\"925\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">uczymy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">się</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">teraz</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Spacy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d894f54125a54a00a8a1aa6731da306a-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d894f54125a54a00a8a1aa6731da306a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">expl:pv</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d894f54125a54a00a8a1aa6731da306a-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d894f54125a54a00a8a1aa6731da306a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,266.5 L403.0,254.5 387.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d894f54125a54a00a8a1aa6731da306a-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d894f54125a54a00a8a1aa6731da306a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d894f54125a54a00a8a1aa6731da306a-0-3\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d894f54125a54a00a8a1aa6731da306a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"uczymy się teraz o Spacy\")\n",
    "spacy.displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency Parsing\n",
    "Jest to proces tworzenia struktury gramatycznej zdania. Daje on nam zależność słów w zdaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uczymy --> ROOT\n",
      "się --> amod\n",
      "teraz --> dobj\n",
      "o --> dobj\n",
      "Spacy --> dobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"uczymy się teraz o Spacy\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"-->\", token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41865864,  0.43066335,  0.6623521 , -0.20936172,  0.48971444,\n",
       "        0.49390063,  0.64525855, -0.90870166,  0.09301043,  0.18278256,\n",
       "       -0.74089634, -0.05980694,  0.22271365,  0.34179288, -0.5375267 ,\n",
       "        0.7238251 , -0.9606206 ,  0.12817085, -0.56941235,  1.1561015 ,\n",
       "       -0.09720856, -0.50086236, -0.75893176,  0.42354727,  0.10997573,\n",
       "        0.7482457 , -1.2016877 ,  0.8505768 ,  0.3301307 , -0.9260626 ,\n",
       "       -0.39288688,  0.61222076, -0.94754726, -0.41945955, -0.36880997,\n",
       "        0.00419371,  0.14100781, -0.771331  ,  0.17537194, -0.1911444 ,\n",
       "        0.28079316, -0.37717414,  0.39071086, -0.782937  , -0.23812774,\n",
       "        0.10956369,  0.11842769, -0.40983358, -0.0601393 ,  1.0633551 ,\n",
       "        0.96898174, -0.29064146, -0.86304533, -0.57538044,  0.45362335,\n",
       "       -0.7393721 , -0.89779377,  0.5219121 , -0.6684075 , -0.5712844 ,\n",
       "       -0.71596515,  0.10056004, -0.10889052,  0.349348  ,  0.26711488,\n",
       "       -0.20262252, -0.02398084,  1.1425614 , -0.6714214 , -0.7501637 ,\n",
       "        0.7040586 ,  0.25924474, -0.44784704,  0.08794829, -0.8002536 ,\n",
       "       -0.00244986,  0.12149614, -0.34459263,  1.0467522 ,  1.1042118 ,\n",
       "        0.20438994, -0.10097617, -0.07216828, -0.5774925 ,  1.5221567 ,\n",
       "       -0.54075456,  0.13652617,  0.10671539,  1.3401827 ,  0.12996882,\n",
       "       -0.9135802 ,  0.71375424, -0.749292  ,  0.23759776, -0.4671238 ,\n",
       "        1.002167  ], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recogniton\n",
    "Czyli po prostu wykrywanie nazw własnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enitites: (Warszawie, lini metra)\n",
      "Warszawie 2 11 placeName\n",
      "lini metra 51 61 persName\n"
     ]
    }
   ],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\n",
    "    \"W Warszawie ostatnio otworzono nowe stacje drugiej lini metra.\"\n",
    ")\n",
    "# See the entity present\n",
    "print(f\"Enitites: {doc.ents}\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Recogniton\n",
    "nazywane też Entity Detection jest bardziej zaawansowany od NER, ponieważ rozpoznaje istotne elementy między innymi miejsca, ludzi, organizacje, języki itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Amazon, 'ORG', 383),\n",
       " (the Amazon Jungle, 'GPE', 384),\n",
       " (English, 'LANGUAGE', 389),\n",
       " (Amazonia, 'GPE', 384),\n",
       " (Amazon, 'ORG', 383),\n",
       " (Amazon, 'ORG', 383),\n",
       " (South America, 'LOC', 385),\n",
       " (7,000,000, 'CARDINAL', 397),\n",
       " (2,700,000, 'CARDINAL', 397),\n",
       " (5,500,000, 'CARDINAL', 397),\n",
       " (2,100,000, 'CARDINAL', 397),\n",
       " (nine, 'CARDINAL', 397),\n",
       " (Brazil, 'GPE', 384),\n",
       " (60%, 'PERCENT', 393),\n",
       " (Peru, 'GPE', 384),\n",
       " (13%, 'PERCENT', 393),\n",
       " (Colombia, 'GPE', 384),\n",
       " (10%, 'PERCENT', 393),\n",
       " (Bolivia, 'GPE', 384),\n",
       " (Ecuador, 'GPE', 384),\n",
       " (French Guiana, 'PERSON', 380),\n",
       " (Guyana, 'GPE', 384),\n",
       " (Suriname, 'GPE', 384),\n",
       " (Venezuela, 'GPE', 384),\n",
       " (Four, 'CARDINAL', 397),\n",
       " (Amazonas, 'ORG', 383),\n",
       " (one, 'CARDINAL', 397),\n",
       " (first, 'ORDINAL', 396),\n",
       " (France, 'GPE', 384),\n",
       " (Guiana Amazonian Park, 'WORK_OF_ART', 388),\n",
       " (Amazon, 'ORG', 383),\n",
       " (over half, 'CARDINAL', 397),\n",
       " (an estimated 390 billion, 'MONEY', 394),\n",
       " (16,000, 'CARDINAL', 397),\n",
       " (Amazon, 'ORG', 383),\n",
       " (Francisco de Orellana, 'ORG', 383),\n",
       " (Tapuyas, 'LOC', 385),\n",
       " (Orellana, 'PERSON', 380),\n",
       " (Amazonas, 'ORG', 383),\n",
       " (Herodotus, 'ORG', 383),\n",
       " (South America, 'LOC', 385),\n",
       " (Amazon, 'ORG', 383),\n",
       " (Amazon River, 'LOC', 385),\n",
       " (§, 'GPE', 384),\n",
       " (Amazonas, 'ORG', 383),\n",
       " (Jivaroan, 'GPE', 384),\n",
       " (Shuar, 'ORG', 383),\n",
       " (Brazil, 'GPE', 384),\n",
       " (Venezuela, 'GPE', 384),\n",
       " (Yanomami, 'PERSON', 380),\n",
       " (More than a third, 'CARDINAL', 397),\n",
       " (Yanomamo, 'NORP', 381)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\n",
    "    \"\"\"The Amazon rainforest,[a] alternatively, the Amazon Jungle, also known in English as Amazonia, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km2 (2,700,000 sq mi), of which 5,500,000 km2 (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations.\n",
    "\n",
    "The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Bolivia, Ecuador, French Guiana, Guyana, Suriname, and Venezuela. Four nations have \"Amazonas\" as the name of one of their first-level administrative regions and France uses the name \"Guiana Amazonian Park\" for its rainforest protected area. The Amazon represents over half of the planet's remaining rainforests,[2] and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.[3]\n",
    "\n",
    "Etymology\n",
    "The name Amazon is said to arise from a war Francisco de Orellana fought with the Tapuyas and other tribes. The women of the tribe fought alongside the men, as was their custom.[4] Orellana derived the name Amazonas from the Amazons of Greek mythology, described by Herodotus and Diodorus.[4]\n",
    "\n",
    "History\n",
    "See also: History of South America § Amazon, and Amazon River § History\n",
    "Tribal societies are well capable of escalation to all-out wars between tribes. Thus, in the Amazonas, there was perpetual animosity between the neighboring tribes of the Jivaro. Several tribes of the Jivaroan group, including the Shuar, practised headhunting for trophies and headshrinking.[5] The accounts of missionaries to the area in the borderlands between Brazil and Venezuela have recounted constant infighting in the Yanomami tribes. More than a third of the Yanomamo males, on average, died from warfare.[6]\"\"\"\n",
    ")\n",
    "\n",
    "entities = [(i, i.label_, i.label) for i in doc.ents]\n",
    "entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " rainforest,[a] alternatively, \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Amazon Jungle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", also known in \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    English\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " as \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazonia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", is a moist broadleaf tropical rainforest in the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " biome that covers most of the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " basin of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". This basin encompasses \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    7,000,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " km2 (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2,700,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " sq mi), of which \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5,500,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " km2 (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2,100,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " sq mi) are covered by the rainforest. This region includes territory belonging to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " nations.</br></br>The majority of the forest is contained within \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    60%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of the rainforest, followed by \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Peru\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    13%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Colombia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ", and with minor amounts in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolivia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ecuador\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    French Guiana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Guyana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Suriname\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Venezuela\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Four\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " nations have &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazonas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot; as the name of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of their \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       "-level administrative regions and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    France\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " uses the name &quot;\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Guiana Amazonian Park\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "&quot; for its rainforest protected area. The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " represents \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    over half\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the planet's remaining rainforests,[2] and comprises the largest and most biodiverse tract of tropical rainforest in the world, with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    an estimated 390 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " individual trees divided into \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    16,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " species.[3]</br></br>Etymology</br>The name \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is said to arise from a war \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Francisco de Orellana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " fought with the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tapuyas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and other tribes. The women of the tribe fought alongside the men, as was their custom.[4] \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Orellana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " derived the name \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazonas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " from the Amazons of Greek mythology, described by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Herodotus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and Diodorus.[4]</br></br>History</br>See also: History of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " § \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon River\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    §\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " History</br>Tribal societies are well capable of escalation to all-out wars between tribes. Thus, in the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazonas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", there was perpetual animosity between the neighboring tribes of the Jivaro. Several tribes of the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jivaroan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " group, including the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shuar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", practised headhunting for trophies and headshrinking.[5] The accounts of missionaries to the area in the borderlands between \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Venezuela\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " have recounted constant infighting in the \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yanomami\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " tribes. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    More than a third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yanomamo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " males, on average, died from warfare.[6]</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers\n",
    "Transformery wywołały ogromny przełom w NLP, są one w stanie modelować relacje między dowolnie odległymi chwilami czasu i są szybsze ponieważ nie wymagają pętli(wystarcza tylko mnożenie wektorów i macierzy)\n",
    "\n",
    "![](Grafika/transformer.png)\n",
    "\n",
    "Czym jest `Positional Encoding`? Istnieją dwie szkoły tworzenia\n",
    "* Uczymy embeddingi pozycji razem z modelem, czyli `Positional Encoding` jest parameterem modelu o ustalonej długości\n",
    "* Wykorzystujemy z góry zdefiniowaną funkcję np.\n",
    "\\begin{align*}\n",
    "  p_{i,j}=\n",
    "  \\begin{cases}\n",
    "    \\sin\\left(\\frac{i}{10000^{j/d}}\\right)\\\\\n",
    "    \\cos\\left(\\frac{i}{10000^{(j-1)/d}}\\right)\n",
    "  \\end{cases}\n",
    "\\end{align*}\n",
    "gdzie $i$-chwila czasu, $j$-j'ty wymiar w wektorze positional encodingu, $d$-wymiar positional encodingu.\n",
    "\n",
    "Positional Encoding jest potrzebny, żeby model był w stanie modelować dane wejściowe jako sekwencje, w przeciwnym wypadku, pozycja w której umieścimy token/wartość w chwili czasu nie ma żadnego znaczenia.\n",
    "\n",
    "Nakładamy maskę, żeby wyliczać atencję tylko na podstawie tokenów/chwil czasu, które chcemy, żeby model brał pod uwagę. Np. podczas uczenia generatora tekstu, będziemy maskowali wszystkie następne tokeny, ponieważ nie chcemy, żeby model genrował token na podstawie przyszłych tokenów, natomiast w przypadku klasyfikacji tekstu już taka maska nie jest potrzebna. Podczas trenowania nakłada też się zawsze maskę na tokeny odpowiadające paddingowi.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630e81ef686e4f34a9be93197609d4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
       "array([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,\n",
       "         102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliografia\n",
    "#### Sieci rekurencyjne\n",
    "* [RNN i LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [ELMo-Embeddingi z kontekstem](https://arxiv.org/abs/1802.05365v2)\n",
    "* [BERT ELMo zilustrowane](https://jalammar.github.io/illustrated-bert/)\n",
    "* [Bahdanau Attention](https://arxiv.org/abs/1508.04025)\n",
    "#### Transformery\n",
    "* [Artykuł wprowadzający transformery](https://arxiv.org/abs/1706.03762)\n",
    "* [Wizualizacje działania transformerów](https://jalammar.github.io/illustrated-transformer/)\n",
    "* [BERT](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tematy\n",
    "### Sub-word tokenizers:\n",
    "* [Byte-Pair Encoding](https://arxiv.org/abs/1508.07909)\n",
    "* [WordPiece](https://ai.googleblog.com/2021/12/a-fast-wordpiece-tokenization-system.html)\n",
    "* [Unigram Language Model](https://arxiv.org/pdf/1804.10959.pdf)\n",
    "* [SentencePiece](https://jacky2wong.medium.com/understanding-sentencepiece-under-standing-sentence-piece-ac8da59f6b08)\n",
    "### Embeddingi\n",
    "* [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [FastText](https://arxiv.org/pdf/1607.04606.pdf)\n",
    "* [Doc2Vec](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "## Biblioteki:\n",
    "* [NLTK](https://www.nltk.org/)\n",
    "* [Spacy](https://spacy.io/)\n",
    "* [FastText](https://fasttext.cc/)\n",
    "* [Hugging face tokenizers](https://huggingface.co/docs/tokenizers/python/latest/)\n",
    "* [Gensim](https://radimrehurek.com/gensim/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b480b8933f078b9bb649a28ef31ddb4e88638560591c0b6b6c9f25971fe4507f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
