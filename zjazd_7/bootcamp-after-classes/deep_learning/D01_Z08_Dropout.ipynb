{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.6746 - accuracy: 0.5951 - val_loss: 0.5648 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.5823 - accuracy: 0.7357 - val_loss: 0.5447 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.5513 - accuracy: 0.7490 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4870 - accuracy: 0.7818 - val_loss: 0.4240 - val_accuracy: 0.8254\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4442 - accuracy: 0.8060 - val_loss: 0.3936 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4260 - accuracy: 0.8121 - val_loss: 0.3789 - val_accuracy: 0.8374\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4109 - accuracy: 0.8183 - val_loss: 0.3698 - val_accuracy: 0.8384\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4020 - accuracy: 0.8189 - val_loss: 0.3636 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3947 - accuracy: 0.8215 - val_loss: 0.3590 - val_accuracy: 0.8373\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3911 - accuracy: 0.8213 - val_loss: 0.3571 - val_accuracy: 0.8374\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3901 - accuracy: 0.8230 - val_loss: 0.3555 - val_accuracy: 0.8376\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3871 - accuracy: 0.8215 - val_loss: 0.3539 - val_accuracy: 0.8381\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3897 - accuracy: 0.8213 - val_loss: 0.3528 - val_accuracy: 0.8390\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3836 - accuracy: 0.8229 - val_loss: 0.3515 - val_accuracy: 0.8386\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3808 - accuracy: 0.8273 - val_loss: 0.3502 - val_accuracy: 0.8383\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3794 - accuracy: 0.8273 - val_loss: 0.3490 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3793 - accuracy: 0.8258 - val_loss: 0.3481 - val_accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3770 - accuracy: 0.8291 - val_loss: 0.3471 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3789 - accuracy: 0.8276 - val_loss: 0.3463 - val_accuracy: 0.8415\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3772 - accuracy: 0.8280 - val_loss: 0.3459 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3770 - accuracy: 0.8286 - val_loss: 0.3455 - val_accuracy: 0.8422\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.3451 - val_accuracy: 0.8426\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3737 - accuracy: 0.8295 - val_loss: 0.3446 - val_accuracy: 0.8430\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3734 - accuracy: 0.8295 - val_loss: 0.3442 - val_accuracy: 0.8428\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3737 - accuracy: 0.8290 - val_loss: 0.3438 - val_accuracy: 0.8428\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3434 - val_accuracy: 0.8433\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3704 - accuracy: 0.8307 - val_loss: 0.3431 - val_accuracy: 0.8439\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3716 - accuracy: 0.8294 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3714 - accuracy: 0.8292 - val_loss: 0.3423 - val_accuracy: 0.8442\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3717 - accuracy: 0.8306 - val_loss: 0.3422 - val_accuracy: 0.8444\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3420 - val_accuracy: 0.8445\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3710 - accuracy: 0.8321 - val_loss: 0.3418 - val_accuracy: 0.8444\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3699 - accuracy: 0.8316 - val_loss: 0.3417 - val_accuracy: 0.8444\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3717 - accuracy: 0.8314 - val_loss: 0.3415 - val_accuracy: 0.8443\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3720 - accuracy: 0.8295 - val_loss: 0.3414 - val_accuracy: 0.8444\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3704 - accuracy: 0.8314 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3694 - accuracy: 0.8309 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3692 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3694 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8446\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3718 - accuracy: 0.8302 - val_loss: 0.3407 - val_accuracy: 0.8448\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3686 - accuracy: 0.8329 - val_loss: 0.3406 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 3s 91us/step - loss: 0.3685 - accuracy: 0.8316 - val_loss: 0.3405 - val_accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 3s 101us/step - loss: 0.3708 - accuracy: 0.8329 - val_loss: 0.3405 - val_accuracy: 0.8446\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 3s 102us/step - loss: 0.3726 - accuracy: 0.8296 - val_loss: 0.3404 - val_accuracy: 0.8446\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 3s 111us/step - loss: 0.3708 - accuracy: 0.8315 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 3s 106us/step - loss: 0.3694 - accuracy: 0.8306 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.3675 - accuracy: 0.8309 - val_loss: 0.3402 - val_accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 3s 102us/step - loss: 0.3688 - accuracy: 0.8328 - val_loss: 0.3401 - val_accuracy: 0.8448\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 3s 95us/step - loss: 0.3665 - accuracy: 0.8313 - val_loss: 0.3400 - val_accuracy: 0.8451\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 3s 101us/step - loss: 0.3685 - accuracy: 0.8335 - val_loss: 0.3400 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 3s 105us/step - loss: 0.3690 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 3s 107us/step - loss: 0.3671 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.3673 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 2s 60us/step - loss: 0.3697 - accuracy: 0.8318 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3689 - accuracy: 0.8316 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3669 - accuracy: 0.8320 - val_loss: 0.3398 - val_accuracy: 0.8448\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3680 - accuracy: 0.8323 - val_loss: 0.3397 - val_accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3668 - accuracy: 0.8328 - val_loss: 0.3397 - val_accuracy: 0.8448\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3674 - accuracy: 0.8323 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3679 - accuracy: 0.8328 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 3s 96us/step - loss: 0.3686 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 3s 108us/step - loss: 0.3698 - accuracy: 0.8330 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 3s 104us/step - loss: 0.3651 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3677 - accuracy: 0.8314 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3674 - accuracy: 0.8328 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3687 - accuracy: 0.8299 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3672 - accuracy: 0.8316 - val_loss: 0.3395 - val_accuracy: 0.8451\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 3s 83us/step - loss: 0.3669 - accuracy: 0.8330 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3693 - accuracy: 0.8314 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3672 - accuracy: 0.8322 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3692 - accuracy: 0.8296 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3677 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3661 - accuracy: 0.8300 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3675 - accuracy: 0.8327 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3690 - accuracy: 0.8292 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3671 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.8316 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3686 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3698 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3680 - accuracy: 0.8341 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3682 - accuracy: 0.8303 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3684 - accuracy: 0.8321 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3687 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3648 - accuracy: 0.8329 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3654 - accuracy: 0.8309 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3682 - accuracy: 0.8319 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3681 - accuracy: 0.8311 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3694 - accuracy: 0.8333 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3686 - accuracy: 0.8318 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3682 - accuracy: 0.8306 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.8328 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3678 - accuracy: 0.8320 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 98/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3713 - accuracy: 0.8297 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 99/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3665 - accuracy: 0.8330 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3660 - accuracy: 0.8332 - val_loss: 0.3393 - val_accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6facf3e358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniższego modelu dodaj modelu \n",
    "```python\n",
    "model.add(Dropout(0.8))\n",
    "```\n",
    "po każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5660 - val_loss: 0.6709 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.7139 - accuracy: 0.3962 - val_loss: 0.7082 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.6502 - accuracy: 0.5472 - val_loss: 0.6445 - val_accuracy: 0.7234\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.6412 - accuracy: 0.6981 - val_loss: 0.6156 - val_accuracy: 0.7447\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.5896 - accuracy: 0.8679 - val_loss: 0.6071 - val_accuracy: 0.7234\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 307us/step - loss: 0.5594 - accuracy: 0.7925 - val_loss: 0.6047 - val_accuracy: 0.7660\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.5359 - accuracy: 0.7736 - val_loss: 0.5546 - val_accuracy: 0.7660\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 692us/step - loss: 0.4880 - accuracy: 0.8113 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.4530 - accuracy: 0.8113 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 343us/step - loss: 0.4214 - accuracy: 0.8302 - val_loss: 0.5066 - val_accuracy: 0.7660\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3916 - accuracy: 0.8491 - val_loss: 0.4883 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3588 - accuracy: 0.8491 - val_loss: 0.4813 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3372 - accuracy: 0.8491 - val_loss: 0.4880 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3286 - accuracy: 0.8491 - val_loss: 0.4974 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3210 - accuracy: 0.8491 - val_loss: 0.5088 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3101 - accuracy: 0.8679 - val_loss: 0.5273 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2997 - accuracy: 0.8679 - val_loss: 0.5382 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2946 - accuracy: 0.8679 - val_loss: 0.5421 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2903 - accuracy: 0.8679 - val_loss: 0.5349 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 0.2728 - accuracy: 0.8679 - val_loss: 0.5011 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.4666 - val_accuracy: 0.8298\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2646 - accuracy: 0.8868 - val_loss: 0.4487 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2642 - accuracy: 0.8868 - val_loss: 0.4556 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2467 - accuracy: 0.8868 - val_loss: 0.4555 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2418 - accuracy: 0.9057 - val_loss: 0.4695 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2402 - accuracy: 0.9057 - val_loss: 0.4872 - val_accuracy: 0.8298\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2410 - accuracy: 0.9057 - val_loss: 0.4863 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2367 - accuracy: 0.9057 - val_loss: 0.4677 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2310 - accuracy: 0.8868 - val_loss: 0.4485 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2361 - accuracy: 0.9057 - val_loss: 0.4436 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.4669 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2256 - accuracy: 0.8868 - val_loss: 0.4905 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 751us/step - loss: 0.2218 - accuracy: 0.9057 - val_loss: 0.4892 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2175 - accuracy: 0.9057 - val_loss: 0.4910 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2157 - accuracy: 0.9057 - val_loss: 0.4887 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.2149 - accuracy: 0.8868 - val_loss: 0.4783 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2114 - accuracy: 0.8868 - val_loss: 0.4790 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.2095 - accuracy: 0.8868 - val_loss: 0.4740 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2077 - accuracy: 0.8868 - val_loss: 0.4778 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2060 - accuracy: 0.8868 - val_loss: 0.4780 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2058 - accuracy: 0.9057 - val_loss: 0.4709 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2027 - accuracy: 0.8868 - val_loss: 0.4763 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1997 - accuracy: 0.9057 - val_loss: 0.4868 - val_accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1997 - accuracy: 0.9057 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2005 - accuracy: 0.9057 - val_loss: 0.4905 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1976 - accuracy: 0.9057 - val_loss: 0.4671 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1934 - accuracy: 0.9057 - val_loss: 0.4561 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1949 - accuracy: 0.9057 - val_loss: 0.4421 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1942 - accuracy: 0.9057 - val_loss: 0.4501 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1890 - accuracy: 0.9245 - val_loss: 0.4562 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.4664 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1847 - accuracy: 0.9057 - val_loss: 0.4861 - val_accuracy: 0.8085\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1874 - accuracy: 0.9434 - val_loss: 0.4975 - val_accuracy: 0.8085\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1880 - accuracy: 0.9434 - val_loss: 0.4833 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1825 - accuracy: 0.9245 - val_loss: 0.4753 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.4608 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1818 - accuracy: 0.9245 - val_loss: 0.4382 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1855 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1847 - accuracy: 0.9245 - val_loss: 0.4647 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1782 - accuracy: 0.9245 - val_loss: 0.4749 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1731 - accuracy: 0.9434 - val_loss: 0.4601 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1701 - accuracy: 0.9434 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1703 - accuracy: 0.9245 - val_loss: 0.4209 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1692 - accuracy: 0.9245 - val_loss: 0.4244 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1679 - accuracy: 0.9245 - val_loss: 0.4249 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1640 - accuracy: 0.9434 - val_loss: 0.4132 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1650 - accuracy: 0.9434 - val_loss: 0.4085 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1649 - accuracy: 0.9434 - val_loss: 0.3938 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1642 - accuracy: 0.9245 - val_loss: 0.3991 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1585 - accuracy: 0.9434 - val_loss: 0.4306 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1594 - accuracy: 0.9811 - val_loss: 0.4427 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1568 - accuracy: 0.9811 - val_loss: 0.4257 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1542 - accuracy: 0.9623 - val_loss: 0.4012 - val_accuracy: 0.8511\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1501 - accuracy: 0.9245 - val_loss: 0.3946 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1501 - accuracy: 0.9245 - val_loss: 0.3983 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1520 - accuracy: 0.9434 - val_loss: 0.4185 - val_accuracy: 0.8298\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1433 - accuracy: 0.9623 - val_loss: 0.4168 - val_accuracy: 0.8298\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1431 - accuracy: 0.9623 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1442 - accuracy: 0.9623 - val_loss: 0.3901 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.3932 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1352 - accuracy: 0.9623 - val_loss: 0.4091 - val_accuracy: 0.8723\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1357 - accuracy: 0.9811 - val_loss: 0.4125 - val_accuracy: 0.8511\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1320 - accuracy: 0.9811 - val_loss: 0.3911 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1279 - accuracy: 0.9623 - val_loss: 0.3733 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1309 - accuracy: 0.9623 - val_loss: 0.3575 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1285 - accuracy: 0.9623 - val_loss: 0.3694 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1234 - accuracy: 0.9623 - val_loss: 0.3669 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1190 - accuracy: 0.9811 - val_loss: 0.3748 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1193 - accuracy: 0.9811 - val_loss: 0.3851 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1196 - accuracy: 0.9811 - val_loss: 0.3628 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1138 - accuracy: 0.9811 - val_loss: 0.3434 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1103 - accuracy: 0.9811 - val_loss: 0.3236 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1075 - accuracy: 0.9811 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1065 - accuracy: 0.9811 - val_loss: 0.3062 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1037 - accuracy: 0.9811 - val_loss: 0.2998 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0953 - accuracy: 0.9811 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0936 - accuracy: 0.9811 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0898 - accuracy: 0.9811 - val_loss: 0.2777 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0887 - accuracy: 0.9811 - val_loss: 0.2565 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0864 - accuracy: 0.9811 - val_loss: 0.2498 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0831 - accuracy: 0.9811 - val_loss: 0.2522 - val_accuracy: 0.8936\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0791 - accuracy: 0.9811 - val_loss: 0.2653 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0807 - accuracy: 0.9811 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0780 - accuracy: 0.9811 - val_loss: 0.2509 - val_accuracy: 0.8936\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 0.0720 - accuracy: 0.9811 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0706 - accuracy: 0.9811 - val_loss: 0.2194 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0697 - accuracy: 0.9811 - val_loss: 0.2157 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.96 - 0s 510us/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0634 - accuracy: 0.9811 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 397us/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0472 - accuracy: 0.9811 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0425 - accuracy: 0.9811 - val_loss: 0.2084 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 732us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9362\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9149\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 486us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9362\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9149\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9149\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9149\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 384us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9149\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9149\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9149\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9149\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9362\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9149\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9149\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 674us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 510us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 534us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 485us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 742us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 473us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 587us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 397us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 295us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 315us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 737us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 465us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 557us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 448us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 507us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 447us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 754us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 328us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 532us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 286us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 8.7944e-04 - accuracy: 1.00 - 0s 295us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 805us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.9960e-04 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8571e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8943e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8706e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 9.6970e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.5447e-04 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.6565e-04 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 9.7161e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.2803e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.3436e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.7484e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 510us/step - loss: 9.3502e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.1319e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.1184e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 9.1946e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.3781e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0889e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 9.3812e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.8627e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0914e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.7748e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7298e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.6785e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 8.8733e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.5873e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.5609e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7141e-04 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 8.4705e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.5990e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 8.5121e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.3893e-04 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.7774e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.4253e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 7.3765e-04 - accuracy: 1.00 - 0s 510us/step - loss: 8.8682e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2285e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.6128e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2567e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.4942e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2893e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.0047e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.9346e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.0067e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9443e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.9252e-04 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 7.9930e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.4386e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9923e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.2327e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.6456e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.6376e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.6493e-04 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.7398e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.4788e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.4420e-04 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.5446e-04 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.6789e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 7.6126e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.4630e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.4327e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.3272e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.1927e-04 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2175e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.1091e-04 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.1123e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2352e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.3595e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.3143e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.1648e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.8400e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.7314e-04 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2385e-04 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.6885e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.1498e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.3717e-04 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.7602e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.0739e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.8077e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.6787e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.0308e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.7191e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.5998e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.6071e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.5650e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.6940e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.5475e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.3918e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 490us/step - loss: 6.3688e-04 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.4532e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3318e-04 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3406e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 6.4459e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 652us/step - loss: 6.2658e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.2335e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 487us/step - loss: 6.2904e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.1561e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.1239e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 754us/step - loss: 6.1495e-04 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 6.2779e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 6.2555e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.2143e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3030e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.9768e-04 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.0289e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.9137e-04 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.9070e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.2658e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.2248e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.9506e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.7761e-04 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.6628e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 5.9052e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.2084e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.9529e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.5963e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.6357e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 6.2472e-04 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.0384e-04 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.8872e-04 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.6022e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.5059e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 5.5547e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.8528e-04 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.6470e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4401e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4032e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.7029e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 855us/step - loss: 5.5906e-04 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 416us/step - loss: 5.3668e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.5889e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.3463e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 5.2795e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 435us/step - loss: 5.3512e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4637e-04 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 634us/step - loss: 5.3074e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.1127e-04 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 371us/step - loss: 5.5154e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.2329e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 5.2467e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.1716e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 795us/step - loss: 5.0800e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.0277e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 5.0116e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 801us/step - loss: 5.0174e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.0039e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.0395e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.9104e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.8998e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.8735e-04 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.9032e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.2587e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 5.0607e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.9102e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.0039e-04 - accuracy: 1.0000 - val_loss: 0.3153 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.8974e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.8871e-04 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.7170e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7858e-04 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6784e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6713e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6646e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6483e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6245e-04 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7129e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5719e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6296e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5411e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5396e-04 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5989e-04 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6668e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.5497e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4511e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4438e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4807e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4752e-04 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4435e-04 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.3817e-04 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.3495e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.3364e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.3262e-04 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 420us/step - loss: 4.3192e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.3079e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.3427e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2615e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2397e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 695us/step - loss: 4.2847e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 316us/step - loss: 4.2280e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2903e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2578e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.3524e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.2535e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.1658e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.1186e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2920e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.1561e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 4.2040e-04 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 4.0515e-04 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.0317e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 4.0143e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.9946e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 723us/step - loss: 3.9867e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.0498e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.0893e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9449e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9298e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9139e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9891e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 461us/step - loss: 4.0041e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 3.8757e-04 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 3.9133e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.8443e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.8350e-04 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.9400e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8362e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.7994e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8043e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.9283e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8587e-04 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 3.7651e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 404us/step - loss: 3.7337e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 5.3739e-04 - accuracy: 1.00 - 0s 720us/step - loss: 3.7255e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.7868e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.7796e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.7371e-04 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6891e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6515e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.7596e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6375e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6631e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.7378e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.6422e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6966e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.6737e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6029e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6509e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.5774e-04 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5174e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6336e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.5086e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5406e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4735e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5750e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5132e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 572us/step - loss: 3.4713e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.4240e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.4284e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.4991e-04 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.5167e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.4526e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.3988e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3536e-04 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.4735e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4309e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.3219e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4250e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.3644e-04 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3051e-04 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2624e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2533e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2718e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.2877e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.3372e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2881e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.2870e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2014e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1798e-04 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1557e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2826e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 3.2356e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.1410e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.1167e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 675us/step - loss: 3.1042e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2225e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1313e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0958e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 4.4655e-04 - accuracy: 1.00 - 0s 491us/step - loss: 3.0659e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0519e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0454e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0432e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1007e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0303e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0099e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1202e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0084e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0495e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9802e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9730e-04 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.0142e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.9428e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.9373e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9797e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9124e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.9428e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.9817e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8994e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9119e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9724e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8929e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8632e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8471e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8579e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8654e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8427e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.8227e-04 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7945e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8699e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8269e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7755e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7601e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7401e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7545e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 568us/step - loss: 2.7912e-04 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8910e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8191e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.7770e-04 - accuracy: 1.00 - 0s 491us/step - loss: 2.8758e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6977e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6907e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7090e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.6989e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.7929e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.6699e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.6565e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6281e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6207e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6826e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6327e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6506e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6117e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5610e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.6253e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5489e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.5404e-04 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5258e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5226e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5166e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5546e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5127e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4903e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5767e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5001e-04 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5156e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4740e-04 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 2.4518e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.5291e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4568e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4658e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.4314e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 2.4996e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.4534e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.4640e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4628e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4235e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3823e-04 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3775e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3711e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3650e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.3507e-04 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3453e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3350e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3309e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3242e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3494e-04 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3702e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3021e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3271e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.2798e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2725e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2680e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2600e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2850e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.2351e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2533e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2723e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2659e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2657e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3121e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 369us/step - loss: 2.2416e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2048e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.1899e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2651e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2106e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1848e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2170e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1452e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1382e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 729us/step - loss: 2.1318e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 394us/step - loss: 2.1732e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.1156e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1107e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1463e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1391e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0901e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0839e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.0786e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1091e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0699e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0586e-04 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0559e-04 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0524e-04 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0765e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0578e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0363e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0873e-04 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0826e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0223e-04 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0145e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0440e-04 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 737us/step - loss: 2.0359e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.9944e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.9874e-04 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.9985e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 400us/step - loss: 1.9770e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9761e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9759e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9724e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 833us/step - loss: 1.9661e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 1.9918e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9712e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9909e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9427e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9516e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9240e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9217e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9329e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9502e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9423e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9367e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9284e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9258e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9098e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8922e-04 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 1.8773e-04 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8692e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8642e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8985e-04 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8569e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8519e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8394e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8362e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8613e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8719e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 672us/step - loss: 1.8423e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8606e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8358e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8032e-04 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8080e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 1.8544e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7986e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8139e-04 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7809e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8198e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7691e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7903e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7596e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7562e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7526e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7480e-04 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7627e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7831e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7287e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7512e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7215e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7126e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7153e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7149e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7104e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7200e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7422e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6833e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6756e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.6727e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6632e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6961e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 671us/step - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6871e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6412e-04 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6575e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6411e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6295e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6259e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6911e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6743e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6430e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.5969e-04 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 1.6591e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6103e-04 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6077e-04 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6095e-04 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.5899e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6fae1d4da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "\n",
    "# Zad.\n",
    "Do do modelu \n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
    "```\n",
    "\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "history_Adam_2 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],), activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(500,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(200,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
