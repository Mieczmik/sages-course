{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import History\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49, 28], [41, 26], [29, 8], [42, 26], [30], [17], [13, 8], [13, 41], [13, 26], [27, 4, 28, 25]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49 28  0  0]\n",
      " [41 26  0  0]\n",
      " [29  8  0  0]\n",
      " [42 26  0  0]\n",
      " [30  0  0  0]\n",
      " [17  0  0  0]\n",
      " [13  8  0  0]\n",
      " [13 41  0  0]\n",
      " [13 26  0  0]\n",
      " [27  4 28 25]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5873 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.5853 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.5834 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.5815 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 336us/step - loss: 0.5795 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5776 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.5757 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 330us/step - loss: 0.5737 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5718 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 447us/step - loss: 0.5699 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.5679 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5660 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5641 - accuracy: 1.0000 - val_loss: 0.5141 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 0.5622 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5603 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 780us/step - loss: 0.5583 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.5564 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5545 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5526 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5507 - accuracy: 0.8889 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5488 - accuracy: 0.8889 - val_loss: 0.5160 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5468 - accuracy: 0.8889 - val_loss: 0.5162 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5449 - accuracy: 0.8889 - val_loss: 0.5164 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.5430 - accuracy: 0.8889 - val_loss: 0.5166 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5411 - accuracy: 0.8889 - val_loss: 0.5168 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 220us/step - loss: 0.5392 - accuracy: 0.8889 - val_loss: 0.5169 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.5373 - accuracy: 0.8889 - val_loss: 0.5171 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5354 - accuracy: 0.8889 - val_loss: 0.5173 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.5335 - accuracy: 0.8889 - val_loss: 0.5174 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 225us/step - loss: 0.5316 - accuracy: 0.8889 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 441us/step - loss: 0.5296 - accuracy: 0.8889 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5277 - accuracy: 0.8889 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5258 - accuracy: 0.8889 - val_loss: 0.5180 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5239 - accuracy: 0.8889 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5220 - accuracy: 0.8889 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.5201 - accuracy: 0.8889 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 440us/step - loss: 0.5182 - accuracy: 0.8889 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 449us/step - loss: 0.5163 - accuracy: 0.8889 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.5143 - accuracy: 0.8889 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5124 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 0.5105 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5086 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5066 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5047 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.5028 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5009 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4989 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4970 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4951 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 0.4931 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 321us/step - loss: 0.4912 - accuracy: 0.8889 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4893 - accuracy: 0.8889 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 217us/step - loss: 0.4873 - accuracy: 0.8889 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.4854 - accuracy: 0.8889 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4835 - accuracy: 0.8889 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 111us/step - loss: 0.4815 - accuracy: 0.8889 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.4796 - accuracy: 0.8889 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4777 - accuracy: 0.8889 - val_loss: 0.5182 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 217us/step - loss: 0.4757 - accuracy: 0.8889 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 217us/step - loss: 0.4738 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 217us/step - loss: 0.4718 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 217us/step - loss: 0.4699 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.4680 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.4660 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4641 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.4621 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4602 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4582 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4563 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4544 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4524 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4505 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4486 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4466 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.4447 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4427 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4408 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4389 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 449us/step - loss: 0.4369 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 330us/step - loss: 0.4350 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.4331 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 225us/step - loss: 0.4312 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 297us/step - loss: 0.4292 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4273 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 330us/step - loss: 0.4254 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.4235 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 0.4216 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4196 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4177 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 0.4158 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4139 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 451us/step - loss: 0.4120 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 351us/step - loss: 0.4101 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 440us/step - loss: 0.4082 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4063 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 337us/step - loss: 0.4044 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4025 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4006 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.3987 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 447us/step - loss: 0.3968 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1eae93ddf60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1891e-01,  1.5255e-01, -8.2073e-02, -7.4144e-01,  7.5917e-01,\n",
       "       -4.8328e-01, -3.1009e-01,  5.1476e-01, -9.8708e-01,  6.1757e-04,\n",
       "       -1.5043e-01,  8.3770e-01, -1.0797e+00, -5.1460e-01,  1.3188e+00,\n",
       "        6.2007e-01,  1.3779e-01,  4.7108e-01, -7.2874e-02, -7.2675e-01,\n",
       "       -7.4116e-01,  7.5263e-01,  8.8180e-01,  2.9561e-01,  1.3548e+00,\n",
       "       -2.5701e+00, -1.3523e+00,  4.5880e-01,  1.0068e+00, -1.1856e+00,\n",
       "        3.4737e+00,  7.7898e-01, -7.2929e-01,  2.5102e-01, -2.6156e-01,\n",
       "       -3.4684e-01,  5.5841e-01,  7.5098e-01,  4.9830e-01, -2.6823e-01,\n",
       "       -2.7443e-03, -1.8298e-02, -2.8096e-01,  5.5318e-01,  3.7706e-02,\n",
       "        1.8555e-01, -1.5025e-01, -5.7512e-01, -2.6671e-01,  9.2121e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 50)             750       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 201\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5556 - val_loss: 0.5185 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.6706 - accuracy: 0.5556 - val_loss: 0.5102 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.6638 - accuracy: 0.5556 - val_loss: 0.5028 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.6577 - accuracy: 0.6667 - val_loss: 0.4953 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.6515 - accuracy: 0.6667 - val_loss: 0.4876 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.6451 - accuracy: 0.6667 - val_loss: 0.4802 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 337us/step - loss: 0.6389 - accuracy: 0.6667 - val_loss: 0.4730 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.6329 - accuracy: 0.6667 - val_loss: 0.4659 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.6270 - accuracy: 0.6667 - val_loss: 0.4591 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.6211 - accuracy: 0.6667 - val_loss: 0.4524 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.6154 - accuracy: 0.6667 - val_loss: 0.4460 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.6097 - accuracy: 0.6667 - val_loss: 0.4398 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 225us/step - loss: 0.6042 - accuracy: 0.6667 - val_loss: 0.4338 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5988 - accuracy: 0.6667 - val_loss: 0.4282 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.5935 - accuracy: 0.6667 - val_loss: 0.4228 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.5884 - accuracy: 0.6667 - val_loss: 0.4176 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.5834 - accuracy: 0.6667 - val_loss: 0.4127 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5784 - accuracy: 0.6667 - val_loss: 0.4081 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5736 - accuracy: 0.6667 - val_loss: 0.4036 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.5688 - accuracy: 0.6667 - val_loss: 0.3995 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.5642 - accuracy: 0.7778 - val_loss: 0.3956 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5596 - accuracy: 0.7778 - val_loss: 0.3919 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5551 - accuracy: 0.7778 - val_loss: 0.3885 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.5507 - accuracy: 0.7778 - val_loss: 0.3853 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5465 - accuracy: 0.8889 - val_loss: 0.3823 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.5422 - accuracy: 0.8889 - val_loss: 0.3796 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.5380 - accuracy: 0.8889 - val_loss: 0.3771 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.5340 - accuracy: 0.8889 - val_loss: 0.3748 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5299 - accuracy: 0.8889 - val_loss: 0.3727 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5259 - accuracy: 0.8889 - val_loss: 0.3708 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5219 - accuracy: 0.8889 - val_loss: 0.3690 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.5180 - accuracy: 0.8889 - val_loss: 0.3675 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.5142 - accuracy: 0.8889 - val_loss: 0.3661 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5104 - accuracy: 0.8889 - val_loss: 0.3649 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5066 - accuracy: 0.8889 - val_loss: 0.3638 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5029 - accuracy: 0.8889 - val_loss: 0.3629 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4992 - accuracy: 0.8889 - val_loss: 0.3622 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 227us/step - loss: 0.4955 - accuracy: 0.8889 - val_loss: 0.3615 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.4920 - accuracy: 0.8889 - val_loss: 0.3610 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 331us/step - loss: 0.4884 - accuracy: 0.8889 - val_loss: 0.3606 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.4848 - accuracy: 0.8889 - val_loss: 0.3603 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.4813 - accuracy: 0.8889 - val_loss: 0.3601 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4779 - accuracy: 0.8889 - val_loss: 0.3600 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4745 - accuracy: 0.8889 - val_loss: 0.3600 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4711 - accuracy: 0.8889 - val_loss: 0.3600 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.4677 - accuracy: 0.8889 - val_loss: 0.3602 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.4644 - accuracy: 0.8889 - val_loss: 0.3604 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 337us/step - loss: 0.4611 - accuracy: 0.8889 - val_loss: 0.3606 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4579 - accuracy: 0.8889 - val_loss: 0.3609 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4546 - accuracy: 0.8889 - val_loss: 0.3613 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.4515 - accuracy: 0.8889 - val_loss: 0.3617 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 337us/step - loss: 0.4483 - accuracy: 0.8889 - val_loss: 0.3621 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4452 - accuracy: 0.8889 - val_loss: 0.3625 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4421 - accuracy: 0.8889 - val_loss: 0.3630 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.4390 - accuracy: 0.8889 - val_loss: 0.3636 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4360 - accuracy: 0.8889 - val_loss: 0.3641 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4330 - accuracy: 0.8889 - val_loss: 0.3647 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 442us/step - loss: 0.4300 - accuracy: 0.8889 - val_loss: 0.3652 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4270 - accuracy: 0.8889 - val_loss: 0.3658 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4240 - accuracy: 0.8889 - val_loss: 0.3664 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.4211 - accuracy: 0.8889 - val_loss: 0.3670 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.4183 - accuracy: 0.8889 - val_loss: 0.3677 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.4154 - accuracy: 0.8889 - val_loss: 0.3683 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.4126 - accuracy: 0.8889 - val_loss: 0.3689 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4098 - accuracy: 0.8889 - val_loss: 0.3695 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 337us/step - loss: 0.4070 - accuracy: 0.8889 - val_loss: 0.3701 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4043 - accuracy: 0.8889 - val_loss: 0.3707 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4016 - accuracy: 0.8889 - val_loss: 0.3714 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 336us/step - loss: 0.3989 - accuracy: 0.8889 - val_loss: 0.3720 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.3962 - accuracy: 0.8889 - val_loss: 0.3726 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.3935 - accuracy: 0.8889 - val_loss: 0.3732 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.3909 - accuracy: 0.8889 - val_loss: 0.3738 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 440us/step - loss: 0.3883 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3857 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3806 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 220us/step - loss: 0.3781 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.3756 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3732 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3707 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 218us/step - loss: 0.3659 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 226us/step - loss: 0.3635 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.3612 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.3588 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 336us/step - loss: 0.3565 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.3519 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.3497 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 328us/step - loss: 0.3474 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 329us/step - loss: 0.3452 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 439us/step - loss: 0.3430 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 219us/step - loss: 0.3408 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 221us/step - loss: 0.3387 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.3365 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3344 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.3323 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.3302 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.3282 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1eaf2b04dd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
