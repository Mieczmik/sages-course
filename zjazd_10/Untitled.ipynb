{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed62cf8-9e4a-46da-858f-a58726b7d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m531.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.6.2-cp310-cp310-macosx_11_0_arm64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.8/281.8 kB\u001b[0m \u001b[31m268.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m447.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m634.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.7 regex-2022.6.2 tqdm-4.64.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efccefe-81db-4863-b033-ce41f86bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea55e66-23d5-409b-918d-6704a988f230",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/mikolajmiecznikowski/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc2f678-86ec-43ba-8708-acacb9ea6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>In <a href=\"/wiki/Mathematics\" title=\"Mathematics\">mathematics</a>, an <b>integral</b> assigns numbers to functions in a way that describes displacement, <a href=\"/wiki/Area\" title=\"Area\">area</a>,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "wiki = \"http://en.wikipedia.org/wiki/\"\n",
    "titles = [\"Integral\", \"Riemann_integral\", \"Riemann-Stieltjes_integral\", \"Derivative\",\n",
    "    \"Limit_of_a_sequence\", \"Edvard_Munch\", \"Vincent_van_Gogh\", \"Jan_Matejko\",\n",
    "    \"Lev_Tolstoj\", \"Franz_Kafka\", \"J._R._R._Tolkien\"]\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def parse(url):        \n",
    "    x = urlopen(url).read()\n",
    "    x = BeautifulSoup(x).find(\"div\",id=\"bodyContent\").find_all(\"p\")\n",
    "    return(x)\n",
    "\n",
    "articles = [parse(url) for url in [wiki+x for x in titles]]\n",
    "articles = [\" \".join([str(paragraph) for paragraph in article]) for article in articles]\n",
    "\n",
    "articles[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58818804-dbc8-4222-847f-1bc29b2c3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6710269-8324-44bf-a98d-6c96f42a53a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In  mathematics , an  integral  assigns numbers to functions in a way that describes displacement,  area ,  volume , and other concepts that arise by combining  infinitesimal  data. The process of finding integrals is called  integration . Along with  differentiation , integration is a fundamental, essential operation of  calculus ,  [a]   and serves as a tool to solve problems in mathematics and  physics  involving the area of an arbitrary shape, the length of a curve, and the volume of a soli'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [re.sub(\"<.+?>\",\" \",art) for art in articles]\n",
    "articles[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8922db-2243-4cef-b82e-95cf5882500c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" in  mathematics , an  integral  assigns numbers to functions in a way that describes displacement,  area ,  volume , and other concepts that arise by combining  infinitesimal  data. the process of finding integrals is called  integration . along with  differentiation , integration is a fundamental, essential operation of  calculus ,  [a]   and serves as a tool to solve problems in mathematics and  physics  involving the area of an arbitrary shape, the length of a curve, and the volume of a solid, among others.\\n   the integrals enumerated here are those termed  definite integrals , which can be interpreted as the signed  area  of the region in the plane that is bounded by the  graph  of a given  function  between two points in the  real line . conventionally, areas above the horizontal axis of the plane are positive while areas below are negative. integrals also refer to the concept of an  antiderivative , a function whose derivative is the given function. in this case, they are called  indefinite integrals . the  fundamental theorem of calculus  relates definite integrals with differentiation and provides a method to compute the definite integral of a function when its antiderivative is known.\\n   although methods of calculating areas and volumes dated from  ancient greek mathematics , the principles of integration were formulated independently by  isaac newton  and  gottfried wilhelm leibniz  in the late 17th century, who thought of the area under a curve as an infinite sum of rectangles of  infinitesimal  width.  bernhard riemann  later gave a rigorous definition of integrals, which is based on a limiting procedure that approximates the area of a  curvilinear  region by breaking the region into infinitesimally thin vertical slabs. in the early 20th century,  henri lebesgue  generalized riemann's formulation by introducing what is now referred to as the  lebesgue integral ; it is more robust than riemann's in the sense that a wider class of functions are lebesgue-integrable. \\n   integrals may be generalized depending on the type of the function as well as the  domain  over which the integration is performed. for example, a  line integral  is defined for functions of two or more variables, and the  interval  of integration is replaced by a curve connecting the two endpoints of the interval. in a  surface integral , the curve is replaced by a piece of a  surface  in  three-dimensional space .\\n   the first documented systematic technique capable of determining integrals is the  method of exhaustion  of the  ancient greek  astronomer  eudoxus  ( ca.  370 bc), which sought to find areas and volumes by breaking them up into an infinite number of divisions for which the area or volume was known.  [1]   this method was further developed and employed by  archimedes  in the 3rd century bc and used to calculate the  area of a circle , the  surface area  and  volume  of a  sphere , area of an  ellipse , the area under a  parabola , the volume of a segment of a  paraboloid  of revolution, the volume of a segment of a  hyperboloid  of revolution, and the area of a  spiral .  [2]  \\n   a similar method was independently developed in  china  around the 3rd century ad by  liu hui , who used it to find the area of the circle. this method was later used in the 5th century by chinese father-and-son mathematicians  zu chongzhi  and  zu geng  to find the volume of a sphere.  [3]  \\n   in the middle east, hasan ibn al-haytham, latinized as  alhazen  ( c.  \\u2009965 \\xa0– c. \\u20091040 \\xa0ad) derived a formula for the sum of  fourth powers .  [4]   he used the results to carry out what would now be called an integration of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a  paraboloid .  [5]  \\n   the next significant advances in integral calculus did not begin to appear until the 17th century. at this time, the work of  cavalieri  with his  method of indivisibles , and work by  fermat , began to lay the foundations of modern calculus,  [6]   with cavalieri computing the integrals of   x   n    up to degree   n  = 9  in  cavalieri's quadrature formula .  [7]   further steps were made in the early 17th century by  barrow  and  torricelli , who provided the first hints of a connection between integration and  differentiation . barrow provided the first proof of the  fundamental theorem of calculus .  [8]    wallis  generalized cavalieri's method, computing integrals of  x  to a general power, including negative powers and fractional powers.  [9]  \\n   the major advance in integration came in the 17th century with the independent discovery of the  fundamental theorem of calculus  by  leibniz  and  newton .  [10]   the theorem demonstrates a connection between integration and differentiation. this connection, combined with the comparative ease of differentiation, can be exploited to calculate integrals. in particular, the fundamental theorem of calculus allows one to solve a muc\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [art.lower() for art in articles]\n",
    "articles[0][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef2eac-5967-4379-b950-ad1705b6b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae371f7-cc2f-4a2a-abb3-cf19b52a1c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreebankWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank.\n",
       "\n",
       "This tokenizer performs the following steps:\n",
       "\n",
       "- split standard contractions, e.g. ``don't`` -> ``do n't`` and ``they'll`` -> ``they 'll``\n",
       "- treat most punctuation characters as separate tokens\n",
       "- split off commas and single quotes, when followed by whitespace\n",
       "- separate periods that appear at the end of line\n",
       "\n",
       ">>> from nltk.tokenize import TreebankWordTokenizer\n",
       ">>> s = '''Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\nThanks.'''\n",
       ">>> TreebankWordTokenizer().tokenize(s)\n",
       "['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Please', 'buy', 'me', 'two', 'of', 'them.', 'Thanks', '.']\n",
       ">>> s = \"They'll save and invest more.\"\n",
       ">>> TreebankWordTokenizer().tokenize(s)\n",
       "['They', \"'ll\", 'save', 'and', 'invest', 'more', '.']\n",
       ">>> s = \"hi, my name can't hello,\"\n",
       ">>> TreebankWordTokenizer().tokenize(s)\n",
       "['hi', ',', 'my', 'name', 'ca', \"n't\", 'hello', ',']\n",
       "\u001b[0;31mFile:\u001b[0m           /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nltk/tokenize/treebank.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nltk.TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2fc9f9-93e5-4c69-8457-3972aa5744ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# można usunąć przypisy regexem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ffa48-b298-442a-b071-2fb67bcfd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rozbicie tekstów na tokeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b8ef704-1d6b-4c6c-8907-cfe292250d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'an',\n",
       " 'integral',\n",
       " 'assigns',\n",
       " 'numbers',\n",
       " 'to',\n",
       " 'functions',\n",
       " 'in']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [nltk.word_tokenize(art) for art in articles]\n",
    "articles[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a1033-f579-4766-a4dd-c497702e706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwanie stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1324010d-f58b-4b17-9e09-8503a447d41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mathematics',\n",
       " ',',\n",
       " 'integral',\n",
       " 'assigns',\n",
       " 'numbers',\n",
       " 'functions',\n",
       " 'way',\n",
       " 'describes',\n",
       " 'displacement',\n",
       " ',']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\")) # mozna tokenizowac stopwordsy\n",
    "articles = [[word for word in art if word not in stopwords] for art in articles]\n",
    "articles[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df021eb-7e28-4cee-a36f-f76024a4ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afa76d88-7eba-4b30-a68a-b349a47702ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Liczba unikalnych slow przed stemmowaniem:\n",
    "len(set(articles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f79e510-4a2b-45bb-8107-bb28f8327ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mathemat'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "stemmer.stem(\"mathematically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a75cd33-23ee-4412-aed5-59e6532952d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [[stemmer.stem(word) for word in art] for art in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b940a96d-67b8-4c1c-b255-60948ed610c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(articles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b521ef9c-ef0e-40b0-bf98-b8f2a2554377",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mathemat',\n",
       " ',',\n",
       " 'integr',\n",
       " 'assign',\n",
       " 'number',\n",
       " 'function',\n",
       " 'way',\n",
       " 'describ',\n",
       " 'displac',\n",
       " ',',\n",
       " 'area',\n",
       " ',',\n",
       " 'volum',\n",
       " ',',\n",
       " 'concept',\n",
       " 'aris',\n",
       " 'combin',\n",
       " 'infinitesim',\n",
       " 'data',\n",
       " '.',\n",
       " 'process',\n",
       " 'find',\n",
       " 'integr',\n",
       " 'call',\n",
       " 'integr',\n",
       " '.',\n",
       " 'along',\n",
       " 'differenti',\n",
       " ',',\n",
       " 'integr',\n",
       " 'fundament',\n",
       " ',',\n",
       " 'essenti',\n",
       " 'oper',\n",
       " 'calculu',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " 'serv',\n",
       " 'tool',\n",
       " 'solv',\n",
       " 'problem',\n",
       " 'mathemat',\n",
       " 'physic',\n",
       " 'involv',\n",
       " 'area',\n",
       " 'arbitrari',\n",
       " 'shape',\n",
       " ',',\n",
       " 'length',\n",
       " 'curv',\n",
       " ',',\n",
       " 'volum',\n",
       " 'solid',\n",
       " ',',\n",
       " 'among',\n",
       " 'other',\n",
       " '.',\n",
       " 'integr',\n",
       " 'enumer',\n",
       " 'term',\n",
       " 'definit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'interpret',\n",
       " 'sign',\n",
       " 'area',\n",
       " 'region',\n",
       " 'plane',\n",
       " 'bound',\n",
       " 'graph',\n",
       " 'given',\n",
       " 'function',\n",
       " 'two',\n",
       " 'point',\n",
       " 'real',\n",
       " 'line',\n",
       " '.',\n",
       " 'convent',\n",
       " ',',\n",
       " 'area',\n",
       " 'horizont',\n",
       " 'axi',\n",
       " 'plane',\n",
       " 'posit',\n",
       " 'area',\n",
       " 'neg',\n",
       " '.',\n",
       " 'integr',\n",
       " 'also',\n",
       " 'refer',\n",
       " 'concept',\n",
       " 'antideriv',\n",
       " ',',\n",
       " 'function',\n",
       " 'whose',\n",
       " 'deriv',\n",
       " 'given',\n",
       " 'function',\n",
       " '.',\n",
       " 'case',\n",
       " ',',\n",
       " 'call',\n",
       " 'indefinit',\n",
       " 'integr',\n",
       " '.',\n",
       " 'fundament',\n",
       " 'theorem',\n",
       " 'calculu',\n",
       " 'relat',\n",
       " 'definit',\n",
       " 'integr',\n",
       " 'differenti',\n",
       " 'provid',\n",
       " 'method',\n",
       " 'comput',\n",
       " 'definit',\n",
       " 'integr',\n",
       " 'function',\n",
       " 'antideriv',\n",
       " 'known',\n",
       " '.',\n",
       " 'although',\n",
       " 'method',\n",
       " 'calcul',\n",
       " 'area',\n",
       " 'volum',\n",
       " 'date',\n",
       " 'ancient',\n",
       " 'greek',\n",
       " 'mathemat',\n",
       " ',',\n",
       " 'principl',\n",
       " 'integr',\n",
       " 'formul',\n",
       " 'independ',\n",
       " 'isaac',\n",
       " 'newton',\n",
       " 'gottfri',\n",
       " 'wilhelm',\n",
       " 'leibniz',\n",
       " 'late',\n",
       " '17th',\n",
       " 'centuri',\n",
       " ',',\n",
       " 'thought',\n",
       " 'area',\n",
       " 'curv',\n",
       " 'infinit',\n",
       " 'sum',\n",
       " 'rectangl',\n",
       " 'infinitesim',\n",
       " 'width',\n",
       " '.',\n",
       " 'bernhard',\n",
       " 'riemann',\n",
       " 'later',\n",
       " 'gave',\n",
       " 'rigor',\n",
       " 'definit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'base',\n",
       " 'limit',\n",
       " 'procedur',\n",
       " 'approxim',\n",
       " 'area',\n",
       " 'curvilinear',\n",
       " 'region',\n",
       " 'break',\n",
       " 'region',\n",
       " 'infinitesim',\n",
       " 'thin',\n",
       " 'vertic',\n",
       " 'slab',\n",
       " '.',\n",
       " 'earli',\n",
       " '20th',\n",
       " 'centuri',\n",
       " ',',\n",
       " 'henri',\n",
       " 'lebesgu',\n",
       " 'gener',\n",
       " 'riemann',\n",
       " \"'s\",\n",
       " 'formul',\n",
       " 'introduc',\n",
       " 'refer',\n",
       " 'lebesgu',\n",
       " 'integr',\n",
       " ';',\n",
       " 'robust',\n",
       " 'riemann',\n",
       " \"'s\",\n",
       " 'sens',\n",
       " 'wider',\n",
       " 'class',\n",
       " 'function',\n",
       " 'lebesgue-integr',\n",
       " '.',\n",
       " 'integr',\n",
       " 'may',\n",
       " 'gener',\n",
       " 'depend',\n",
       " 'type',\n",
       " 'function',\n",
       " 'well',\n",
       " 'domain',\n",
       " 'integr',\n",
       " 'perform',\n",
       " '.',\n",
       " 'exampl',\n",
       " ',',\n",
       " 'line',\n",
       " 'integr',\n",
       " 'defin',\n",
       " 'function',\n",
       " 'two',\n",
       " 'variabl',\n",
       " ',',\n",
       " 'interv',\n",
       " 'integr',\n",
       " 'replac',\n",
       " 'curv',\n",
       " 'connect',\n",
       " 'two',\n",
       " 'endpoint',\n",
       " 'interv',\n",
       " '.',\n",
       " 'surfac',\n",
       " 'integr',\n",
       " ',',\n",
       " 'curv',\n",
       " 'replac',\n",
       " 'piec',\n",
       " 'surfac',\n",
       " 'three-dimension',\n",
       " 'space',\n",
       " '.',\n",
       " 'first',\n",
       " 'document',\n",
       " 'systemat',\n",
       " 'techniqu',\n",
       " 'capabl',\n",
       " 'determin',\n",
       " 'integr',\n",
       " 'method',\n",
       " 'exhaust',\n",
       " 'ancient',\n",
       " 'greek',\n",
       " 'astronom',\n",
       " 'eudoxu',\n",
       " '(',\n",
       " 'ca',\n",
       " '.',\n",
       " '370',\n",
       " 'bc',\n",
       " ')',\n",
       " ',',\n",
       " 'sought',\n",
       " 'find',\n",
       " 'area',\n",
       " 'volum',\n",
       " 'break',\n",
       " 'infinit',\n",
       " 'number',\n",
       " 'divis',\n",
       " 'area',\n",
       " 'volum',\n",
       " 'known',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'method',\n",
       " 'develop',\n",
       " 'employ',\n",
       " 'archimed',\n",
       " '3rd',\n",
       " 'centuri',\n",
       " 'bc',\n",
       " 'use',\n",
       " 'calcul',\n",
       " 'area',\n",
       " 'circl',\n",
       " ',',\n",
       " 'surfac',\n",
       " 'area',\n",
       " 'volum',\n",
       " 'sphere',\n",
       " ',',\n",
       " 'area',\n",
       " 'ellips',\n",
       " ',',\n",
       " 'area',\n",
       " 'parabola',\n",
       " ',',\n",
       " 'volum',\n",
       " 'segment',\n",
       " 'paraboloid',\n",
       " 'revolut',\n",
       " ',',\n",
       " 'volum',\n",
       " 'segment',\n",
       " 'hyperboloid',\n",
       " 'revolut',\n",
       " ',',\n",
       " 'area',\n",
       " 'spiral',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'similar',\n",
       " 'method',\n",
       " 'independ',\n",
       " 'develop',\n",
       " 'china',\n",
       " 'around',\n",
       " '3rd',\n",
       " 'centuri',\n",
       " 'ad',\n",
       " 'liu',\n",
       " 'hui',\n",
       " ',',\n",
       " 'use',\n",
       " 'find',\n",
       " 'area',\n",
       " 'circl',\n",
       " '.',\n",
       " 'method',\n",
       " 'later',\n",
       " 'use',\n",
       " '5th',\n",
       " 'centuri',\n",
       " 'chines',\n",
       " 'father-and-son',\n",
       " 'mathematician',\n",
       " 'zu',\n",
       " 'chongzhi',\n",
       " 'zu',\n",
       " 'geng',\n",
       " 'find',\n",
       " 'volum',\n",
       " 'sphere',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'middl',\n",
       " 'east',\n",
       " ',',\n",
       " 'hasan',\n",
       " 'ibn',\n",
       " 'al-haytham',\n",
       " ',',\n",
       " 'latin',\n",
       " 'alhazen',\n",
       " '(',\n",
       " 'c.',\n",
       " '965',\n",
       " '–',\n",
       " 'c.',\n",
       " '1040',\n",
       " 'ad',\n",
       " ')',\n",
       " 'deriv',\n",
       " 'formula',\n",
       " 'sum',\n",
       " 'fourth',\n",
       " 'power',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'use',\n",
       " 'result',\n",
       " 'carri',\n",
       " 'would',\n",
       " 'call',\n",
       " 'integr',\n",
       " 'function',\n",
       " ',',\n",
       " 'formula',\n",
       " 'sum',\n",
       " 'integr',\n",
       " 'squar',\n",
       " 'fourth',\n",
       " 'power',\n",
       " 'allow',\n",
       " 'calcul',\n",
       " 'volum',\n",
       " 'paraboloid',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'next',\n",
       " 'signific',\n",
       " 'advanc',\n",
       " 'integr',\n",
       " 'calculu',\n",
       " 'begin',\n",
       " 'appear',\n",
       " '17th',\n",
       " 'centuri',\n",
       " '.',\n",
       " 'time',\n",
       " ',',\n",
       " 'work',\n",
       " 'cavalieri',\n",
       " 'method',\n",
       " 'indivis',\n",
       " ',',\n",
       " 'work',\n",
       " 'fermat',\n",
       " ',',\n",
       " 'began',\n",
       " 'lay',\n",
       " 'foundat',\n",
       " 'modern',\n",
       " 'calculu',\n",
       " ',',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'cavalieri',\n",
       " 'comput',\n",
       " 'integr',\n",
       " 'x',\n",
       " 'n',\n",
       " 'degre',\n",
       " 'n',\n",
       " '=',\n",
       " '9',\n",
       " 'cavalieri',\n",
       " \"'s\",\n",
       " 'quadratur',\n",
       " 'formula',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'step',\n",
       " 'made',\n",
       " 'earli',\n",
       " '17th',\n",
       " 'centuri',\n",
       " 'barrow',\n",
       " 'torricelli',\n",
       " ',',\n",
       " 'provid',\n",
       " 'first',\n",
       " 'hint',\n",
       " 'connect',\n",
       " 'integr',\n",
       " 'differenti',\n",
       " '.',\n",
       " 'barrow',\n",
       " 'provid',\n",
       " 'first',\n",
       " 'proof',\n",
       " 'fundament',\n",
       " 'theorem',\n",
       " 'calculu',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " 'walli',\n",
       " 'gener',\n",
       " 'cavalieri',\n",
       " \"'s\",\n",
       " 'method',\n",
       " ',',\n",
       " 'comput',\n",
       " 'integr',\n",
       " 'x',\n",
       " 'gener',\n",
       " 'power',\n",
       " ',',\n",
       " 'includ',\n",
       " 'neg',\n",
       " 'power',\n",
       " 'fraction',\n",
       " 'power',\n",
       " '.',\n",
       " '[',\n",
       " '9',\n",
       " ']',\n",
       " 'major',\n",
       " 'advanc',\n",
       " 'integr',\n",
       " 'came',\n",
       " '17th',\n",
       " 'centuri',\n",
       " 'independ',\n",
       " 'discoveri',\n",
       " 'fundament',\n",
       " 'theorem',\n",
       " 'calculu',\n",
       " 'leibniz',\n",
       " 'newton',\n",
       " '.',\n",
       " '[',\n",
       " '10',\n",
       " ']',\n",
       " 'theorem',\n",
       " 'demonstr',\n",
       " 'connect',\n",
       " 'integr',\n",
       " 'differenti',\n",
       " '.',\n",
       " 'connect',\n",
       " ',',\n",
       " 'combin',\n",
       " 'compar',\n",
       " 'eas',\n",
       " 'differenti',\n",
       " ',',\n",
       " 'exploit',\n",
       " 'calcul',\n",
       " 'integr',\n",
       " '.',\n",
       " 'particular',\n",
       " ',',\n",
       " 'fundament',\n",
       " 'theorem',\n",
       " 'calculu',\n",
       " 'allow',\n",
       " 'one',\n",
       " 'solv',\n",
       " 'much',\n",
       " 'broader',\n",
       " 'class',\n",
       " 'problem',\n",
       " '.',\n",
       " 'equal',\n",
       " 'import',\n",
       " 'comprehens',\n",
       " 'mathemat',\n",
       " 'framework',\n",
       " 'leibniz',\n",
       " 'newton',\n",
       " 'develop',\n",
       " '.',\n",
       " 'given',\n",
       " 'name',\n",
       " 'infinitesim',\n",
       " 'calculu',\n",
       " ',',\n",
       " 'allow',\n",
       " 'precis',\n",
       " 'analysi',\n",
       " 'function',\n",
       " 'within',\n",
       " 'continu',\n",
       " 'domain',\n",
       " '.',\n",
       " 'framework',\n",
       " 'eventu',\n",
       " 'becam',\n",
       " 'modern',\n",
       " 'calculu',\n",
       " ',',\n",
       " 'whose',\n",
       " 'notat',\n",
       " 'integr',\n",
       " 'drawn',\n",
       " 'directli',\n",
       " 'work',\n",
       " 'leibniz',\n",
       " '.',\n",
       " 'newton',\n",
       " 'leibniz',\n",
       " 'provid',\n",
       " 'systemat',\n",
       " 'approach',\n",
       " 'integr',\n",
       " ',',\n",
       " 'work',\n",
       " 'lack',\n",
       " 'degre',\n",
       " 'rigour',\n",
       " '.',\n",
       " 'bishop',\n",
       " 'berkeley',\n",
       " 'memor',\n",
       " 'attack',\n",
       " 'vanish',\n",
       " 'increment',\n",
       " 'use',\n",
       " 'newton',\n",
       " ',',\n",
       " 'call',\n",
       " '``',\n",
       " 'ghost',\n",
       " 'depart',\n",
       " 'quantiti',\n",
       " '``',\n",
       " '.',\n",
       " '[',\n",
       " '11',\n",
       " ']',\n",
       " 'calculu',\n",
       " 'acquir',\n",
       " 'firmer',\n",
       " 'foot',\n",
       " 'develop',\n",
       " 'limit',\n",
       " '.',\n",
       " 'integr',\n",
       " 'first',\n",
       " 'rigor',\n",
       " 'formal',\n",
       " ',',\n",
       " 'use',\n",
       " 'limit',\n",
       " ',',\n",
       " 'riemann',\n",
       " '.',\n",
       " '[',\n",
       " '12',\n",
       " ']',\n",
       " 'although',\n",
       " 'bound',\n",
       " 'piecewis',\n",
       " 'continu',\n",
       " 'function',\n",
       " 'riemann-integr',\n",
       " 'bound',\n",
       " 'interv',\n",
       " ',',\n",
       " 'subsequ',\n",
       " 'gener',\n",
       " 'function',\n",
       " 'considered—particularli',\n",
       " 'context',\n",
       " 'fourier',\n",
       " 'analysi',\n",
       " '—to',\n",
       " 'riemann',\n",
       " \"'s\",\n",
       " 'definit',\n",
       " 'appli',\n",
       " ',',\n",
       " 'lebesgu',\n",
       " 'formul',\n",
       " 'differ',\n",
       " 'definit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'found',\n",
       " 'measur',\n",
       " 'theori',\n",
       " '(',\n",
       " 'subfield',\n",
       " 'real',\n",
       " 'analysi',\n",
       " ')',\n",
       " '.',\n",
       " 'definit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'extend',\n",
       " 'riemann',\n",
       " \"'s\",\n",
       " 'lebesgu',\n",
       " \"'s\",\n",
       " 'approach',\n",
       " ',',\n",
       " 'propos',\n",
       " '.',\n",
       " 'approach',\n",
       " 'base',\n",
       " 'real',\n",
       " 'number',\n",
       " 'system',\n",
       " 'one',\n",
       " 'common',\n",
       " 'today',\n",
       " ',',\n",
       " 'altern',\n",
       " 'approach',\n",
       " 'exist',\n",
       " ',',\n",
       " 'definit',\n",
       " 'integr',\n",
       " 'standard',\n",
       " 'part',\n",
       " 'infinit',\n",
       " 'riemann',\n",
       " 'sum',\n",
       " ',',\n",
       " 'base',\n",
       " 'hyperr',\n",
       " 'number',\n",
       " 'system',\n",
       " '.',\n",
       " 'notat',\n",
       " 'indefinit',\n",
       " 'integr',\n",
       " 'introduc',\n",
       " 'gottfri',\n",
       " 'wilhelm',\n",
       " 'leibniz',\n",
       " '1675',\n",
       " '.',\n",
       " '[',\n",
       " '13',\n",
       " ']',\n",
       " 'adapt',\n",
       " 'integr',\n",
       " 'symbol',\n",
       " ',',\n",
       " '∫',\n",
       " ',',\n",
       " 'letter',\n",
       " 'ſ',\n",
       " '(',\n",
       " 'long',\n",
       " ')',\n",
       " ',',\n",
       " 'stand',\n",
       " 'summa',\n",
       " '(',\n",
       " 'written',\n",
       " 'ſumma',\n",
       " ';',\n",
       " 'latin',\n",
       " '``',\n",
       " 'sum',\n",
       " \"''\",\n",
       " '``',\n",
       " 'total',\n",
       " \"''\",\n",
       " ')',\n",
       " '.',\n",
       " 'modern',\n",
       " 'notat',\n",
       " 'definit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'limit',\n",
       " 'integr',\n",
       " 'sign',\n",
       " ',',\n",
       " 'first',\n",
       " 'use',\n",
       " 'joseph',\n",
       " 'fourier',\n",
       " 'mémoir',\n",
       " 'french',\n",
       " 'academi',\n",
       " 'around',\n",
       " '1819–20',\n",
       " ',',\n",
       " 'reprint',\n",
       " 'book',\n",
       " '1822',\n",
       " '.',\n",
       " '[',\n",
       " '14',\n",
       " ']',\n",
       " 'isaac',\n",
       " 'newton',\n",
       " 'use',\n",
       " 'small',\n",
       " 'vertic',\n",
       " 'bar',\n",
       " 'variabl',\n",
       " 'indic',\n",
       " 'integr',\n",
       " ',',\n",
       " 'place',\n",
       " 'variabl',\n",
       " 'insid',\n",
       " 'box',\n",
       " '.',\n",
       " 'vertic',\n",
       " 'bar',\n",
       " 'easili',\n",
       " 'confus',\n",
       " '.',\n",
       " 'x',\n",
       " 'x',\n",
       " '′',\n",
       " ',',\n",
       " 'use',\n",
       " 'indic',\n",
       " 'differenti',\n",
       " ',',\n",
       " 'box',\n",
       " 'notat',\n",
       " 'difficult',\n",
       " 'printer',\n",
       " 'reproduc',\n",
       " ',',\n",
       " 'notat',\n",
       " 'wide',\n",
       " 'adopt',\n",
       " '.',\n",
       " '[',\n",
       " '15',\n",
       " ']',\n",
       " 'term',\n",
       " 'first',\n",
       " 'print',\n",
       " 'latin',\n",
       " 'jacob',\n",
       " 'bernoulli',\n",
       " '1690',\n",
       " ':',\n",
       " '``',\n",
       " 'ergo',\n",
       " 'et',\n",
       " 'horum',\n",
       " 'integralia',\n",
       " 'aequantur',\n",
       " \"''\",\n",
       " '.',\n",
       " '[',\n",
       " '16',\n",
       " ']',\n",
       " 'gener',\n",
       " ',',\n",
       " 'integr',\n",
       " 'real-valu',\n",
       " 'function',\n",
       " 'f',\n",
       " '(',\n",
       " 'x',\n",
       " ')',\n",
       " 'respect',\n",
       " 'real',\n",
       " 'variabl',\n",
       " 'x',\n",
       " 'interv',\n",
       " '[',\n",
       " ',',\n",
       " 'b',\n",
       " ']',\n",
       " 'written',\n",
       " 'integr',\n",
       " 'sign',\n",
       " '∫',\n",
       " 'repres',\n",
       " 'integr',\n",
       " '.',\n",
       " 'symbol',\n",
       " 'dx',\n",
       " ',',\n",
       " 'call',\n",
       " 'differenti',\n",
       " 'variabl',\n",
       " 'x',\n",
       " ',',\n",
       " 'indic',\n",
       " 'variabl',\n",
       " 'integr',\n",
       " 'x',\n",
       " '.',\n",
       " 'function',\n",
       " 'f',\n",
       " '(',\n",
       " 'x',\n",
       " ')',\n",
       " 'call',\n",
       " 'integrand',\n",
       " ',',\n",
       " 'point',\n",
       " 'b',\n",
       " 'call',\n",
       " 'limit',\n",
       " '(',\n",
       " 'bound',\n",
       " ')',\n",
       " 'integr',\n",
       " ',',\n",
       " 'integr',\n",
       " 'said',\n",
       " 'interv',\n",
       " '[',\n",
       " ',',\n",
       " 'b',\n",
       " ']',\n",
       " ',',\n",
       " 'call',\n",
       " 'interv',\n",
       " 'integr',\n",
       " '.',\n",
       " '[',\n",
       " '17',\n",
       " ']',\n",
       " 'function',\n",
       " 'said',\n",
       " 'integr',\n",
       " 'integr',\n",
       " 'domain',\n",
       " 'finit',\n",
       " '.',\n",
       " 'limit',\n",
       " 'specifi',\n",
       " ',',\n",
       " 'integr',\n",
       " 'call',\n",
       " 'definit',\n",
       " 'integr',\n",
       " '.',\n",
       " 'limit',\n",
       " 'omit',\n",
       " ',',\n",
       " 'integr',\n",
       " 'call',\n",
       " 'indefinit',\n",
       " 'integr',\n",
       " ',',\n",
       " 'repres',\n",
       " 'class',\n",
       " 'function',\n",
       " '(',\n",
       " 'antideriv',\n",
       " ')',\n",
       " 'whose',\n",
       " 'deriv',\n",
       " 'integrand',\n",
       " '.',\n",
       " '[',\n",
       " '18',\n",
       " ']',\n",
       " 'fundament',\n",
       " 'theorem',\n",
       " 'calculu',\n",
       " 'relat',\n",
       " 'evalu',\n",
       " 'definit',\n",
       " 'integr',\n",
       " 'indefinit',\n",
       " 'integr',\n",
       " '.',\n",
       " 'sever',\n",
       " 'extens',\n",
       " 'notat',\n",
       " 'integr',\n",
       " 'encompass',\n",
       " 'integr',\n",
       " 'unbound',\n",
       " 'domain',\n",
       " 'and/or',\n",
       " 'multipl',\n",
       " 'dimens',\n",
       " '(',\n",
       " 'see',\n",
       " 'later',\n",
       " 'section',\n",
       " 'articl',\n",
       " ')',\n",
       " '.',\n",
       " 'advanc',\n",
       " 'set',\n",
       " ',',\n",
       " 'uncommon',\n",
       " 'leav',\n",
       " 'dx',\n",
       " 'simpl',\n",
       " 'riemann',\n",
       " 'integr',\n",
       " 'use',\n",
       " ',',\n",
       " 'exact',\n",
       " 'type',\n",
       " 'integr',\n",
       " 'immateri',\n",
       " '.',\n",
       " 'instanc',\n",
       " ',',\n",
       " 'one',\n",
       " 'might',\n",
       " 'write',\n",
       " '∫',\n",
       " 'b',\n",
       " '(',\n",
       " 'c',\n",
       " '1',\n",
       " 'f',\n",
       " '+',\n",
       " 'c',\n",
       " '2',\n",
       " 'g',\n",
       " ')',\n",
       " '=',\n",
       " 'c',\n",
       " '1',\n",
       " '∫',\n",
       " 'b',\n",
       " 'f',\n",
       " '+',\n",
       " 'c',\n",
       " '2',\n",
       " '∫',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e235fc2-bde7-44a0-b39d-52d2cc0cb5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# usuwanie interpunkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b38f165f-f13f-4ba9-9d4c-23f3bd5cf696",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\" \".join(art) for art in articles]\n",
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "099a1a45-b2bc-4a41-af32-1000950c17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "articles = [a.translate(table) for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54b8976a-e2db-4617-ba88-26e1d39f0069",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mathemat  integr assign number function way describ displac  area  volum  concept aris combin infinitesim data  process find integr call integr  along differenti  integr fundament  essenti oper calculu    serv tool solv problem mathemat physic involv area arbitrari shape  length curv  volum solid  among other  integr enumer term definit integr  interpret sign area region plane bound graph given function two point real line  convent  area horizont axi plane posit area neg  integr also refer concept antideriv  function whose deriv given function  case  call indefinit integr  fundament theorem calculu relat definit integr differenti provid method comput definit integr function antideriv known  although method calcul area volum date ancient greek mathemat  principl integr formul independ isaac newton gottfri wilhelm leibniz late 17th centuri  thought area curv infinit sum rectangl infinitesim width  bernhard riemann later gave rigor definit integr  base limit procedur approxim area curvilinear region break region infinitesim thin vertic slab  earli 20th centuri  henri lebesgu gener riemann s formul introduc refer lebesgu integr  robust riemann s sens wider class function lebesgueintegr  integr may gener depend type function well domain integr perform  exampl  line integr defin function two variabl  interv integr replac curv connect two endpoint interv  surfac integr  curv replac piec surfac threedimension space  first document systemat techniqu capabl determin integr method exhaust ancient greek astronom eudoxu  ca  370 bc   sought find area volum break infinit number divis area volum known   1  method develop employ archimed 3rd centuri bc use calcul area circl  surfac area volum sphere  area ellips  area parabola  volum segment paraboloid revolut  volum segment hyperboloid revolut  area spiral   2  similar method independ develop china around 3rd centuri ad liu hui  use find area circl  method later use 5th centuri chines fatherandson mathematician zu chongzhi zu geng find volum sphere   3  middl east  hasan ibn alhaytham  latin alhazen  c 965 – c 1040 ad  deriv formula sum fourth power   4  use result carri would call integr function  formula sum integr squar fourth power allow calcul volum paraboloid   5  next signific advanc integr calculu begin appear 17th centuri  time  work cavalieri method indivis  work fermat  began lay foundat modern calculu   6  cavalieri comput integr x n degre n  9 cavalieri s quadratur formula   7  step made earli 17th centuri barrow torricelli  provid first hint connect integr differenti  barrow provid first proof fundament theorem calculu   8  walli gener cavalieri s method  comput integr x gener power  includ neg power fraction power   9  major advanc integr came 17th centuri independ discoveri fundament theorem calculu leibniz newton   10  theorem demonstr connect integr differenti  connect  combin compar eas differenti  exploit calcul integr  particular  fundament theorem calculu allow one solv much broader class problem  equal import comprehens mathemat framework leibniz newton develop  given name infinitesim calculu  allow precis analysi function within continu domain  framework eventu becam modern calculu  whose notat integr drawn directli work leibniz  newton leibniz provid systemat approach integr  work lack degre rigour  bishop berkeley memor attack vanish increment use newton  call  ghost depart quantiti    11  calculu acquir firmer foot develop limit  integr first rigor formal  use limit  riemann   12  although bound piecewis continu function riemannintegr bound interv  subsequ gener function considered—particularli context fourier analysi —to riemann s definit appli  lebesgu formul differ definit integr  found measur theori  subfield real analysi   definit integr  extend riemann s lebesgu s approach  propos  approach base real number system one common today  altern approach exist  definit integr standard part infinit riemann sum  base hyperr number system  notat indefinit integr introduc gottfri wilhelm leibniz 1675   13  adapt integr symbol  ∫  letter ſ  long   stand summa  written ſumma  latin  sum   total    modern notat definit integr  limit integr sign  first use joseph fourier mémoir french academi around 1819–20  reprint book 1822   14  isaac newton use small vertic bar variabl indic integr  place variabl insid box  vertic bar easili confus  x x ′  use indic differenti  box notat difficult printer reproduc  notat wide adopt   15  term first print latin jacob bernoulli 1690   ergo et horum integralia aequantur    16  gener  integr realvalu function f  x  respect real variabl x interv   b  written integr sign ∫ repres integr  symbol dx  call differenti variabl x  indic variabl integr x  function f  x  call integrand  point b call limit  bound  integr  integr said interv   b   call interv integr   17  function said integr integr domain finit  limit specifi  integr call definit integr  limit omit  integr call indefinit integr  repres class function  antideriv  whose deriv integrand   18  fundament theorem calculu relat evalu definit integr indefinit integr  sever extens notat integr encompass integr unbound domain andor multipl dimens  see later section articl   advanc set  uncommon leav dx simpl riemann integr use  exact type integr immateri  instanc  one might write ∫ b  c 1 f  c 2 g   c 1 ∫ b f  c 2 ∫ b g  textstyl int      b   c  1  fc  2  g  c  1  int      b  fc  2  int      b  g  express linear integr  properti share riemann integr gener thereof   19  integr appear mani practic situat  instanc  length  width depth swim pool rectangular flat bottom  one determin volum water contain  area surfac  length edg  oval round bottom  integr requir find exact rigor valu quantiti  case  one may divid sought quantiti infinit mani infinitesim piec  sum piec achiev accur approxim  exampl  find area region bound graph function f  x   √ x x  0 x  1  one cross interv five step  0  15  25    1   fill rectangl use right end height piec  thu √ 0  √ 15  √ 25    √ 1  sum area get approxim larger exact valu  altern  replac subinterv one left end height piec  approxim one get low  twelv subinterv approxim area 06203 howev  number piec increas infin  reach limit exact valu area sought  case  23   one write mean 23 result weight sum function valu  √ x  multipli infinitesim step width  denot dx  interv  0  1   mani way formal defin integr  equival  differ exist mostli deal differ special case may integr definit  also occasion pedagog reason  commonli use definit riemann integr lebesgu integr  riemann integr defin term riemann sum function respect tag partit interv   20  tag partit close interv   b  real line finit sequenc partit interv   b  n subinterv  x −1  x  index   tag  distinguish point ∈  x −1  x   riemann sum function f respect tag partit defin thu term sum area rectangl height equal function valu distinguish point given subinterv  width width subinterv  δ  x − x −1  mesh tag partit width largest subinterv form partit  max 1  n δ  riemann integr function f interv   b  equal   21  chosen tag give maximum  respect  minimum  valu interv  riemann sum becom upper  respect  lower  darboux sum  suggest close connect riemann integr darboux integr  often interest  theori applic  abl pass limit integr  instanc  sequenc function frequent construct approxim  suitabl sens  solut problem  integr solut function limit integr approxim  howev  mani function obtain limit riemannintegr  limit theorem hold riemann integr  therefor  great import definit integr allow wider class function integr   22  integr lebesgu integr  exploit follow fact enlarg class integr function  valu function rearrang domain  integr function remain  thu henri lebesgu introduc integr bear name  explain integr thu letter paul montel   23  pay certain sum  collect pocket  take bill coin pocket give creditor order find reach total sum  riemann integr  proceed differ  taken money pocket order bill coin accord ident valu pay sever heap one creditor  integr  folland put   comput riemann integr f  one partit domain   b  subinterv   lebesgu integr   one effect partit rang f    24  definit lebesgu integr thu begin measur  μ simplest case  lebesgu measur μ   interv    b  width  b −  lebesgu integr agre  proper  riemann integr exist   25  complic case  set measur highli fragment  continu resembl interv  use  partit rang f  philosophi  integr nonneg function f  r → r sum area thin horizont strip    dt  area μ  x  f  x   gt   dt  let f ∗    μ  x  f  x   gt    lebesgu integr f defin integr right ordinari improp riemann integr  f ∗ strictli decreas posit function  therefor welldefin improp riemann integr    26  suitabl class function  measur function  defin lebesgu integr  gener measur function f lebesgueintegr sum absolut valu area region graph f x axi finit   27  case  integr  riemannian case  differ area x axi area x axi   28  although riemann lebesgu integr wide use definit integr  number other exist  includ  collect riemannintegr function close interv   b  form vector space oper pointwis addit multipl scalar  oper integr linear function vector space  thu  collect integr function close take linear combin  integr linear combin linear combin integr   29  similarli  set real valu lebesgueintegr function given measur space e measur μ close take linear combin henc form vector space  lebesgu integr linear function vector space    28  gener  consid vector space measur function measur space  e  μ   take valu local compact complet topolog vector space v local compact topolog field k  f  e → v  one may defin abstract integr map assign function f element v symbol ∞  compat linear combin   30  situat  linear hold subspac function whose integr element v  ie   finit    import special case aris k r  c  finit extens field q p padic number  v finitedimension vector space k  k  c v complex hilbert space  linear  togeth natur continu properti normal certain class  simpl  function  may use give altern definit integr  approach daniel case realvalu function set x  gener nicola bourbaki function valu local compact topolog vector space  see hildebrandt 1953 axiomat character integr  number gener inequ hold riemannintegr function defin close bound interv   b  gener notion integr  lebesgu daniel   section  f realvalu riemannintegr function  integr interv   b  defin  lt  b  mean upper lower sum function f evalu partit  x 0 ≤ x 1 ≤    ≤ x n  b whose valu x increas  geometr  signifi integr take place  left right   evalu f within interv  x  x 1  interv higher index lie right one lower index  valu b  endpoint interv  call limit integr f  integr also defin  gt  b   17   b  impli  first convent necessari consider take integr subinterv   b   second say integr taken degener interv  point  zero  one reason first convent integr f interv   b  impli f integr subinterv  c    particular integr properti c element   b     29  first convent  result relat welldefin cyclic permut  b  c  fundament theorem calculu statement differenti integr invers oper  continu function first integr differenti  origin function retriev   33  import consequ  sometim call second fundament theorem calculu  allow one comput integr use antideriv function integr   34  let f continu realvalu function defin close interv   b   let f function defin  x   b    f continu   b   differenti open interv   b   x   b   let f realvalu function defin close interv   b  admit antideriv f   b    f f function x   b   f integr   b   proper  riemann integr assum integrand defin finit close bound interv  bracket limit integr  improp integr occur one condit satisfi  case integr may defin consid limit sequenc proper riemann integr progress larger interv  interv unbound  instanc upper end  improp integr limit endpoint goe infin   35  integrand defin finit halfopen interv  instanc   b   limit may provid finit result   36   improp integr limit proper integr one endpoint interv integr approach either specifi real number  ∞  −∞  complic case  limit requir endpoint  interior point  definit integr posit function one variabl repres area region graph function x axi  doubl integr posit function two variabl repres volum region surfac defin function plane contain domain   37  exampl  function two dimens depend two real variabl  x  integr function f rectangl r given cartesian product two interv r    b  ×  c    displaystyl r   b  time  c    written differenti da indic integr taken respect area  doubl integr defin use riemann sum  repres  sign  volum graph z  f  x   domain r   38  suitabl condit  eg  f continu   fubini s theorem state integr express equival iter integr  39  reduc problem comput doubl integr comput onedimension integr   anoth notat integr r use doubl integr sign   38  integr gener domain possibl  integr function f  respect volum  n dimension region r n  displaystyl mathbb  r    n   denot symbol  concept integr extend gener domain integr  curv line surfac insid higherdimension space  integr known line integr surfac integr respect  import applic physic  deal vector field  line integr  sometim call path integr  integr function integr evalu along curv   40  variou differ line integr use  case close curv also call contour integr  function integr may scalar field vector field  valu line integr sum valu field point curv  weight scalar function curv  commonli arc length  vector field  scalar product vector field differenti vector curv    41  weight distinguish line integr simpler integr defin interv  mani simpl formula physic natur continu analog term line integr  exampl  fact work equal forc  f  multipli displac   may express  term vector quantiti    42  object move along path c vector field f electr field gravit field  total work done field object obtain sum differenti work done move   give line integr  43  surfac integr gener doubl integr integr surfac  may curv set space   thought doubl integr analog line integr  function integr may scalar field vector field  valu surfac integr sum field point surfac  achiev split surfac surfac element  provid partit riemann sum   44  exampl applic surfac integr  consid vector field v surfac   point x  v  x  vector  imagin fluid flow  v  x  determin veloc fluid x  flux defin quantiti fluid flow unit amount time  find flux  one need take dot product v unit surfac normal point  give scalar field  integr surfac   45  fluid flux exampl may physic fluid water air  electr magnet flux  thu surfac integr applic physic  particularli classic theori electromagnet  complex analysi  integrand complexvalu function complex variabl z instead real function real variabl x  complex function integr along curv γ  displaystyl gamma  complex plane  integr denot follow known contour integr  differenti form mathemat concept field multivari calculu  differenti topolog  tensor  differenti form organ degre  exampl  oneform weight sum differenti coordin   e  f  g function three dimens  differenti oneform integr orient path  result integr anoth way write line integr  basic differenti dx  dy  dz measur infinitesim orient length parallel three coordin axe  differenti twoform sum form basic twoform x ∧  z ∧ x  ∧ z  displaystyl dxwedg dy  dzwedg dx  dywedg dz  measur orient area parallel coordin twoplan  symbol ∧  displaystyl wedg  denot wedg product  similar cross product sens wedg product two form repres orient length repres orient area  twoform integr orient surfac  result integr equival surfac integr give flux e  f j  g k  displaystyl emathbf   fmathbf  j  gmathbf  k    unlik cross product  threedimension vector calculu  wedg product calculu differenti form make sens arbitrari dimens gener manifold  curv  surfac  higherdimension analog   exterior deriv play role gradient curl vector calculu  stoke  theorem simultan gener three theorem vector calculu  diverg theorem  green s theorem  kelvinstok theorem  discret equival integr summat  summat integr put foundat use theori lebesgu integr timescal calculu  integr perform variabl   physic  space time dimens   space function  refer function integr  integr use extens mani area  exampl  probabl theori  integr use determin probabl random variabl fall within certain rang   46  moreov  integr entir probabl densiti function must equal 1  provid test whether function neg valu could densiti function   47  integr use comput area twodimension region curv boundari  well comput volum threedimension object curv boundari  area twodimension region calcul use aforement definit integr   48  volum threedimension object disc washer comput disc integr use equat volum cylind  π r 2 h  displaystyl pi r  2  h   r  displaystyl r  radiu  case simpl disc creat rotat curv x axi  radiu given f  x   height differenti dx  use integr bound b  volum disc equal   49  π ∫ b f 2  x  x   displaystyl pi int      b  f  2   x    dx   integr also use physic  area like kinemat find quantiti like displac  time  veloc  exampl  rectilinear motion  displac object time interv   b   displaystyl   b   given  v    displaystyl v    veloc express function time   50  work done forc f  x   displaystyl f  x    given function posit  initi posit  displaystyl  final posit b  displaystyl b    51  integr also use thermodynam  thermodynam integr use calcul differ free energi two given state  basic techniqu comput definit integr one real variabl base fundament theorem calculu  let f  x  function x integr given interv   b    find antideriv f   function f f ′  f interv  provid integrand integr singular path integr  fundament theorem calculu  sometim necessari use one mani techniqu develop evalu integr  techniqu rewrit one integr differ one hope tractabl  techniqu includ integr substitut  integr part  integr trigonometr substitut  integr partial fraction  altern method exist comput complex integr  mani nonelementari integr expand taylor seri integr term term  occasion  result infinit seri sum analyt  method convolut use meijer gfunction also use  assum integrand written product meijer gfunction  also mani less common way calcul definit integr  instanc  parsev s ident use transform integr rectangular region infinit sum  occasion  integr evalu trick  exampl  see gaussian integr  comput volum solid revolut usual done disk integr shell integr  specif result work variou techniqu collect list integr  mani problem mathemat  physic  engin involv integr explicit formula integr desir  extens tabl integr compil publish year purpos  spread comput  mani profession  educ  student turn comput algebra system specif design perform difficult tediou task  includ integr  symbol integr one motiv develop first system  like macsyma mapl  major mathemat difficulti symbol integr mani case  rel simpl function integr express close form involv elementari function  includ ration exponenti function  logarithm  trigonometr function invers trigonometr function  oper multipl composit  risch algorithm provid gener criterion determin whether antideriv elementari function elementari  comput  howev  function close express antideriv except  consequ  computer algebra system hope abl find antideriv randomli construct elementari function  posit side  build block  antideriv fix advanc  may still possibl decid whether antideriv given function express use block oper multipl composit  find symbol answer whenev exist  risch algorithm  implement mathematica  mapl comput algebra system  function antideriv built ration function  radic  logarithm  exponenti function  special integrand occur often enough warrant special studi  particular  may use  set antideriv  special function  like legendr function  hypergeometr function  gamma function  incomplet gamma function   extend risch s algorithm includ function possibl challeng activ research subject  recent new approach emerg  use finit function  solut linear differenti equat polynomi coeffici  elementari special function finit  integr finit function also finit function  provid algorithm express antideriv finit function solut differenti equat  theori also allow one comput definit integr function sum seri given first coeffici  provid algorithm comput coeffici  definit integr may approxim use sever method numer integr  rectangl method reli divid region function seri rectangl correspond function valu multipli step width find sum  better approach  trapezoid rule  replac rectangl use riemann sum trapezoid  trapezoid rule weight first last valu one half  multipli step width obtain better approxim   52  idea behind trapezoid rule  accur approxim function yield better approxim integr  carri  simpson s rule approxim integrand piecewis quadrat function   53  riemann sum  trapezoid rule  simpson s rule exampl famili quadratur rule call newton–cot formula  degre n newton–cot quadratur rule approxim polynomi subinterv degre n polynomi  polynomi chosen interpol valu function interv   54  higher degre newton–cot approxim accur  requir function evalu  suffer numer inaccuraci due rung s phenomenon  one solut problem clenshaw–curti quadratur  integrand approxim expand term chebyshev polynomi  romberg s method halv step width increment  give trapezoid approxim denot  h 0    h 1    h k 1 half h k  new step size  half new function valu need comput  other carri previou size  interpol polynomi approxim  extrapol  0   gaussian quadratur evalu function root set orthogon polynomi   55  n point gaussian method exact polynomi degre 2 n − 1  comput higherdimension integr  exampl  volum calcul  make import use altern mont carlo integr   56  area arbitrari twodimension shape determin use measur instrument call planimet  volum irregular object measur precis fluid displac object submerg  area sometim found via geometr compassandstraightedg construct equival squar  kempf  jackson moral demonstr mathemat relat allow integr calcul mean differenti  calculu involv dirac delta function partial deriv oper ∂ x  displaystyl partial   x    also appli function integr  allow comput function differenti   57  fundament theorem calculu allow straightforward calcul basic function  ∫ 0 π sin \\u2061  x  x  − co \\u2061  x  ∣ x  0 x  π  − co \\u2061  π  −  − co \\u2061  0    2  displaystyl int   0    pi  sin  x  dxco  x  mid   x0    xpi  co  pi    co  0   2 '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71875beb-e3b3-45fb-8f51-f06a7b5eb7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4645ee08-855d-43f5-a3ef-6431ee0e32db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(?u)\\\\b\\\\w\\\\w+\\\\b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.int64'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Convert a collection of text documents to a matrix of token counts.\n",
       "\n",
       "This implementation produces a sparse representation of the counts using\n",
       "scipy.sparse.csr_matrix.\n",
       "\n",
       "If you do not provide an a-priori dictionary and you do not use an analyzer\n",
       "that does some kind of feature selection then the number of features will\n",
       "be equal to the vocabulary size found by analyzing the data.\n",
       "\n",
       "Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "input : {'filename', 'file', 'content'}, default='content'\n",
       "    - If `'filename'`, the sequence passed as an argument to fit is\n",
       "      expected to be a list of filenames that need reading to fetch\n",
       "      the raw content to analyze.\n",
       "\n",
       "    - If `'file'`, the sequence items must have a 'read' method (file-like\n",
       "      object) that is called to fetch the bytes in memory.\n",
       "\n",
       "    - If `'content'`, the input is expected to be a sequence of items that\n",
       "      can be of type string or byte.\n",
       "\n",
       "encoding : str, default='utf-8'\n",
       "    If bytes or files are given to analyze, this encoding is used to\n",
       "    decode.\n",
       "\n",
       "decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
       "    Instruction on what to do if a byte sequence is given to analyze that\n",
       "    contains characters not of the given `encoding`. By default, it is\n",
       "    'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
       "    values are 'ignore' and 'replace'.\n",
       "\n",
       "strip_accents : {'ascii', 'unicode'}, default=None\n",
       "    Remove accents and perform other character normalization\n",
       "    during the preprocessing step.\n",
       "    'ascii' is a fast method that only works on characters that have\n",
       "    an direct ASCII mapping.\n",
       "    'unicode' is a slightly slower method that works on any characters.\n",
       "    None (default) does nothing.\n",
       "\n",
       "    Both 'ascii' and 'unicode' use NFKD normalization from\n",
       "    :func:`unicodedata.normalize`.\n",
       "\n",
       "lowercase : bool, default=True\n",
       "    Convert all characters to lowercase before tokenizing.\n",
       "\n",
       "preprocessor : callable, default=None\n",
       "    Override the preprocessing (strip_accents and lowercase) stage while\n",
       "    preserving the tokenizing and n-grams generation steps.\n",
       "    Only applies if ``analyzer`` is not callable.\n",
       "\n",
       "tokenizer : callable, default=None\n",
       "    Override the string tokenization step while preserving the\n",
       "    preprocessing and n-grams generation steps.\n",
       "    Only applies if ``analyzer == 'word'``.\n",
       "\n",
       "stop_words : {'english'}, list, default=None\n",
       "    If 'english', a built-in stop word list for English is used.\n",
       "    There are several known issues with 'english' and you should\n",
       "    consider an alternative (see :ref:`stop_words`).\n",
       "\n",
       "    If a list, that list is assumed to contain stop words, all of which\n",
       "    will be removed from the resulting tokens.\n",
       "    Only applies if ``analyzer == 'word'``.\n",
       "\n",
       "    If None, no stop words will be used. max_df can be set to a value\n",
       "    in the range [0.7, 1.0) to automatically detect and filter stop\n",
       "    words based on intra corpus document frequency of terms.\n",
       "\n",
       "token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
       "    Regular expression denoting what constitutes a \"token\", only used\n",
       "    if ``analyzer == 'word'``. The default regexp select tokens of 2\n",
       "    or more alphanumeric characters (punctuation is completely ignored\n",
       "    and always treated as a token separator).\n",
       "\n",
       "    If there is a capturing group in token_pattern then the\n",
       "    captured group content, not the entire match, becomes the token.\n",
       "    At most one capturing group is permitted.\n",
       "\n",
       "ngram_range : tuple (min_n, max_n), default=(1, 1)\n",
       "    The lower and upper boundary of the range of n-values for different\n",
       "    word n-grams or char n-grams to be extracted. All values of n such\n",
       "    such that min_n <= n <= max_n will be used. For example an\n",
       "    ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\n",
       "    unigrams and bigrams, and ``(2, 2)`` means only bigrams.\n",
       "    Only applies if ``analyzer`` is not callable.\n",
       "\n",
       "analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n",
       "    Whether the feature should be made of word n-gram or character\n",
       "    n-grams.\n",
       "    Option 'char_wb' creates character n-grams only from text inside\n",
       "    word boundaries; n-grams at the edges of words are padded with space.\n",
       "\n",
       "    If a callable is passed it is used to extract the sequence of features\n",
       "    out of the raw, unprocessed input.\n",
       "\n",
       "    .. versionchanged:: 0.21\n",
       "\n",
       "    Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n",
       "    first read from the file and then passed to the given callable\n",
       "    analyzer.\n",
       "\n",
       "max_df : float in range [0.0, 1.0] or int, default=1.0\n",
       "    When building the vocabulary ignore terms that have a document\n",
       "    frequency strictly higher than the given threshold (corpus-specific\n",
       "    stop words).\n",
       "    If float, the parameter represents a proportion of documents, integer\n",
       "    absolute counts.\n",
       "    This parameter is ignored if vocabulary is not None.\n",
       "\n",
       "min_df : float in range [0.0, 1.0] or int, default=1\n",
       "    When building the vocabulary ignore terms that have a document\n",
       "    frequency strictly lower than the given threshold. This value is also\n",
       "    called cut-off in the literature.\n",
       "    If float, the parameter represents a proportion of documents, integer\n",
       "    absolute counts.\n",
       "    This parameter is ignored if vocabulary is not None.\n",
       "\n",
       "max_features : int, default=None\n",
       "    If not None, build a vocabulary that only consider the top\n",
       "    max_features ordered by term frequency across the corpus.\n",
       "\n",
       "    This parameter is ignored if vocabulary is not None.\n",
       "\n",
       "vocabulary : Mapping or iterable, default=None\n",
       "    Either a Mapping (e.g., a dict) where keys are terms and values are\n",
       "    indices in the feature matrix, or an iterable over terms. If not\n",
       "    given, a vocabulary is determined from the input documents. Indices\n",
       "    in the mapping should not be repeated and should not have any gap\n",
       "    between 0 and the largest index.\n",
       "\n",
       "binary : bool, default=False\n",
       "    If True, all non zero counts are set to 1. This is useful for discrete\n",
       "    probabilistic models that model binary events rather than integer\n",
       "    counts.\n",
       "\n",
       "dtype : type, default=np.int64\n",
       "    Type of the matrix returned by fit_transform() or transform().\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "vocabulary_ : dict\n",
       "    A mapping of terms to feature indices.\n",
       "\n",
       "fixed_vocabulary_ : bool\n",
       "    True if a fixed vocabulary of term to indices mapping\n",
       "    is provided by the user.\n",
       "\n",
       "stop_words_ : set\n",
       "    Terms that were ignored because they either:\n",
       "\n",
       "      - occurred in too many documents (`max_df`)\n",
       "      - occurred in too few documents (`min_df`)\n",
       "      - were cut off by feature selection (`max_features`).\n",
       "\n",
       "    This is only available if no vocabulary was given.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "HashingVectorizer : Convert a collection of text documents to a\n",
       "    matrix of token counts.\n",
       "\n",
       "TfidfVectorizer : Convert a collection of raw documents to a matrix\n",
       "    of TF-IDF features.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The ``stop_words_`` attribute can get large and increase the model size\n",
       "when pickling. This attribute is provided only for introspection and can\n",
       "be safely removed using delattr or set to None before pickling.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
       ">>> corpus = [\n",
       "...     'This is the first document.',\n",
       "...     'This document is the second document.',\n",
       "...     'And this is the third one.',\n",
       "...     'Is this the first document?',\n",
       "... ]\n",
       ">>> vectorizer = CountVectorizer()\n",
       ">>> X = vectorizer.fit_transform(corpus)\n",
       ">>> vectorizer.get_feature_names_out()\n",
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], ...)\n",
       ">>> print(X.toarray())\n",
       "[[0 1 1 1 0 0 1 0 1]\n",
       " [0 2 0 1 0 1 1 0 1]\n",
       " [1 0 0 1 1 0 1 1 1]\n",
       " [0 1 1 1 0 0 1 0 1]]\n",
       ">>> vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
       ">>> X2 = vectorizer2.fit_transform(corpus)\n",
       ">>> vectorizer2.get_feature_names_out()\n",
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third', 'third one',\n",
       "       'this document', 'this is', 'this the'], ...)\n",
       " >>> print(X2.toarray())\n",
       " [[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
       " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
       " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
       " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n",
       "\u001b[0;31mFile:\u001b[0m           /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     TfidfVectorizer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27f10d38-e824-4196-8ecb-82777d65806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x1558 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7206 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', min_df=3)\n",
    "vectorizer.fit(articles)\n",
    "X = vectorizer.transform(articles)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05c9e615-f319-43d4-bb61-3e7485236cf8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '136',\n",
       " '14',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '155',\n",
       " '156',\n",
       " '157',\n",
       " '158',\n",
       " '159',\n",
       " '16',\n",
       " '160',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '164',\n",
       " '165',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '169',\n",
       " '17',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '173',\n",
       " '174',\n",
       " '175',\n",
       " '176',\n",
       " '177',\n",
       " '178',\n",
       " '179',\n",
       " '18',\n",
       " '180',\n",
       " '181',\n",
       " '1819',\n",
       " '182',\n",
       " '183',\n",
       " '184',\n",
       " '185',\n",
       " '1851',\n",
       " '1854',\n",
       " '1857',\n",
       " '186',\n",
       " '1860',\n",
       " '1861',\n",
       " '1862',\n",
       " '1863',\n",
       " '1864',\n",
       " '1868',\n",
       " '1869',\n",
       " '187',\n",
       " '1870',\n",
       " '1872',\n",
       " '1874',\n",
       " '1877',\n",
       " '1878',\n",
       " '1879',\n",
       " '188',\n",
       " '1882',\n",
       " '1883',\n",
       " '1884',\n",
       " '1886',\n",
       " '1887',\n",
       " '1889',\n",
       " '189',\n",
       " '1890',\n",
       " '1891',\n",
       " '1892',\n",
       " '1893',\n",
       " '1894',\n",
       " '1895',\n",
       " '1896',\n",
       " '1898',\n",
       " '19',\n",
       " '1900',\n",
       " '1901',\n",
       " '1903',\n",
       " '1904',\n",
       " '1906',\n",
       " '1907',\n",
       " '1908',\n",
       " '1909',\n",
       " '191',\n",
       " '1910',\n",
       " '1911',\n",
       " '1912',\n",
       " '1913',\n",
       " '1914',\n",
       " '1916',\n",
       " '1917',\n",
       " '1918',\n",
       " '1919',\n",
       " '1920',\n",
       " '1921',\n",
       " '1924',\n",
       " '1925',\n",
       " '1928',\n",
       " '1930',\n",
       " '1944',\n",
       " '1960',\n",
       " '1963',\n",
       " '197',\n",
       " '1978',\n",
       " '198',\n",
       " '199',\n",
       " '19thcenturi',\n",
       " '20',\n",
       " '200',\n",
       " '2004',\n",
       " '2008',\n",
       " '201',\n",
       " '2012',\n",
       " '2016',\n",
       " '2019',\n",
       " '206',\n",
       " '20th',\n",
       " '20thcenturi',\n",
       " '21',\n",
       " '22',\n",
       " '223',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " 'abandon',\n",
       " 'abl',\n",
       " 'absolut',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'acclaim',\n",
       " 'accompani',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accus',\n",
       " 'achiev',\n",
       " 'acknowledg',\n",
       " 'acquaint',\n",
       " 'acquir',\n",
       " 'across',\n",
       " 'activ',\n",
       " 'actual',\n",
       " 'acut',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'addit',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advoc',\n",
       " 'affair',\n",
       " 'afford',\n",
       " 'afterward',\n",
       " 'age',\n",
       " 'agre',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'albert',\n",
       " 'alien',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altogeth',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amp',\n",
       " 'analog',\n",
       " 'analysi',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'anguish',\n",
       " 'anna',\n",
       " 'announc',\n",
       " 'annual',\n",
       " 'anoth',\n",
       " 'apart',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approxim',\n",
       " 'april',\n",
       " 'arc',\n",
       " 'area',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'around',\n",
       " 'arrang',\n",
       " 'arriv',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'artist',\n",
       " 'artwork',\n",
       " 'ask',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'astronom',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attract',\n",
       " 'auction',\n",
       " 'audienc',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auster',\n",
       " 'author',\n",
       " 'avoid',\n",
       " 'awaken',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'axi',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bar',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'battl',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behind',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'berlin',\n",
       " 'bernhard',\n",
       " 'best',\n",
       " 'bestsel',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'bibl',\n",
       " 'biograph',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bleed',\n",
       " 'blood',\n",
       " 'board',\n",
       " 'bodi',\n",
       " 'book',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'boy',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bring',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brutal',\n",
       " 'build',\n",
       " 'built',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'buy',\n",
       " 'calcul',\n",
       " 'calculu',\n",
       " 'call',\n",
       " 'came',\n",
       " 'campaign',\n",
       " 'canva',\n",
       " 'captur',\n",
       " 'care',\n",
       " 'carri',\n",
       " 'case',\n",
       " 'caus',\n",
       " 'celebr',\n",
       " 'cemeteri',\n",
       " 'centr',\n",
       " 'centuri',\n",
       " 'certain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'chang',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'china',\n",
       " 'choic',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'christian',\n",
       " 'chronolog',\n",
       " 'church',\n",
       " 'circl',\n",
       " 'citi',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'clear',\n",
       " 'clearli',\n",
       " 'clinic',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'coin',\n",
       " 'collect',\n",
       " 'collector',\n",
       " 'colleg',\n",
       " 'coloni',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'commentari',\n",
       " 'commerci',\n",
       " 'commiss',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commonli',\n",
       " 'commun',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'compil',\n",
       " 'complain',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'compos',\n",
       " 'composit',\n",
       " 'comprehens',\n",
       " 'comput',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'conclud',\n",
       " 'condit',\n",
       " 'confess',\n",
       " 'conflict',\n",
       " 'confus',\n",
       " 'connect',\n",
       " 'consequ',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'constant',\n",
       " 'constitut',\n",
       " 'construct',\n",
       " 'contain',\n",
       " 'contemporari',\n",
       " 'content',\n",
       " 'continu',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'controversi',\n",
       " 'convent',\n",
       " 'convers',\n",
       " 'convey',\n",
       " 'convinc',\n",
       " 'copi',\n",
       " 'correct',\n",
       " 'correspond',\n",
       " 'could',\n",
       " 'countri',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'craft',\n",
       " 'creat',\n",
       " 'creativ',\n",
       " 'crisi',\n",
       " 'criterion',\n",
       " 'critic',\n",
       " 'cross',\n",
       " 'cultur',\n",
       " 'curv',\n",
       " 'da',\n",
       " 'danc',\n",
       " 'danger',\n",
       " 'daniel',\n",
       " 'danish',\n",
       " 'darboux',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debt',\n",
       " 'decad',\n",
       " 'decemb',\n",
       " 'decid',\n",
       " 'declar',\n",
       " 'declin',\n",
       " 'dedic',\n",
       " 'deepli',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'degre',\n",
       " 'delight',\n",
       " 'deliv',\n",
       " 'demand',\n",
       " 'demonstr',\n",
       " 'den',\n",
       " 'denot',\n",
       " 'departur',\n",
       " 'depend',\n",
       " 'depict',\n",
       " 'depress',\n",
       " 'depth',\n",
       " 'der',\n",
       " 'deriv',\n",
       " 'descend',\n",
       " 'describ',\n",
       " 'descript',\n",
       " 'design',\n",
       " 'desir',\n",
       " 'despit',\n",
       " 'destroy',\n",
       " 'detail',\n",
       " 'determin',\n",
       " 'develop',\n",
       " 'diagnos',\n",
       " 'diari',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'differenti',\n",
       " 'difficult',\n",
       " 'dimens',\n",
       " 'direct',\n",
       " 'directli',\n",
       " 'director',\n",
       " 'disappear',\n",
       " 'discov',\n",
       " 'discuss',\n",
       " 'disgust',\n",
       " 'dismiss',\n",
       " 'display',\n",
       " 'displaystyl',\n",
       " 'distanc',\n",
       " 'distinct',\n",
       " 'distinguish',\n",
       " 'divid',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'domain',\n",
       " 'domin',\n",
       " 'donat',\n",
       " 'done',\n",
       " 'dot',\n",
       " 'doubl',\n",
       " 'dozen',\n",
       " 'dr',\n",
       " 'draft',\n",
       " 'dramat',\n",
       " 'draw',\n",
       " 'drawn',\n",
       " 'drew',\n",
       " 'drink',\n",
       " 'due',\n",
       " 'duti',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'earliest',\n",
       " 'earn',\n",
       " 'easi',\n",
       " 'easier',\n",
       " 'eastern',\n",
       " 'edit',\n",
       " 'educ',\n",
       " 'effect',\n",
       " 'effort',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'elabor',\n",
       " 'element',\n",
       " 'elementari',\n",
       " 'els',\n",
       " 'embodi',\n",
       " 'emerg',\n",
       " 'emot',\n",
       " 'empir',\n",
       " 'employ',\n",
       " 'empti',\n",
       " 'encompass',\n",
       " 'encourag',\n",
       " 'end',\n",
       " 'endur',\n",
       " 'energi',\n",
       " 'engag',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enlarg',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertain',\n",
       " 'entir',\n",
       " 'entri',\n",
       " 'equal',\n",
       " 'equat',\n",
       " 'equival',\n",
       " 'especi',\n",
       " 'essay',\n",
       " 'essenti',\n",
       " 'establish',\n",
       " 'estat',\n",
       " 'estim',\n",
       " 'et',\n",
       " 'etern',\n",
       " 'europ',\n",
       " 'european',\n",
       " 'evalu',\n",
       " 'even',\n",
       " 'event',\n",
       " 'eventu',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'everywher',\n",
       " 'evid',\n",
       " 'evok',\n",
       " 'evolv',\n",
       " 'exact',\n",
       " 'exactli',\n",
       " 'exam',\n",
       " 'examin',\n",
       " 'exampl',\n",
       " 'except',\n",
       " 'exchang',\n",
       " 'execut',\n",
       " 'exhaust',\n",
       " 'exhibit',\n",
       " 'exil',\n",
       " 'exist',\n",
       " 'expand',\n",
       " 'expect',\n",
       " 'experi',\n",
       " 'explain',\n",
       " 'exploit',\n",
       " 'explor',\n",
       " 'express',\n",
       " 'expressionist',\n",
       " 'extend',\n",
       " 'extens',\n",
       " 'extent',\n",
       " 'extrem',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'factori',\n",
       " 'fail',\n",
       " 'failur',\n",
       " 'fall',\n",
       " 'fals',\n",
       " 'fame',\n",
       " 'famili',\n",
       " 'famou',\n",
       " 'far',\n",
       " 'farm',\n",
       " 'father',\n",
       " 'favourit',\n",
       " 'fear',\n",
       " 'featur',\n",
       " 'februari',\n",
       " 'feel',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'fiction',\n",
       " 'field',\n",
       " 'figur',\n",
       " 'fill',\n",
       " 'film',\n",
       " 'final',\n",
       " 'financi',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finit',\n",
       " 'fire',\n",
       " 'firm',\n",
       " 'first',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'flat',\n",
       " 'fled',\n",
       " 'flower',\n",
       " 'focu',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'fond',\n",
       " 'forc',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'formal',\n",
       " 'former',\n",
       " 'formul',\n",
       " 'formula',\n",
       " 'found',\n",
       " 'foundat',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'framework',\n",
       " 'franc',\n",
       " 'franci',\n",
       " 'franz',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'french',\n",
       " 'frequent',\n",
       " 'friend',\n",
       " 'full',\n",
       " 'fulli',\n",
       " 'function',\n",
       " 'fundament',\n",
       " 'funer',\n",
       " 'gain',\n",
       " 'galleri',\n",
       " 'gave',\n",
       " 'gener',\n",
       " 'genr',\n",
       " 'geometr',\n",
       " 'georg',\n",
       " 'german',\n",
       " 'germani',\n",
       " 'get',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goe',\n",
       " 'good',\n",
       " 'gothic',\n",
       " 'govern',\n",
       " 'graduat',\n",
       " 'grand',\n",
       " 'grant',\n",
       " 'graph',\n",
       " 'graphic',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'grew',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'gt',\n",
       " 'gustav',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'hand',\n",
       " 'handl',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'hat',\n",
       " 'head',\n",
       " 'health',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heavi',\n",
       " 'height',\n",
       " 'held',\n",
       " 'help',\n",
       " 'henri',\n",
       " 'heritag',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'highli',\n",
       " 'hint',\n",
       " 'histor',\n",
       " 'histori',\n",
       " 'historian',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hospit',\n",
       " 'host',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'howev',\n",
       " 'human',\n",
       " 'hundr',\n",
       " 'husband',\n",
       " 'hyperr',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'ident',\n",
       " 'identifi',\n",
       " 'ie',\n",
       " 'ignor',\n",
       " 'ii',\n",
       " 'ill',\n",
       " 'illustr',\n",
       " 'imag',\n",
       " 'imagin',\n",
       " 'immedi',\n",
       " 'implement',\n",
       " 'impli',\n",
       " 'import',\n",
       " 'improp',\n",
       " 'incid',\n",
       " 'includ',\n",
       " 'incom',\n",
       " 'incorpor',\n",
       " 'increas',\n",
       " 'inde',\n",
       " 'independ',\n",
       " 'index',\n",
       " 'indic',\n",
       " 'individu',\n",
       " 'industri',\n",
       " 'inequ',\n",
       " 'infect',\n",
       " 'infin',\n",
       " 'infinit',\n",
       " 'infinitesim',\n",
       " 'influenc',\n",
       " 'influenti',\n",
       " 'inform',\n",
       " 'inherit',\n",
       " 'initi',\n",
       " 'insid',\n",
       " 'inspir',\n",
       " 'instanc',\n",
       " 'instead',\n",
       " 'institut',\n",
       " 'instruct',\n",
       " 'integ',\n",
       " 'integr',\n",
       " 'integrand',\n",
       " 'intend',\n",
       " 'intens',\n",
       " 'intent',\n",
       " 'interest',\n",
       " 'interior',\n",
       " 'intern',\n",
       " 'interpret',\n",
       " 'interv',\n",
       " 'introduc',\n",
       " 'invent',\n",
       " 'investig',\n",
       " 'involv',\n",
       " 'isol',\n",
       " 'issu',\n",
       " 'jacob',\n",
       " 'jame',\n",
       " 'januari',\n",
       " 'japanes',\n",
       " 'jewish',\n",
       " 'johann',\n",
       " 'join',\n",
       " 'joseph',\n",
       " 'journal',\n",
       " 'journalist',\n",
       " 'journey',\n",
       " 'juli',\n",
       " 'june',\n",
       " 'justifi',\n",
       " 'karl',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'kind',\n",
       " 'king',\n",
       " 'knight',\n",
       " 'know',\n",
       " 'known',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'land',\n",
       " 'landscap',\n",
       " 'languag',\n",
       " 'larg',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latin',\n",
       " 'latter',\n",
       " 'le',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leav',\n",
       " 'lebesgu',\n",
       " 'lectur',\n",
       " 'led',\n",
       " 'left',\n",
       " 'legaci',\n",
       " 'length',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'liber',\n",
       " 'lie',\n",
       " 'lieuten',\n",
       " 'life',\n",
       " 'like',\n",
       " 'limit',\n",
       " 'line',\n",
       " 'linear',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'liter',\n",
       " 'literari',\n",
       " 'literatur',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'local',\n",
       " 'locat',\n",
       " 'lone',\n",
       " 'long',\n",
       " 'look',\n",
       " 'loos',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lt',\n",
       " 'made',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manag',\n",
       " 'mani',\n",
       " 'manner',\n",
       " 'manuscript',\n",
       " 'map',\n",
       " 'march',\n",
       " 'mari',\n",
       " 'mark',\n",
       " 'marri',\n",
       " 'marriag',\n",
       " 'master',\n",
       " 'masterpiec',\n",
       " 'materi',\n",
       " 'mathbb',\n",
       " 'mathemat',\n",
       " 'mathematician',\n",
       " 'matter',\n",
       " 'max',\n",
       " 'may',\n",
       " 'mean',\n",
       " 'measur',\n",
       " 'medic',\n",
       " 'meet',\n",
       " 'member',\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a64800-4522-472a-aaa4-4e8799e578f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warto zrupowac np. wzgledem liczby cyfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dbae568-4ad0-4f99-8311-20fe303e8c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9687c104-7e25-4b43-98c2-7fe1bbcb6a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1558 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 365 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "799515a0-a904-4e33-9489-c2991233a8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1b4bd13-43f3-4792-be44-288a86d3761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,3].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27565e60-0c07-48dc-9599-bf885b9c1c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,3].A.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a347b74-2a0f-4118-b714-97d2a9f126b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 68],\n",
       "        [125],\n",
       "        [ 20],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,vectorizer.get_feature_names().index(\"paint\")].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e617a3d-769d-4dc9-ab03-b1437543b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podaj 10 najczestszych slow z kazdego dokumentu argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "789b18e5-2214-4b18-bf5d-33829a5a7c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['integr' 'function' 'use' 'area' 'interv' 'sum' 'riemann' 'one'\n",
      " 'differenti' 'definit']\n",
      "['integr' 'riemann' 'function' 'sum' 'interv' 'partit' 'tag' 'zero'\n",
      " 'point' 'definit']\n",
      "['integr' 'displaystyl' 'riemann' 'function' 'gener' 'partit' 'continu'\n",
      " 'respect' 'bound' 'exist']\n",
      "['deriv' 'function' 'point' 'vector' 'differenti' 'linear' 'variabl'\n",
      " 'direct' 'displaystyl' 'approxim']\n",
      "['displaystyl' 'sequenc' 'limit' 'to' 'space' 'gt' 'seri' 'right' 'exist'\n",
      " 'real']\n",
      "['paint' 'museum' 'work' 'art' 'life' 'exhibit' 'oil' 'artist' 'includ'\n",
      " 'canva']\n",
      "['paint' 'work' 'art' 'museum' 'pari' 'artist' 'two' '1890' '1889' 'life']\n",
      "['paint' 'art' 'histor' 'nation' '30' 'work' 'fine' 'histori' '17'\n",
      " 'museum']\n",
      "['work' 'war' 'also' 'wrote' 'novel' 'state' 'one' 'peac' 'time' 'life']\n",
      "['work' 'publish' 'stori' 'write' 'german' 'der' 'franz' 'die' 'time'\n",
      " 'first']\n",
      "['work' 'languag' 'english' 'publish' 'later' 'book' 'first' 'letter'\n",
      " 'year' 'stori']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "n = 10\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', min_df=3)\n",
    "vectorizer.fit(articles)\n",
    "X = vectorizer.transform(articles)\n",
    "\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "for i in range(X.shape[0]):\n",
    "    print(words[X[i].A.flatten().argsort()[::-1]][:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0eca556b-cc21-4e7e-9aed-949548811cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 541,  570, 1086, 1265, 1401,  887,  318, 1489,  759,  878])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2214154-fc84-485a-92d4-d811c3b8c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b16fa898-0906-4e1b-9c03-1a1c3b93b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['integr' 'function' 'interv' 'riemann' 'area' 'differenti' 'sum']\n",
      "['integr' 'riemann' 'interv' 'partit' 'sum' 'function' 'tag']\n",
      "['integr' 'riemann' 'displaystyl' 'function' 'partit' 'bound' 'gener']\n",
      "['deriv' 'function' 'vector' 'differenti' 'variabl' 'linear' 'displaystyl']\n",
      "['displaystyl' 'sequenc' 'limit' 'to' 'gt' 'space' 'tend']\n",
      "['paint' 'museum' 'art' 'oil' 'work' 'life' 'canva']\n",
      "['paint' 'work' 'art' 'museum' 'pari' 'portrait' '1889']\n",
      "['paint' 'histor' 'art' 'fine' 'nation' '30' 'histori']\n",
      "['war' 'work' 'novel' 'wrote' 'peac' 'also' 'life']\n",
      "['work' 'stori' 'franz' 'publish' 'der' 'literari' 'jewish']\n",
      "['english' 'languag' 'work' 'colleg' 'stori' 'publish' 'year']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "n = 7\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', min_df=3)\n",
    "vectorizer.fit(articles)\n",
    "X = vectorizer.transform(articles)\n",
    "\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "for i in range(X.shape[0]):\n",
    "    print(words[X[i].A.flatten().argsort()[::-1]][:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7608345-bf49-49f7-9d31-ed88df869583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6a365477-ffa5-413c-b6c2-99b35a63b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b2eb9fd3-e310-4315-818b-9da1a86dfef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rych' 'prj' 'file' 'textur' '3d' 'festival' 'save']\n",
      "['almanac' 'frog' 'koresh' '245' '604' 'uta' 'utarlg']\n"
     ]
    }
   ],
   "source": [
    "texts = newsgroups_train.data\n",
    "y = newsgroups_train.target\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "texts = [nltk.word_tokenize(mail) for mail in texts]\n",
    "texts = [[stemmer.stem(word) for word in mail] for mail in texts]\n",
    "texts = [\" \".join(mail) for mail in texts]\n",
    "\n",
    "i = 0\n",
    "n = 7\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', min_df=1)\n",
    "vectorizer.fit(texts)\n",
    "X = vectorizer.transform(texts)\n",
    "\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "for i in range(2):#X.shape[0]):\n",
    "    print(words[X[i].A.flatten().argsort()[::-1]][:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "effbd4e7-10af-41ad-a808-6a5378264bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "72ebb14d-e583-4f1a-9c99-0e4d53bafd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', min_df=1)\n",
    "vectorizer.fit(articles)\n",
    "X = vectorizer.transform(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dddb1a05-3139-40dc-b706-8c57d18b5732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86, -0.04, -0.1 ],\n",
       "       [ 0.85, -0.06, -0.14],\n",
       "       [ 0.89, -0.07, -0.01],\n",
       "       [ 0.47,  0.03,  0.16],\n",
       "       [ 0.37,  0.02,  0.31],\n",
       "       [ 0.04,  0.55, -0.36],\n",
       "       [ 0.05,  0.58, -0.33],\n",
       "       [ 0.04,  0.56, -0.22],\n",
       "       [ 0.04,  0.36,  0.43],\n",
       "       [ 0.05,  0.37,  0.47],\n",
       "       [ 0.05,  0.38,  0.42]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_reductor = TruncatedSVD(3)\n",
    "dim_reductor.fit(X)\n",
    "dim_reductor.transform(X).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cdc0f1-2ea3-460c-a0e5-d8929863911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(list_of_list):\n",
    "    result = []\n",
    "    for inner_list in list_of_list:\n",
    "        for x in inner_list:\n",
    "            if x not in result:\n",
    "                result.append(x)\n",
    "    return result\n",
    "\n",
    "def f2(list_of_list):\n",
    "    flat_list = []\n",
    "    for inner_list in list_of_list:\n",
    "        flat_list.extend(inner_list)\n",
    "    return [\n",
    "        x for i, x in enumerate(flat_list)\n",
    "        if flat_list.index(x) == i]\n",
    "\n",
    "def f3(list_of_list):\n",
    "    result = []\n",
    "    seen = set()\n",
    "    for inner_list in list_of_list:\n",
    "        for x in inner_list:\n",
    "            if x not in seen:\n",
    "                result.append(x)\n",
    "                seen.add(x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e327d12-74da-46fc-8986-6daff12cb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exlst = [10000*[1,4,6,1,1,2,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa059639-d52c-4227-aeff-d12674d657fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 ms, sys: 29 µs, total: 2.79 ms\n",
      "Wall time: 2.89 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f1(exlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e904b48d-ed41-4ecb-880e-59cde0f545ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.13 ms, sys: 125 µs, total: 7.26 ms\n",
      "Wall time: 7.24 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f2(exlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fecf8c45-80fb-4577-bae7-6a43bcf97bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 ms, sys: 0 ns, total: 1.53 ms\n",
      "Wall time: 1.53 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f3(exlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a793a99-aeba-4d6b-8452-ee1b5910286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999987"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 - 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7305a807-8140-4bc3-952b-7cac3317a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}Layer\"\n",
    "\n",
    "class ActivationLayer(BaseLayer):\n",
    "    def __init__(self, size):\n",
    "        super().__init__(\"Activation\")\n",
    "        self.size = size\n",
    "\n",
    "class FCLayer(BaseLayer):\n",
    "    def __init__(self, size):\n",
    "        super().__init__(\"FullyConnected\")\n",
    "        self.size = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33ab198-8ad4-425d-8cdc-97b0f52a9cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaseLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac2ba5-39c4-48e9-a20c-cd081c294e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
